{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys, getopt\n",
    "import csv\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import umap\n",
    "from sklearn.decomposition import TruncatedSVD as tsvd\n",
    "\n",
    "def nearZeroVarDropAuto(df,thresh=0.99):\n",
    "    vVal=df.var(axis=0).values\n",
    "    cs=pd.Series(vVal).sort_values(ascending=False).cumsum()\n",
    "    remove=cs[cs>cs.values[-1]*thresh].index.values\n",
    "    return df.drop(df.columns[remove],axis=1)\n",
    "\n",
    "%run SodaKick_download_functions.ipynb\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import SGD, Adagrad, Adam, Adagrad\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ray import tune\n",
    "#from ray.tune import CLIReporter\n",
    "#from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from hyperopt import STATUS_OK, STATUS_FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    \"\"\" Stops the training if loss doesn't improve after a given number of epochs. \"\"\"\n",
    "\n",
    "    def __init__(self, patience=3, epsilon=1e-5, keepBest=True, silent=True):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs without change before stopping the learning (default 3).\n",
    "            epsilon (float): Minimum change in loss to be considered for early stopping (default 1e-5).\n",
    "            keepBest (bool): Keep track of the best model (memory consuming).\n",
    "        \"\"\"\n",
    "\n",
    "        self.patience = patience\n",
    "        self.epsilon = epsilon\n",
    "        self.counter = 0\n",
    "        \n",
    "        self.bestScore = np.inf\n",
    "     \n",
    "        self.keepBest = keepBest \n",
    "        self.bestModel = None\n",
    "\n",
    "        self.earlyStop = False\n",
    "        self.silent = silent\n",
    "\n",
    "    def __call__(self, loss, model):\n",
    "\n",
    "\n",
    "        \"\"\" Evaluate the loss change between epochs and activates early stop if below epsilon.\n",
    "\n",
    "        Args:\n",
    "            loss (float): current loss.\n",
    "            model (torch model): the current model.\n",
    "        \"\"\"\n",
    "\n",
    "        if loss > self.bestScore - self.epsilon:\n",
    "\n",
    "            self.counter += 1\n",
    "            if not self.silent:\n",
    "                print('EarlyStopping counter: {:d}/{:d}'.format(self.counter,self.patience))\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.earlyStop = True\n",
    "\n",
    "        else:   \n",
    "\n",
    "            self.counter = 0\n",
    "            self.bestScore = loss\n",
    "\n",
    "            if self.keepBest:\n",
    "                self.bestModel = copy.deepcopy(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class matchesDataset(Dataset):\n",
    "\n",
    "    \"\"\" Extend pytorch Dataset class to include cleaning and training set creation, \"\"\"\n",
    "    \n",
    "    def __init__(self, matches, results):\n",
    "\n",
    "        self.matches = torch.tensor(matches, dtype=torch.float32)\n",
    "        self.results = torch.tensor(results, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        \"\"\" Returns the len of the training sample. \"\"\"\n",
    "        \n",
    "        return len(self.matches)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index): \n",
    "\n",
    "        \"\"\" Returns a word, a context word and a list of negative words for training for a given index. \n",
    "\n",
    "        Args:\n",
    "            index (int): index for the word selection.\n",
    "\n",
    "        Returns:\n",
    "            (string, string, list of strings): selected word, context word and a randomly drawn list \n",
    "                                               of negative words.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.matches[index], self.results[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/quirky-keras-custom-and-asymmetric-loss-functions-for-keras-in-r-a8b5271171fe\n",
    "#weighted asimmetric square error, errors by going below the value (not seeing a goal when it's there) are weighted more\n",
    "\n",
    "def WSE(output, target, a=1.5, b=.5):\n",
    "    loss = torch.mean(a/(a+b)*torch.minimum(torch.zeros(output.shape[1]),output - target)**2+\\\n",
    "                      b/(a+b)*torch.maximum(torch.zeros(output.shape[1]),output - target)**2)      \n",
    "    return loss\n",
    "\n",
    "def WSEl1(output, target, a=1.5, b=.5):\n",
    "    loss = torch.mean(a/(a+b)*torch.abs(torch.minimum(torch.zeros(output.shape[1]),output - target))+\\\n",
    "                      b/(a+b)*torch.abs(torch.maximum(torch.zeros(output.shape[1]),output - target)))      \n",
    "    return loss\n",
    "\n",
    "def WSE2(output, target, a=1.5, b=.5):\n",
    "    loss = np.mean(a/(a+b)*np.minimum(np.zeros(output.shape[0]),output - target)**2+\\\n",
    "                      b/(a+b)*np.maximum(np.zeros(output.shape[0]),output - target)**2)      \n",
    "    return loss\n",
    "\n",
    "def WSEl12(output, target, a=1.5, b=.5):\n",
    "    loss = np.mean(a/(a+b)*np.abs(np.minimum(np.zeros(output.shape[0]),output - target))+\\\n",
    "                      b/(a+b)*np.abs(np.maximum(np.zeros(output.shape[0]),output - target)))      \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mins(vec):\n",
    "    for i in range(vec.shape[0]):\n",
    "        vec[i][::8]=vec[i][::8]/90\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def NormalizeMatrix(data):   \n",
    "    for i in range(data.shape[1]):\n",
    "        data[:,i] = NormalizeData(data[:,i])\n",
    "\n",
    "def norm_max(out):\n",
    "    \n",
    "    maxes=[]\n",
    "    for i in range(int(out.shape[1]/8.0)):\n",
    "        maxes.append(out[:,8*int(i):8*(int(i)+1)].max(axis=0))\n",
    "\n",
    "        #maxes.append(out.max(axis=1)[8*int(i):8*(int(i)+1):8])\n",
    "    denominator=np.tile(np.max(maxes,axis=0),int(out.shape[1]/8))\n",
    "    return out/denominator, denominator \n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/inp_220223.pkl', 'rb') as pk:\n",
    "    inp=pickle.load(pk)\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/out_220223.pkl', 'rb') as pk:\n",
    "    out=np.array(pickle.load(pk),dtype=float)\n",
    "    \n",
    "### skipping norm for now since it's already tsvd \n",
    "#NormalizeMatrix(inp)\n",
    "#np.nan_to_num(inp, copy=False)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "inp = scaler.fit_transform(inp)\n",
    "\n",
    "#normalize_mins(out)\n",
    "out, denominator= norm_max(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "         inp[:25000], out[:25000], test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_layers, num_nodes, scaling_factor, num_nodes_out, final_activation, batch_norm, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc = []\n",
    "        self.lr = []\n",
    "        self.bn = []\n",
    "        self.dp = []\n",
    "        self.fact = final_activation\n",
    "        self.nl = num_layers\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        power=0\n",
    "        \n",
    "        for i in range(self.nl):\n",
    "            self.fc.append(nn.Linear(int(num_nodes*(scaling_factor**power)), int(num_nodes*(scaling_factor**(power+1)))))\n",
    "            self.lr.append(nn.LeakyReLU())\n",
    "            \n",
    "            if self.batch_norm:\n",
    "                self.bn.append(nn.BatchNorm1d(int(num_nodes*(scaling_factor**(power+1)))))\n",
    "\n",
    "            if self.dropout>0.0:\n",
    "                self.dp.append(nn.Dropout(dropout))\n",
    "                \n",
    "            power+=1\n",
    "        \n",
    "        self.oupt = nn.Linear(int(num_nodes*(scaling_factor**power)), int(num_nodes_out))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x\n",
    "        for i in range(self.nl):\n",
    "            \n",
    "            z = self.fc[i](z)\n",
    "            \n",
    "            if self.batch_norm:\n",
    "                z = self.bn[i](z)\n",
    "            \n",
    "            z = self.lr[i](z)\n",
    "        \n",
    "            if self.dropout>0.0:\n",
    "                z = self.dp[i](z)\n",
    "                \n",
    "        if self.fact is not None:\n",
    "            z = self.fact(z)\n",
    "        \n",
    "        z = self.oupt(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def clp(self):\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.nl):\n",
    "                self.fc[i].weight.copy_ (self.fc[i].weight.data.clamp(min=0)) \n",
    "            self.oupt.weight.copy_ (self.oupt.weight.data.clamp(min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, model=Net, silent=True, checkpoint_dir=None):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        phases = ['train','val']\n",
    "\n",
    "        #x_train, x_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "\n",
    "        training_set = matchesDataset(x_train, y_train)\n",
    "        trainBatch = torch.utils.data.DataLoader(training_set, batch_size=config['batch_size'], shuffle=config['shuffle'], num_workers=config['num_workers'])\n",
    "\n",
    "        validation_set = matchesDataset(x_test, y_test)\n",
    "        valBatch = torch.utils.data.DataLoader(validation_set, batch_size=config['batch_size'], shuffle=config['shuffle'], num_workers=config['num_workers'])\n",
    "\n",
    "        earlStop = EarlyStopping(patience=config['patience'], keepBest=False)\n",
    "\n",
    "        net = model(config['num_layers'], config['num_nodes'], config['scaling_factor'], \n",
    "                    config['num_nodes_out'], config['final_activation'], config['batch_norm'], config['dropout'])\n",
    "\n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                net = nn.DataParallel(net)\n",
    "        net.to(device)\n",
    "\n",
    "        if checkpoint_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "            net.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "        if config['optim']=='adam':\n",
    "            optimizer = Adam(net.parameters(), lr=config['lr'])\n",
    "        elif config['optim']=='adagrad':\n",
    "            optimizer = Adagrad(net.parameters(), lr=config['lr'])\n",
    "        else:\n",
    "            print('optim error')\n",
    "            return\n",
    "\n",
    "\n",
    "        losses=[[],[]]\n",
    "        mses=[]\n",
    "        diffs=[]\n",
    "        exit=False\n",
    "\n",
    "        #for epoch in tqdm(range(epochs), desc='Epoch'):\n",
    "        for epoch in range(config['epochs']):\n",
    "\n",
    "            if exit:\n",
    "                break\n",
    "\n",
    "            for phase in phases:\n",
    "                if phase == 'train':\n",
    "                    net.train(True) \n",
    "\n",
    "                    \"\"\" Run the training of the model. \"\"\"    \n",
    "\n",
    "                    losses_batch=[]\n",
    "                    for batchNum, batch in enumerate(trainBatch):\n",
    "\n",
    "                        x = batch[0]\n",
    "                        y = batch[1]\n",
    "\n",
    "                        \"\"\" Move batches to GPU if available. \"\"\"\n",
    "\n",
    "                        if torch.cuda.is_available():\n",
    "                            x = x.cuda()\n",
    "                            y = y.cuda()\n",
    "\n",
    "                        \"\"\" Core of training. \"\"\"\n",
    "\n",
    "                        loss = config['loss_f'](net(x), y)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if config['clip']:\n",
    "                            net.clp()\n",
    "\n",
    "                        losses_batch.append(loss)\n",
    "\n",
    "                    \"\"\" Early stop check. \"\"\"\n",
    "\n",
    "                    earlStop(loss, net)\n",
    "                    finalepoch = epoch\n",
    "\n",
    "                    if earlStop.earlyStop:\n",
    "\n",
    "                        if not silent:\n",
    "                            print('Limit loss improvement reached, stopping the training.')\n",
    "\n",
    "                        exit=True \n",
    "\n",
    "                    #losses[0].append(torch.mean(torch.stack(losses_batch)).detach().cpu().numpy())\n",
    "                else:\n",
    "                    net.train(False)\n",
    "                    net.eval()\n",
    "\n",
    "                    val_loss=0\n",
    "                    val_mse=0\n",
    "\n",
    "                    losses_batch=[]\n",
    "                    for batchNum, batch in enumerate(valBatch):\n",
    "\n",
    "                        x = batch[0]\n",
    "                        y = batch[1]\n",
    "\n",
    "                        \"\"\" Move batches to GPU if available. \"\"\"\n",
    "\n",
    "                        if torch.cuda.is_available():\n",
    "                            x = x.cuda()\n",
    "                            y = y.cuda()\n",
    "\n",
    "                        \"\"\" Core of training. \"\"\"\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        output=net(x)\n",
    "                        target=y\n",
    "                        loss = config['loss_f'](output, target)\n",
    "\n",
    "                        #losses_batch.append(loss)\n",
    "                        val_loss+=loss.detach().numpy()\n",
    "                        val_mse+=nn.MSELoss()(output, target).detach().numpy()\n",
    "\n",
    "                    #losses[1].append(torch.mean(torch.stack(losses_batch)).detach().cpu().numpy())\n",
    "\n",
    "                    #with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                    #    path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "                    #    torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "                    #tune.report(loss=(val_loss/batchNum), mse=(val_mse/batchNum))\n",
    "                    #tune.report(loss=torch.mean(torch.stack(losses_batch)))\n",
    "\n",
    "        return {'loss': (val_loss/batchNum), 'status': STATUS_OK , 'mse': (val_mse/batchNum)}\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return {'loss': np.nan, 'status': STATUS_FAIL, 'mse': np.nan}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_output(output,multiplier=denominator,lineup=None):\n",
    "\n",
    "    reframe=pd.DataFrame(output.reshape(48,8),\n",
    "                 columns=['minutes','goals','assists','cards_yellow','cards_red','own_goals','goals_against','saves'])\n",
    "    \n",
    "    reframe[reframe<0] = 0\n",
    "    if lineup is not None:\n",
    "        reframe.index=lineup\n",
    "        reframe.drop([x for x in reframe.index if x.startswith('dummy')], axis=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    #reframe['minutes']*=90\n",
    "    reframe=reframe*denominator[:8]\n",
    "    byteamframe=pd.concat([reframe.iloc[:24,:].sum(axis=0),reframe.iloc[24:,:].sum(axis=0)], axis=1).T\n",
    "    \n",
    "    return reframe, byteamframe[byteamframe.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline WSE: 0.039\n",
      "Baseline WSE l1: 0.051\n",
      "Baseline MSE: 0.026\n",
      "Baseline MSE l1: 0.034\n",
      "35.763398692810455\n",
      "23.69281045751634\n",
      "34.116993464052285\n"
     ]
    }
   ],
   "source": [
    "print('Baseline WSE: {:.3f}'.format(WSE2(np.array([0]*out[0].shape[0]),out[0])))\n",
    "print('Baseline WSE l1: {:.3f}'.format(WSEl12(np.array([0]*out[0].shape[0]),out[0])))\n",
    "print('Baseline MSE: {:.3f}'.format(WSE2(np.array([0]*out[0].shape[0]),out[0], a=1, b=1)))\n",
    "print('Baseline MSE l1: {:.3f}'.format(WSEl12(np.array([0]*out[0].shape[0]),out[0], a=1, b=1)))\n",
    "\n",
    "print(np.abs(out[1]-out[10]).sum())\n",
    "print(np.abs(out[50]-out[60]).sum())\n",
    "print(np.abs(out[100]-out[110]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hopt(config, num_samples=10):#, gpus_per_trial=2):\n",
    "    \n",
    "    trials = Trials()\n",
    "    result = fmin(\n",
    "            fn=train,\n",
    "            space=config,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=num_samples,\n",
    "            trials=trials,\n",
    "            show_progressbar=True),\n",
    "            #early_stop_fn=10,\n",
    "            #trials_save_file=None)\n",
    "    \n",
    "    \n",
    "    return trials\n",
    "    #return best_trained_model\n",
    "    #test_acc = test_accuracy(best_trained_model, device)\n",
    "    #print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config = {\\n       \"num_layers\": hp.choice(\\'num_layers\\', [1, 2, 3]),\\n       \"num_nodes\": inp.shape[1],\\n       \"scaling_factor\": hp.uniform(\\'scaling_factor\\', 0.5, 1.5),\\n       \"num_nodes_out\": out.shape[1], \\n       \"final_activation\" : None, #hp.choice(\\'final_activation\\',[torch.tanh, None]),\\n       \"clip\": False, #hp.choice(\\'clip\\',[True, False]),\\n       \"batch_size\": 32, #[16, 32, 64, 128]\\n       \"loss_f\": nn.MSELoss(),#hp.choice(\\'loss_f\\',[WSE, nn.MSELoss()]), #, nn.L1Loss()\\n       \"optim\": hp.choice(\\'optim\\',[\\'adam\\', \\'adagrad\\']),\\n       \"lr\": hp.loguniform(\\'lr\\', np.exp(np.log(1e-4)), np.exp(np.log(1e-1))),\\n       \"batch_norm\": hp.choice(\\'batch_norm\\',[True, False]),\\n       \"dropout\": hp.choice(\\'dropout\\',[0.0,0.1,0.2,0.3,0.4,0.5]),#hp.sample_from(lambda _: np.random.uniform(low=0.0, high=.6)),\\n       \"shuffle\": True,\\n       \"num_workers\": 4,\\n       \"patience\": 10,\\n       \"epochs\": 100\\n   }\\n   \\n\\n\\nbtm = run_hopt(config, num_samples=100)\\n#https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#tune-search-alg\\n\\n\\nresults_df=[]\\n\\nfor trial in btm.trials:\\n   results_df.append([trial[\\'result\\'][\\'loss\\'],\\n   [1,2,3][trial[\\'misc\\'][\\'vals\\'][\"num_layers\"][0]],\\n   #[inp.shape[1]][trial[\\'misc\\'][\\'vals\\'][\"num_nodes\"][0]],\\n   trial[\\'misc\\'][\\'vals\\'][\"scaling_factor\"][0],\\n   #[out.shape[1]][trial[\\'misc\\'][\\'vals\\'][\"num_nodes_out\"][0]],\\n   #[torch.tanh, None][trial[\\'misc\\'][\\'vals\\'][\"final_activation\"][0]],\\n   #[True, False][trial[\\'misc\\'][\\'vals\\'][\"clip\"][0]],\\n   #[16, 32, 64, 128][trial[\\'misc\\'][\\'vals\\'][\"batch_size\"][0]],\\n   #trial[\\'misc\\'][\\'vals\\'][\"loss_f\"][0],\\n   [\\'adam\\', \\'adagrad\\'][trial[\\'misc\\'][\\'vals\\'][\"optim\"][0]],\\n   trial[\\'misc\\'][\\'vals\\'][\"lr\"][0],\\n   [True, False][trial[\\'misc\\'][\\'vals\\'][\"batch_norm\"][0]],\\n   [0.0,0.1,0.2,0.3,0.4,0.5][trial[\\'misc\\'][\\'vals\\'][\"dropout\"][0]],\\n   #True][trial[\\'misc\\'][\\'vals\\'][\"shuffle\"][0]],\\n   #[4][trial[\\'misc\\'][\\'vals\\'][\"num_workers\"][0]],\\n   #[10][trial[\\'misc\\'][\\'vals\\'][\"patience\"][0]],\\n   #[50][trial[\\'misc\\'][\\'vals\\'][\"epochs\"][0]]])\\n                      \\n   ])\\n\\n   \\nresults_df=pd.DataFrame(results_df,columns=[\\'loss\\',\\'num_layers\\',\\'scaling_factor\\',#\\'final_activation\\',\\'clip\\',\\n                                \\'optim\\',\\'lr\\',\\'batch_norm\\',\\'dropout\\']).sort_values(\\'loss\\')\\nresults_df.to_hdf(r\\'/Users/federico comitani/GitHub/sodakick/data/hp_res1.h5\\',key=\\'df\\')'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"\"\"config = {\n",
    "        \"num_layers\": hp.choice('num_layers', [1, 2, 3]),\n",
    "        \"num_nodes\": inp.shape[1],\n",
    "        \"scaling_factor\": hp.uniform('scaling_factor', 0.5, 1.5),\n",
    "        \"num_nodes_out\": out.shape[1], \n",
    "        \"final_activation\" : None, #hp.choice('final_activation',[torch.tanh, None]),\n",
    "        \"clip\": False, #hp.choice('clip',[True, False]),\n",
    "        \"batch_size\": 32, #[16, 32, 64, 128]\n",
    "        \"loss_f\": nn.MSELoss(),#hp.choice('loss_f',[WSE, nn.MSELoss()]), #, nn.L1Loss()\n",
    "        \"optim\": hp.choice('optim',['adam', 'adagrad']),\n",
    "        \"lr\": hp.loguniform('lr', np.exp(np.log(1e-4)), np.exp(np.log(1e-1))),\n",
    "        \"batch_norm\": hp.choice('batch_norm',[True, False]),\n",
    "        \"dropout\": hp.choice('dropout',[0.0,0.1,0.2,0.3,0.4,0.5]),#hp.sample_from(lambda _: np.random.uniform(low=0.0, high=.6)),\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"patience\": 10,\n",
    "        \"epochs\": 100\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "btm = run_hopt(config, num_samples=100)\n",
    "#https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#tune-search-alg\n",
    "\n",
    "\n",
    "results_df=[]\n",
    "\n",
    "for trial in btm.trials:\n",
    "    results_df.append([trial['result']['loss'],\n",
    "    [1,2,3][trial['misc']['vals'][\"num_layers\"][0]],\n",
    "    #[inp.shape[1]][trial['misc']['vals'][\"num_nodes\"][0]],\n",
    "    trial['misc']['vals'][\"scaling_factor\"][0],\n",
    "    #[out.shape[1]][trial['misc']['vals'][\"num_nodes_out\"][0]],\n",
    "    #[torch.tanh, None][trial['misc']['vals'][\"final_activation\"][0]],\n",
    "    #[True, False][trial['misc']['vals'][\"clip\"][0]],\n",
    "    #[16, 32, 64, 128][trial['misc']['vals'][\"batch_size\"][0]],\n",
    "    #trial['misc']['vals'][\"loss_f\"][0],\n",
    "    ['adam', 'adagrad'][trial['misc']['vals'][\"optim\"][0]],\n",
    "    trial['misc']['vals'][\"lr\"][0],\n",
    "    [True, False][trial['misc']['vals'][\"batch_norm\"][0]],\n",
    "    [0.0,0.1,0.2,0.3,0.4,0.5][trial['misc']['vals'][\"dropout\"][0]],\n",
    "    #True][trial['misc']['vals'][\"shuffle\"][0]],\n",
    "    #[4][trial['misc']['vals'][\"num_workers\"][0]],\n",
    "    #[10][trial['misc']['vals'][\"patience\"][0]],\n",
    "    #[50][trial['misc']['vals'][\"epochs\"][0]]])\n",
    "                       \n",
    "    ])\n",
    "\n",
    "    \n",
    "results_df=pd.DataFrame(results_df,columns=['loss','num_layers','scaling_factor',#'final_activation','clip',\n",
    "                                 'optim','lr','batch_norm','dropout']).sort_values('loss')\n",
    "results_df.to_hdf(r'/Users/federico comitani/GitHub/sodakick/data/hp_res1.h5',key='df')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' config = {\\n        \"num_layers\": hp.choice(\\'num_layers\\', [1, 2, 3]),\\n        \"num_nodes\": inp.shape[1],\\n        \"scaling_factor\": hp.uniform(\\'scaling_factor\\', 0.5, 1.5),\\n        \"num_nodes_out\": out.shape[1], \\n        \"final_activation\" : None, #hp.choice(\\'final_activation\\',[torch.tanh, None]),\\n        \"clip\": False, #hp.choice(\\'clip\\',[True, False]),\\n        \"batch_size\": 32, #[16, 32, 64, 128]\\n        \"loss_f\": WSE,#hp.choice(\\'loss_f\\',[WSE, nn.MSELoss()]), #, nn.L1Loss()\\n        \"optim\": hp.choice(\\'optim\\',[\\'adam\\', \\'adagrad\\']),\\n        \"lr\": hp.loguniform(\\'lr\\', np.exp(np.log(1e-4)), np.exp(np.log(1e-1))),\\n        \"batch_norm\": hp.choice(\\'batch_norm\\',[True, False]),\\n        \"dropout\": hp.choice(\\'dropout\\',[0.0,0.1,0.2,0.3,0.4,0.5]),#hp.sample_from(lambda _: np.random.uniform(low=0.0, high=.6)),\\n        \"shuffle\": True,\\n        \"num_workers\": 4,\\n        \"patience\": 10,\\n        \"epochs\": 100\\n    }\\n    \\nbtm = run_hopt(config, num_samples=100)\\n\\nresults_df=[]\\n\\nfor trial in btm.trials:\\n    results_df.append([trial[\\'result\\'][\\'loss\\'],\\n    [1,2,3][trial[\\'misc\\'][\\'vals\\'][\"num_layers\"][0]],\\n    #[inp.shape[1]][trial[\\'misc\\'][\\'vals\\'][\"num_nodes\"][0]],\\n    trial[\\'misc\\'][\\'vals\\'][\"scaling_factor\"][0],\\n    #[out.shape[1]][trial[\\'misc\\'][\\'vals\\'][\"num_nodes_out\"][0]],\\n    #[torch.tanh, None][trial[\\'misc\\'][\\'vals\\'][\"final_activation\"][0]],\\n    #[True, False][trial[\\'misc\\'][\\'vals\\'][\"clip\"][0]],\\n    #[16, 32, 64, 128][trial[\\'misc\\'][\\'vals\\'][\"batch_size\"][0]],\\n    #trial[\\'misc\\'][\\'vals\\'][\"loss_f\"][0],\\n    [\\'adam\\', \\'adagrad\\'][trial[\\'misc\\'][\\'vals\\'][\"optim\"][0]],\\n    trial[\\'misc\\'][\\'vals\\'][\"lr\"][0],\\n    [True, False][trial[\\'misc\\'][\\'vals\\'][\"batch_norm\"][0]],\\n    [0.0,0.1,0.2,0.3,0.4,0.5][trial[\\'misc\\'][\\'vals\\'][\"dropout\"][0]],\\n    #True][trial[\\'misc\\'][\\'vals\\'][\"shuffle\"][0]],\\n    #[4][trial[\\'misc\\'][\\'vals\\'][\"num_workers\"][0]],\\n    #[10][trial[\\'misc\\'][\\'vals\\'][\"patience\"][0]],\\n    #[50][trial[\\'misc\\'][\\'vals\\'][\"epochs\"][0]]])\\n                       \\n    ])\\n\\n    \\nresults_df=pd.DataFrame(results_df,columns=[\\'loss\\',\\'num_layers\\',\\'scaling_factor\\',#\\'final_activation\\',\\'clip\\',\\n                                 \\'optim\\',\\'lr\\',\\'batch_norm\\',\\'dropout\\']).sort_values(\\'loss\\')\\nresults_df.to_hdf(r\\'/Users/federico comitani/GitHub/sodakick/data/hp_res1_wse.h5\\',key=\\'df\\')'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" config = {\n",
    "        \"num_layers\": hp.choice('num_layers', [1, 2, 3]),\n",
    "        \"num_nodes\": inp.shape[1],\n",
    "        \"scaling_factor\": hp.uniform('scaling_factor', 0.5, 1.5),\n",
    "        \"num_nodes_out\": out.shape[1], \n",
    "        \"final_activation\" : None, #hp.choice('final_activation',[torch.tanh, None]),\n",
    "        \"clip\": False, #hp.choice('clip',[True, False]),\n",
    "        \"batch_size\": 32, #[16, 32, 64, 128]\n",
    "        \"loss_f\": WSE,#hp.choice('loss_f',[WSE, nn.MSELoss()]), #, nn.L1Loss()\n",
    "        \"optim\": hp.choice('optim',['adam', 'adagrad']),\n",
    "        \"lr\": hp.loguniform('lr', np.exp(np.log(1e-4)), np.exp(np.log(1e-1))),\n",
    "        \"batch_norm\": hp.choice('batch_norm',[True, False]),\n",
    "        \"dropout\": hp.choice('dropout',[0.0,0.1,0.2,0.3,0.4,0.5]),#hp.sample_from(lambda _: np.random.uniform(low=0.0, high=.6)),\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"patience\": 10,\n",
    "        \"epochs\": 100\n",
    "    }\n",
    "    \n",
    "btm = run_hopt(config, num_samples=100)\n",
    "\n",
    "results_df=[]\n",
    "\n",
    "for trial in btm.trials:\n",
    "    results_df.append([trial['result']['loss'],\n",
    "    [1,2,3][trial['misc']['vals'][\"num_layers\"][0]],\n",
    "    #[inp.shape[1]][trial['misc']['vals'][\"num_nodes\"][0]],\n",
    "    trial['misc']['vals'][\"scaling_factor\"][0],\n",
    "    #[out.shape[1]][trial['misc']['vals'][\"num_nodes_out\"][0]],\n",
    "    #[torch.tanh, None][trial['misc']['vals'][\"final_activation\"][0]],\n",
    "    #[True, False][trial['misc']['vals'][\"clip\"][0]],\n",
    "    #[16, 32, 64, 128][trial['misc']['vals'][\"batch_size\"][0]],\n",
    "    #trial['misc']['vals'][\"loss_f\"][0],\n",
    "    ['adam', 'adagrad'][trial['misc']['vals'][\"optim\"][0]],\n",
    "    trial['misc']['vals'][\"lr\"][0],\n",
    "    [True, False][trial['misc']['vals'][\"batch_norm\"][0]],\n",
    "    [0.0,0.1,0.2,0.3,0.4,0.5][trial['misc']['vals'][\"dropout\"][0]],\n",
    "    #True][trial['misc']['vals'][\"shuffle\"][0]],\n",
    "    #[4][trial['misc']['vals'][\"num_workers\"][0]],\n",
    "    #[10][trial['misc']['vals'][\"patience\"][0]],\n",
    "    #[50][trial['misc']['vals'][\"epochs\"][0]]])\n",
    "                       \n",
    "    ])\n",
    "\n",
    "    \n",
    "results_df=pd.DataFrame(results_df,columns=['loss','num_layers','scaling_factor',#'final_activation','clip',\n",
    "                                 'optim','lr','batch_norm','dropout']).sort_values('loss')\n",
    "results_df.to_hdf(r'/Users/federico comitani/GitHub/sodakick/data/hp_res1_wse.h5',key='df')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [9:41:19<00:00, 348.80s/trial, best loss: 0.006937485976287952]   \n"
     ]
    }
   ],
   "source": [
    " config = {\n",
    "        \"num_layers\": hp.choice('num_layers', [1, 2, 3]),\n",
    "        \"num_nodes\": inp.shape[1],\n",
    "        \"scaling_factor\": hp.uniform('scaling_factor', 0.5, 1.5),\n",
    "        \"num_nodes_out\": out.shape[1], \n",
    "        \"final_activation\" : hp.choice('final_activation',[torch.tanh, None]),\n",
    "        \"clip\": False, #hp.choice('clip',[True, False]),\n",
    "        \"batch_size\": 32, #[16, 32, 64, 128]\n",
    "        \"loss_f\": nn.MSELoss(),#WSE,#hp.choice('loss_f',[WSE, nn.MSELoss()]), #, nn.L1Loss()\n",
    "        \"optim\": 'adam',#hp.choice('optim',['adam', 'adagrad']),\n",
    "        \"lr\": hp.choice('lr',[0.0001,0.001,.00001]),#hp.loguniform('lr', np.exp(np.log(1e-4)), np.exp(np.log(1e-1))),\n",
    "        \"batch_norm\": hp.choice('batch_norm',[True, False]),\n",
    "        \"dropout\": hp.choice('dropout',[0.0,0.1,0.2,0.3]),#hp.sample_from(lambda _: np.random.uniform(low=0.0, high=.6)),\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"patience\": 10,\n",
    "        \"epochs\": 100\n",
    "    }\n",
    "    \n",
    "btm = run_hopt(config, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/lib/python3.7/site-packages/pandas/core/generic.py:2621: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['final_activation'], dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    "results_df=[]\n",
    "\n",
    "for trial in btm.trials:\n",
    "    results_df.append([trial['result']['loss'],\n",
    "    trial['result']['mse'],\n",
    "    [1,2,3][trial['misc']['vals'][\"num_layers\"][0]],\n",
    "    #[inp.shape[1]][trial['misc']['vals'][\"num_nodes\"][0]],\n",
    "    trial['misc']['vals'][\"scaling_factor\"][0],\n",
    "    #[out.shape[1]][trial['misc']['vals'][\"num_nodes_out\"][0]],\n",
    "    [torch.tanh, None][trial['misc']['vals'][\"final_activation\"][0]],\n",
    "    #[True, False][trial['misc']['vals'][\"clip\"][0]],\n",
    "    #[16, 32, 64, 128][trial['misc']['vals'][\"batch_size\"][0]],\n",
    "    #trial['misc']['vals'][\"loss_f\"][0],\n",
    "    #['adam', 'adagrad'][trial['misc']['vals'][\"optim\"][0]],\n",
    "    [0.0001,0.001,.00001][trial['misc']['vals'][\"lr\"][0]],\n",
    "    [True, False][trial['misc']['vals'][\"batch_norm\"][0]],\n",
    "    [0.0,0.1,0.2,0.3,0.4,0.5][trial['misc']['vals'][\"dropout\"][0]],\n",
    "    #True][trial['misc']['vals'][\"shuffle\"][0]],\n",
    "    #[4][trial['misc']['vals'][\"num_workers\"][0]],\n",
    "    #[10][trial['misc']['vals'][\"patience\"][0]],\n",
    "    #[50][trial['misc']['vals'][\"epochs\"][0]]])\n",
    "                       \n",
    "    ])\n",
    "\n",
    "    \n",
    "results_df=pd.DataFrame(results_df,columns=['loss',\n",
    "                                            'mse',\n",
    "                                            'num_layers',\n",
    "                                            'scaling_factor',\n",
    "                                            'final_activation',\n",
    "                                            #'clip', \n",
    "                                            #'optim', \n",
    "                                            'lr',\n",
    "                                            'batch_norm',\n",
    "                                            'dropout']).sort_values('loss')\n",
    "results_df.to_hdf(r'/Users/federico comitani/GitHub/sodakick/data/hp_res1_mse.h5',key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>scaling_factor</th>\n",
       "      <th>final_activation</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_norm</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>1</td>\n",
       "      <td>1.130029</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>1</td>\n",
       "      <td>1.172128</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935703</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953396</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898520</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>1</td>\n",
       "      <td>1.320935</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.007084</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>3</td>\n",
       "      <td>1.458530</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>3</td>\n",
       "      <td>1.384867</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>3</td>\n",
       "      <td>1.461717</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>3</td>\n",
       "      <td>1.461395</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>3</td>\n",
       "      <td>1.459932</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.007127</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>3</td>\n",
       "      <td>1.495240</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>3</td>\n",
       "      <td>1.360872</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>3</td>\n",
       "      <td>1.403706</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>1</td>\n",
       "      <td>1.275836</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.007135</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>3</td>\n",
       "      <td>1.263690</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.007137</td>\n",
       "      <td>0.007137</td>\n",
       "      <td>3</td>\n",
       "      <td>1.477358</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>3</td>\n",
       "      <td>1.498902</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>3</td>\n",
       "      <td>1.290312</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>3</td>\n",
       "      <td>1.429124</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>3</td>\n",
       "      <td>1.357299</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>1</td>\n",
       "      <td>1.197514</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>3</td>\n",
       "      <td>1.490676</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>1</td>\n",
       "      <td>1.223455</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651795</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>2</td>\n",
       "      <td>1.385166</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>3</td>\n",
       "      <td>1.194662</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>2</td>\n",
       "      <td>1.329229</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.007204</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>3</td>\n",
       "      <td>1.174562</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>3</td>\n",
       "      <td>1.167400</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>1</td>\n",
       "      <td>1.369924</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>1</td>\n",
       "      <td>1.339086</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.007312</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>3</td>\n",
       "      <td>1.081124</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.007316</td>\n",
       "      <td>0.007316</td>\n",
       "      <td>3</td>\n",
       "      <td>1.041840</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>1</td>\n",
       "      <td>1.383513</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>1</td>\n",
       "      <td>1.207151</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>1</td>\n",
       "      <td>1.253669</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.307532</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>3</td>\n",
       "      <td>1.043336</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>1</td>\n",
       "      <td>1.119837</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>1</td>\n",
       "      <td>1.111649</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.007453</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>1</td>\n",
       "      <td>1.104905</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>2</td>\n",
       "      <td>0.783244</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>3</td>\n",
       "      <td>0.968520</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942654</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.007570</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>3</td>\n",
       "      <td>1.422739</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>1</td>\n",
       "      <td>1.245421</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.007730</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>3</td>\n",
       "      <td>1.403322</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>1</td>\n",
       "      <td>1.124747</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>3</td>\n",
       "      <td>0.836570</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>1</td>\n",
       "      <td>1.134110</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.007854</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>1</td>\n",
       "      <td>1.478258</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974650</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>1</td>\n",
       "      <td>1.340574</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926253</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840321</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1</td>\n",
       "      <td>1.303370</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.304891</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.008420</td>\n",
       "      <td>0.008420</td>\n",
       "      <td>1</td>\n",
       "      <td>1.095211</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>1</td>\n",
       "      <td>1.049509</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008515</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>2</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.008541</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699172</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863496</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>3</td>\n",
       "      <td>0.992237</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>1</td>\n",
       "      <td>1.020777</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>1</td>\n",
       "      <td>1.019941</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008736</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547022</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>3</td>\n",
       "      <td>1.223595</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>3</td>\n",
       "      <td>1.499827</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>3</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009485</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671186</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.009873</td>\n",
       "      <td>0.009873</td>\n",
       "      <td>3</td>\n",
       "      <td>1.357279</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.010268</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>2</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.010312</td>\n",
       "      <td>0.010312</td>\n",
       "      <td>3</td>\n",
       "      <td>0.547046</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>3</td>\n",
       "      <td>1.179294</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>2</td>\n",
       "      <td>1.441241</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011726</td>\n",
       "      <td>0.011726</td>\n",
       "      <td>3</td>\n",
       "      <td>1.007290</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825339</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941891</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012388</td>\n",
       "      <td>0.012388</td>\n",
       "      <td>2</td>\n",
       "      <td>1.267911</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>2</td>\n",
       "      <td>0.637938</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.012450</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>2</td>\n",
       "      <td>1.322074</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.012480</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>2</td>\n",
       "      <td>0.594075</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013161</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>2</td>\n",
       "      <td>1.394099</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553881</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>3</td>\n",
       "      <td>1.144513</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>3</td>\n",
       "      <td>0.911720</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>3</td>\n",
       "      <td>1.286754</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>3</td>\n",
       "      <td>1.269162</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.016131</td>\n",
       "      <td>0.016131</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000340</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>3</td>\n",
       "      <td>1.460535</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016607</td>\n",
       "      <td>0.016607</td>\n",
       "      <td>2</td>\n",
       "      <td>0.804755</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.017243</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>3</td>\n",
       "      <td>1.443769</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.017518</td>\n",
       "      <td>0.017518</td>\n",
       "      <td>3</td>\n",
       "      <td>1.223855</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.019034</td>\n",
       "      <td>0.019034</td>\n",
       "      <td>3</td>\n",
       "      <td>1.067040</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>3</td>\n",
       "      <td>1.240889</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.019517</td>\n",
       "      <td>0.019517</td>\n",
       "      <td>2</td>\n",
       "      <td>0.512298</td>\n",
       "      <td>&lt;built-in method tanh of type object at 0x1406...</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>3</td>\n",
       "      <td>1.151423</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.025094</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>3</td>\n",
       "      <td>1.422949</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       mse  num_layers  scaling_factor  \\\n",
       "90  0.006937  0.006937           1        1.130029   \n",
       "93  0.006951  0.006951           1        1.172128   \n",
       "94  0.007002  0.007002           1        0.935703   \n",
       "99  0.007013  0.007013           1        0.953396   \n",
       "96  0.007059  0.007059           1        0.898520   \n",
       "80  0.007068  0.007068           1        1.320935   \n",
       "36  0.007084  0.007084           3        1.458530   \n",
       "75  0.007088  0.007088           3        1.384867   \n",
       "69  0.007094  0.007094           3        1.461717   \n",
       "70  0.007107  0.007107           3        1.461395   \n",
       "71  0.007113  0.007113           3        1.459932   \n",
       "41  0.007127  0.007127           3        1.495240   \n",
       "66  0.007129  0.007129           3        1.360872   \n",
       "68  0.007129  0.007129           3        1.403706   \n",
       "85  0.007134  0.007134           1        1.275836   \n",
       "77  0.007135  0.007135           3        1.263690   \n",
       "65  0.007137  0.007137           3        1.477358   \n",
       "35  0.007141  0.007141           3        1.498902   \n",
       "73  0.007142  0.007142           3        1.290312   \n",
       "34  0.007148  0.007148           3        1.429124   \n",
       "67  0.007156  0.007156           3        1.357299   \n",
       "88  0.007176  0.007176           1        1.197514   \n",
       "37  0.007179  0.007179           3        1.490676   \n",
       "81  0.007180  0.007180           1        1.223455   \n",
       "98  0.007182  0.007182           1        0.651795   \n",
       "78  0.007192  0.007192           2        1.385166   \n",
       "54  0.007193  0.007193           3        1.194662   \n",
       "48  0.007199  0.007199           2        1.329229   \n",
       "38  0.007204  0.007204           3        1.174562   \n",
       "45  0.007205  0.007205           3        1.167400   \n",
       "27  0.007303  0.007303           1        1.369924   \n",
       "25  0.007307  0.007307           1        1.339086   \n",
       "72  0.007312  0.007312           3        1.081124   \n",
       "40  0.007316  0.007316           3        1.041840   \n",
       "26  0.007320  0.007320           1        1.383513   \n",
       "31  0.007363  0.007363           1        1.207151   \n",
       "33  0.007363  0.007363           1        1.253669   \n",
       "29  0.007364  0.007364           1        1.307532   \n",
       "46  0.007379  0.007379           3        1.043336   \n",
       "22  0.007395  0.007395           1        1.119837   \n",
       "24  0.007446  0.007446           1        1.111649   \n",
       "23  0.007453  0.007453           1        1.104905   \n",
       "63  0.007489  0.007489           2        0.783244   \n",
       "43  0.007519  0.007519           3        0.968520   \n",
       "95  0.007531  0.007531           1        0.942654   \n",
       "74  0.007570  0.007570           3        1.422739   \n",
       "89  0.007631  0.007631           1        1.245421   \n",
       "13  0.007706  0.007706           1        0.754190   \n",
       "55  0.007730  0.007730           3        1.403322   \n",
       "21  0.007777  0.007777           1        1.124747   \n",
       "59  0.007825  0.007825           3        0.836570   \n",
       "91  0.007833  0.007833           1        1.134110   \n",
       "14  0.007854  0.007854           1        1.478258   \n",
       "84  0.007941  0.007941           1        0.974650   \n",
       "82  0.007975  0.007975           1        1.340574   \n",
       "32  0.007983  0.007983           1        0.926253   \n",
       "97  0.008250  0.008250           1        0.840321   \n",
       "10  0.008300  0.008300           1        1.303370   \n",
       "83  0.008364  0.008364           1        1.304891   \n",
       "87  0.008420  0.008420           1        1.095211   \n",
       "5   0.008492  0.008492           1        1.049509   \n",
       "11  0.008515  0.008515           2        0.808205   \n",
       "20  0.008541  0.008541           1        0.699172   \n",
       "16  0.008611  0.008611           1        0.863496   \n",
       "18  0.008619  0.008619           3        0.992237   \n",
       "86  0.008674  0.008674           1        1.020777   \n",
       "92  0.008735  0.008735           1        1.019941   \n",
       "1   0.008736  0.008736           1        0.547022   \n",
       "7   0.008755  0.008755           3        1.223595   \n",
       "28  0.009079  0.009079           3        1.499827   \n",
       "61  0.009457  0.009457           3        0.879227   \n",
       "9   0.009485  0.009485           1        0.671186   \n",
       "30  0.009873  0.009873           3        1.357279   \n",
       "50  0.010268  0.010268           2        0.731250   \n",
       "51  0.010312  0.010312           3        0.547046   \n",
       "4   0.010570  0.010570           3        1.179294   \n",
       "15  0.011375  0.011375           2        1.441241   \n",
       "0   0.011726  0.011726           3        1.007290   \n",
       "12  0.011894  0.011894           1        0.825339   \n",
       "2   0.012251  0.012251           2        0.941891   \n",
       "3   0.012388  0.012388           2        1.267911   \n",
       "53  0.012417  0.012417           2        0.637938   \n",
       "60  0.012450  0.012450           2        1.322074   \n",
       "17  0.012480  0.012480           2        0.594075   \n",
       "19  0.013161  0.013161           2        1.394099   \n",
       "8   0.013565  0.013565           2        0.553881   \n",
       "62  0.014399  0.014399           3        1.144513   \n",
       "44  0.014778  0.014778           3        0.911720   \n",
       "42  0.015100  0.015100           3        1.286754   \n",
       "57  0.015142  0.015142           3        1.269162   \n",
       "76  0.016131  0.016131           3        1.000340   \n",
       "52  0.016212  0.016212           3        1.460535   \n",
       "6   0.016607  0.016607           2        0.804755   \n",
       "39  0.017243  0.017243           3        1.443769   \n",
       "64  0.017518  0.017518           3        1.223855   \n",
       "58  0.019034  0.019034           3        1.067040   \n",
       "49  0.019361  0.019361           3        1.240889   \n",
       "56  0.019517  0.019517           2        0.512298   \n",
       "79  0.019802  0.019802           3        1.151423   \n",
       "47  0.025094  0.025094           3        1.422949   \n",
       "\n",
       "                                     final_activation       lr  batch_norm  \\\n",
       "90                                               None  0.00010       False   \n",
       "93  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "94  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "99  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "96  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "80                                               None  0.00001       False   \n",
       "36                                               None  0.00100       False   \n",
       "75                                               None  0.00100       False   \n",
       "69                                               None  0.00100       False   \n",
       "70                                               None  0.00100       False   \n",
       "71                                               None  0.00100       False   \n",
       "41                                               None  0.00100       False   \n",
       "66                                               None  0.00100       False   \n",
       "68                                               None  0.00100       False   \n",
       "85                                               None  0.00001       False   \n",
       "77                                               None  0.00100       False   \n",
       "65                                               None  0.00100       False   \n",
       "35                                               None  0.00100       False   \n",
       "73                                               None  0.00100       False   \n",
       "34                                               None  0.00100       False   \n",
       "67                                               None  0.00100       False   \n",
       "88  <built-in method tanh of type object at 0x1406...  0.00001       False   \n",
       "37                                               None  0.00100       False   \n",
       "81                                               None  0.00001       False   \n",
       "98  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "78  <built-in method tanh of type object at 0x1406...  0.00100       False   \n",
       "54                                               None  0.00100       False   \n",
       "48                                               None  0.00100       False   \n",
       "38                                               None  0.00100       False   \n",
       "45                                               None  0.00100       False   \n",
       "27                                               None  0.00010       False   \n",
       "25                                               None  0.00010       False   \n",
       "72                                               None  0.00100       False   \n",
       "40                                               None  0.00100       False   \n",
       "26                                               None  0.00010       False   \n",
       "31                                               None  0.00010       False   \n",
       "33                                               None  0.00010       False   \n",
       "29                                               None  0.00010       False   \n",
       "46                                               None  0.00100       False   \n",
       "22  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "24  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "23  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "63                                               None  0.00100       False   \n",
       "43                                               None  0.00100       False   \n",
       "95  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "74                                               None  0.00001       False   \n",
       "89                                               None  0.00001       False   \n",
       "13  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "55                                               None  0.00001       False   \n",
       "21  <built-in method tanh of type object at 0x1406...  0.00001       False   \n",
       "59                                               None  0.00100       False   \n",
       "91                                               None  0.00010       False   \n",
       "14  <built-in method tanh of type object at 0x1406...  0.00001       False   \n",
       "84  <built-in method tanh of type object at 0x1406...  0.00001       False   \n",
       "82                                               None  0.00001       False   \n",
       "32                                               None  0.00010       False   \n",
       "97  <built-in method tanh of type object at 0x1406...  0.00010        True   \n",
       "10  <built-in method tanh of type object at 0x1406...  0.00010        True   \n",
       "83                                               None  0.00001        True   \n",
       "87                                               None  0.00001        True   \n",
       "5   <built-in method tanh of type object at 0x1406...  0.00001        True   \n",
       "11                                               None  0.00010        True   \n",
       "20  <built-in method tanh of type object at 0x1406...  0.00001       False   \n",
       "16                                               None  0.00010       False   \n",
       "18  <built-in method tanh of type object at 0x1406...  0.00010        True   \n",
       "86                                               None  0.00001       False   \n",
       "92                                               None  0.00010        True   \n",
       "1   <built-in method tanh of type object at 0x1406...  0.00001        True   \n",
       "7                                                None  0.00001        True   \n",
       "28                                               None  0.00010       False   \n",
       "61  <built-in method tanh of type object at 0x1406...  0.00001        True   \n",
       "9   <built-in method tanh of type object at 0x1406...  0.00100        True   \n",
       "30                                               None  0.00010       False   \n",
       "50                                               None  0.00100        True   \n",
       "51                                               None  0.00100       False   \n",
       "4   <built-in method tanh of type object at 0x1406...  0.00100       False   \n",
       "15  <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "0                                                None  0.00100        True   \n",
       "12                                               None  0.00100        True   \n",
       "2   <built-in method tanh of type object at 0x1406...  0.00100       False   \n",
       "3   <built-in method tanh of type object at 0x1406...  0.00100        True   \n",
       "53                                               None  0.00100        True   \n",
       "60                                               None  0.00100       False   \n",
       "17  <built-in method tanh of type object at 0x1406...  0.00001       False   \n",
       "19  <built-in method tanh of type object at 0x1406...  0.00100        True   \n",
       "8   <built-in method tanh of type object at 0x1406...  0.00010       False   \n",
       "62                                               None  0.00100       False   \n",
       "44                                               None  0.00100        True   \n",
       "42                                               None  0.00100        True   \n",
       "57                                               None  0.00100        True   \n",
       "76                                               None  0.00100       False   \n",
       "52                                               None  0.00001       False   \n",
       "6   <built-in method tanh of type object at 0x1406...  0.00001       False   \n",
       "39                                               None  0.00100        True   \n",
       "64  <built-in method tanh of type object at 0x1406...  0.00100       False   \n",
       "58  <built-in method tanh of type object at 0x1406...  0.00001       False   \n",
       "49                                               None  0.00001       False   \n",
       "56  <built-in method tanh of type object at 0x1406...  0.00100       False   \n",
       "79                                               None  0.00100        True   \n",
       "47                                               None  0.00100        True   \n",
       "\n",
       "    dropout  \n",
       "90      0.0  \n",
       "93      0.0  \n",
       "94      0.0  \n",
       "99      0.0  \n",
       "96      0.0  \n",
       "80      0.0  \n",
       "36      0.0  \n",
       "75      0.0  \n",
       "69      0.0  \n",
       "70      0.0  \n",
       "71      0.0  \n",
       "41      0.0  \n",
       "66      0.0  \n",
       "68      0.0  \n",
       "85      0.0  \n",
       "77      0.0  \n",
       "65      0.0  \n",
       "35      0.0  \n",
       "73      0.0  \n",
       "34      0.0  \n",
       "67      0.0  \n",
       "88      0.0  \n",
       "37      0.0  \n",
       "81      0.0  \n",
       "98      0.0  \n",
       "78      0.0  \n",
       "54      0.0  \n",
       "48      0.0  \n",
       "38      0.0  \n",
       "45      0.0  \n",
       "27      0.1  \n",
       "25      0.1  \n",
       "72      0.0  \n",
       "40      0.0  \n",
       "26      0.1  \n",
       "31      0.1  \n",
       "33      0.1  \n",
       "29      0.1  \n",
       "46      0.0  \n",
       "22      0.1  \n",
       "24      0.1  \n",
       "23      0.1  \n",
       "63      0.0  \n",
       "43      0.0  \n",
       "95      0.1  \n",
       "74      0.0  \n",
       "89      0.1  \n",
       "13      0.1  \n",
       "55      0.0  \n",
       "21      0.1  \n",
       "59      0.0  \n",
       "91      0.2  \n",
       "14      0.2  \n",
       "84      0.1  \n",
       "82      0.2  \n",
       "32      0.2  \n",
       "97      0.2  \n",
       "10      0.3  \n",
       "83      0.0  \n",
       "87      0.0  \n",
       "5       0.2  \n",
       "11      0.0  \n",
       "20      0.1  \n",
       "16      0.3  \n",
       "18      0.0  \n",
       "86      0.3  \n",
       "92      0.3  \n",
       "1       0.2  \n",
       "7       0.0  \n",
       "28      0.1  \n",
       "61      0.0  \n",
       "9       0.1  \n",
       "30      0.1  \n",
       "50      0.0  \n",
       "51      0.0  \n",
       "4       0.1  \n",
       "15      0.3  \n",
       "0       0.0  \n",
       "12      0.3  \n",
       "2       0.2  \n",
       "3       0.3  \n",
       "53      0.2  \n",
       "60      0.3  \n",
       "17      0.0  \n",
       "19      0.3  \n",
       "8       0.1  \n",
       "62      0.2  \n",
       "44      0.2  \n",
       "42      0.0  \n",
       "57      0.0  \n",
       "76      0.2  \n",
       "52      0.3  \n",
       "6       0.2  \n",
       "39      0.0  \n",
       "64      0.3  \n",
       "58      0.2  \n",
       "49      0.3  \n",
       "56      0.3  \n",
       "79      0.3  \n",
       "47      0.2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [2:48:15<00:00, 201.92s/trial, best loss: 0.0036771481122391727]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/lib/python3.7/site-packages/pandas/core/generic.py:2621: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['final_activation'], dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    " config = {\n",
    "        \"num_layers\": hp.choice('num_layers', [1, 2, 3]),\n",
    "        \"num_nodes\": inp.shape[1],\n",
    "        \"scaling_factor\": hp.uniform('scaling_factor', 0.5, 1.5),\n",
    "        \"num_nodes_out\": out.shape[1], \n",
    "        \"final_activation\" : None, #hp.choice('final_activation',[torch.tanh, None]),\n",
    "        \"clip\": False, #hp.choice('clip',[True, False]),\n",
    "        \"batch_size\": 32, #[16, 32, 64, 128]\n",
    "        \"loss_f\": WSE,#WSE,#hp.choice('loss_f',[WSE, nn.MSELoss()]), #, nn.L1Loss()\n",
    "        \"optim\": 'adam',#hp.choice('optim',['adam', 'adagrad']),\n",
    "        \"lr\": 0.0001, #hp.choice('lr',[0.0001,0.001,.01,.1]),#hp.loguniform('lr', np.exp(np.log(1e-4)), np.exp(np.log(1e-1))),\n",
    "        \"batch_norm\": False, #hp.choice('batch_norm',[True, False]),\n",
    "        \"dropout\": 0.0, #hp.choice('dropout',[0.0,0.1,0.2,0.3,0.4,0.5]),#hp.sample_from(lambda _: np.random.uniform(low=0.0, high=.6)),\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"patience\": 10,\n",
    "        \"epochs\": 100\n",
    "    }\n",
    "    \n",
    "btm = run_hopt(config, num_samples=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df=[]\n",
    "\n",
    "for trial in btm.trials:\n",
    "    results_df.append([trial['result']['loss'],\n",
    "    trial['result']['mse'],\n",
    "    [1,2,3][trial['misc']['vals'][\"num_layers\"][0]],\n",
    "    #[inp.shape[1]][trial['misc']['vals'][\"num_nodes\"][0]],\n",
    "    trial['misc']['vals'][\"scaling_factor\"][0],\n",
    "    #[out.shape[1]][trial['misc']['vals'][\"num_nodes_out\"][0]],\n",
    "    #[torch.tanh, None][trial['misc']['vals'][\"final_activation\"][0]],\n",
    "    #[True, False][trial['misc']['vals'][\"clip\"][0]],\n",
    "    #[16, 32, 64, 128][trial['misc']['vals'][\"batch_size\"][0]],\n",
    "    #trial['misc']['vals'][\"loss_f\"][0],\n",
    "    #['adam', 'adagrad'][trial['misc']['vals'][\"optim\"][0]],\n",
    "    #[0.0001,0.001,.01,.1][trial['misc']['vals'][\"lr\"][0]],\n",
    "    #[True, False][trial['misc']['vals'][\"batch_norm\"][0]],\n",
    "    #[0.0,0.1,0.2,0.3,0.4,0.5][trial['misc']['vals'][\"dropout\"][0]],\n",
    "    #True][trial['misc']['vals'][\"shuffle\"][0]],\n",
    "    #[4][trial['misc']['vals'][\"num_workers\"][0]],\n",
    "    #[10][trial['misc']['vals'][\"patience\"][0]],\n",
    "    #[50][trial['misc']['vals'][\"epochs\"][0]]])\n",
    "                       \n",
    "    ])\n",
    "\n",
    " \n",
    "\n",
    "results_df=pd.DataFrame(results_df,columns=['loss',\n",
    "                                            'mse',\n",
    "                                            'num_layers',\n",
    "                                            'scaling_factor',\n",
    "                                            #'final_activation',\n",
    "                                            #'clip', \n",
    "                                            #'optim', \n",
    "                                            #'lr',\n",
    "                                            #'batch_norm',\n",
    "                                            #'dropout'\n",
    "                                            ]).sort_values('loss')\n",
    "results_df.to_hdf(r'/Users/federico comitani/GitHub/sodakick/data/hp_res1_wse.h5',key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.sort_values('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [4:24:36<00:00, 317.53s/trial, best loss: 0.03656742031662128]  \n"
     ]
    }
   ],
   "source": [
    " config = {\n",
    "        \"num_layers\": hp.choice('num_layers', [1, 2, 3]),\n",
    "        \"num_nodes\": inp.shape[1],\n",
    "        \"scaling_factor\": hp.uniform('scaling_factor', 0.5, 1.5),\n",
    "        \"num_nodes_out\": out.shape[1], \n",
    "        \"final_activation\" : None, #hp.choice('final_activation',[torch.tanh, None]),\n",
    "        \"clip\": False, #hp.choice('clip',[True, False]),\n",
    "        \"batch_size\": 32, #[16, 32, 64, 128]\n",
    "        \"loss_f\": WSE,#WSE,#hp.choice('loss_f',[WSE, nn.MSELoss()]), #, nn.L1Loss()\n",
    "        \"optim\": 'adam',#hp.choice('optim',['adam', 'adagrad']),\n",
    "        \"lr\": hp.choice('lr',[0.0001,0.001,.00001]),#hp.loguniform('lr', np.exp(np.log(1e-4)), np.exp(np.log(1e-1))),\n",
    "        \"batch_norm\": False,#hp.choice('batch_norm',[True, False]),\n",
    "        \"dropout\": hp.choice('dropout',[0.0,0.1,0.2,0.3]),#hp.sample_from(lambda _: np.random.uniform(low=0.0, high=.6)),\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"patience\": 10,\n",
    "        \"epochs\": 100\n",
    "    }\n",
    "    \n",
    "btm = run_hopt(config, num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df=[]\n",
    "\n",
    "for trial in btm.trials:\n",
    "    results_df.append([trial['result']['loss'],\n",
    "    [1,2,3][trial['misc']['vals'][\"num_layers\"][0]],\n",
    "    #[inp.shape[1]][trial['misc']['vals'][\"num_nodes\"][0]],\n",
    "    trial['misc']['vals'][\"scaling_factor\"][0],\n",
    "    #[out.shape[1]][trial['misc']['vals'][\"num_nodes_out\"][0]],\n",
    "    #[torch.tanh, None][trial['misc']['vals'][\"final_activation\"][0]],\n",
    "    #[True, False][trial['misc']['vals'][\"clip\"][0]],\n",
    "    #[16, 32, 64, 128][trial['misc']['vals'][\"batch_size\"][0]],\n",
    "    #trial['misc']['vals'][\"loss_f\"][0],\n",
    "    #['adam', 'adagrad'][trial['misc']['vals'][\"optim\"][0]],\n",
    "    [0.0001,0.001,.00001][trial['misc']['vals'][\"lr\"][0]],\n",
    "    #[True, False][trial['misc']['vals'][\"batch_norm\"][0]],\n",
    "    [0.0,0.1,0.2,0.3,0.4,0.5][trial['misc']['vals'][\"dropout\"][0]],\n",
    "    #True][trial['misc']['vals'][\"shuffle\"][0]],\n",
    "    #[4][trial['misc']['vals'][\"num_workers\"][0]],\n",
    "    #[10][trial['misc']['vals'][\"patience\"][0]],\n",
    "    #[50][trial['misc']['vals'][\"epochs\"][0]]])\n",
    "                       \n",
    "    ])\n",
    "\n",
    "    \n",
    "results_df=pd.DataFrame(results_df,columns=['loss','num_layers','scaling_factor',#'final_activation','clip', #'optim', #'batch_norm',\n",
    "                                 'lr','dropout']).sort_values('loss')\n",
    "results_df.to_hdf(r'/Users/federico comitani/GitHub/sodakick/data/hp_res1_wse_adam.h5',key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>scaling_factor</th>\n",
       "      <th>lr</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.036567</td>\n",
       "      <td>3</td>\n",
       "      <td>1.490137</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.036576</td>\n",
       "      <td>3</td>\n",
       "      <td>1.488431</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.036726</td>\n",
       "      <td>3</td>\n",
       "      <td>1.442904</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.036774</td>\n",
       "      <td>3</td>\n",
       "      <td>1.499753</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.036937</td>\n",
       "      <td>3</td>\n",
       "      <td>1.470998</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.036961</td>\n",
       "      <td>1</td>\n",
       "      <td>1.425598</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.036978</td>\n",
       "      <td>1</td>\n",
       "      <td>1.318707</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.037003</td>\n",
       "      <td>3</td>\n",
       "      <td>1.483998</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.037089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.376107</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.037104</td>\n",
       "      <td>2</td>\n",
       "      <td>1.363401</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.037117</td>\n",
       "      <td>3</td>\n",
       "      <td>1.398280</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.037195</td>\n",
       "      <td>2</td>\n",
       "      <td>1.229139</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.037199</td>\n",
       "      <td>1</td>\n",
       "      <td>1.119163</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037230</td>\n",
       "      <td>1</td>\n",
       "      <td>1.187248</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.037747</td>\n",
       "      <td>1</td>\n",
       "      <td>1.332237</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.037961</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583001</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.038065</td>\n",
       "      <td>2</td>\n",
       "      <td>1.429218</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.038269</td>\n",
       "      <td>3</td>\n",
       "      <td>1.238619</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.038273</td>\n",
       "      <td>3</td>\n",
       "      <td>1.189995</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.038431</td>\n",
       "      <td>3</td>\n",
       "      <td>1.160946</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.038814</td>\n",
       "      <td>1</td>\n",
       "      <td>1.068559</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.039047</td>\n",
       "      <td>3</td>\n",
       "      <td>1.465365</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.039620</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501279</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.040085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862686</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.040369</td>\n",
       "      <td>3</td>\n",
       "      <td>1.339371</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.041442</td>\n",
       "      <td>3</td>\n",
       "      <td>0.957840</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.042102</td>\n",
       "      <td>2</td>\n",
       "      <td>1.131568</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.042961</td>\n",
       "      <td>2</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043362</td>\n",
       "      <td>2</td>\n",
       "      <td>1.105378</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.043712</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606050</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.044090</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828867</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.044237</td>\n",
       "      <td>3</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.044576</td>\n",
       "      <td>1</td>\n",
       "      <td>1.496181</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.044862</td>\n",
       "      <td>3</td>\n",
       "      <td>1.296315</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.045234</td>\n",
       "      <td>3</td>\n",
       "      <td>1.278294</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.045560</td>\n",
       "      <td>2</td>\n",
       "      <td>0.661146</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.045862</td>\n",
       "      <td>3</td>\n",
       "      <td>0.739002</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045887</td>\n",
       "      <td>2</td>\n",
       "      <td>0.694960</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.046732</td>\n",
       "      <td>3</td>\n",
       "      <td>1.211798</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.047879</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984080</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.047963</td>\n",
       "      <td>3</td>\n",
       "      <td>1.243797</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048123</td>\n",
       "      <td>1</td>\n",
       "      <td>1.285954</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.054348</td>\n",
       "      <td>3</td>\n",
       "      <td>1.064191</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.054976</td>\n",
       "      <td>3</td>\n",
       "      <td>1.060112</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.055464</td>\n",
       "      <td>3</td>\n",
       "      <td>1.024756</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.058497</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524691</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060774</td>\n",
       "      <td>3</td>\n",
       "      <td>0.897347</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.071539</td>\n",
       "      <td>3</td>\n",
       "      <td>0.570232</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077009</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000934</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.078974</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926159</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  num_layers  scaling_factor       lr  dropout\n",
       "25  0.036567           3        1.490137  0.00010      0.0\n",
       "21  0.036576           3        1.488431  0.00010      0.0\n",
       "5   0.036726           3        1.442904  0.00010      0.0\n",
       "30  0.036774           3        1.499753  0.00010      0.0\n",
       "20  0.036937           3        1.470998  0.00010      0.0\n",
       "36  0.036961           1        1.425598  0.00010      0.1\n",
       "42  0.036978           1        1.318707  0.00010      0.1\n",
       "27  0.037003           3        1.483998  0.00010      0.0\n",
       "22  0.037089           3        1.376107  0.00010      0.0\n",
       "49  0.037104           2        1.363401  0.00010      0.0\n",
       "23  0.037117           3        1.398280  0.00010      0.0\n",
       "13  0.037195           2        1.229139  0.00010      0.0\n",
       "9   0.037199           1        1.119163  0.00010      0.1\n",
       "3   0.037230           1        1.187248  0.00010      0.1\n",
       "11  0.037747           1        1.332237  0.00001      0.1\n",
       "12  0.037961           1        0.583001  0.00010      0.0\n",
       "43  0.038065           2        1.429218  0.00001      0.0\n",
       "44  0.038269           3        1.238619  0.00010      0.0\n",
       "26  0.038273           3        1.189995  0.00010      0.0\n",
       "35  0.038431           3        1.160946  0.00010      0.0\n",
       "6   0.038814           1        1.068559  0.00001      0.2\n",
       "10  0.039047           3        1.465365  0.00001      0.0\n",
       "17  0.039620           1        0.501279  0.00001      0.0\n",
       "40  0.040085           1        0.862686  0.00001      0.1\n",
       "37  0.040369           3        1.339371  0.00100      0.0\n",
       "31  0.041442           3        0.957840  0.00010      0.0\n",
       "39  0.042102           2        1.131568  0.00010      0.2\n",
       "8   0.042961           2        0.778689  0.00010      0.1\n",
       "2   0.043362           2        1.105378  0.00001      0.1\n",
       "15  0.043712           2        0.606050  0.00100      0.0\n",
       "32  0.044090           3        0.828867  0.00010      0.0\n",
       "29  0.044237           3        1.375966  0.00010      0.2\n",
       "46  0.044576           1        1.496181  0.00100      0.0\n",
       "28  0.044862           3        1.296315  0.00010      0.2\n",
       "24  0.045234           3        1.278294  0.00010      0.2\n",
       "14  0.045560           2        0.661146  0.00001      0.0\n",
       "41  0.045862           3        0.739002  0.00100      0.0\n",
       "7   0.045887           2        0.694960  0.00100      0.1\n",
       "48  0.046732           3        1.211798  0.00010      0.2\n",
       "47  0.047879           2        0.984080  0.00001      0.1\n",
       "33  0.047963           3        1.243797  0.00100      0.2\n",
       "0   0.048123           1        1.285954  0.00100      0.2\n",
       "38  0.054348           3        1.064191  0.00010      0.3\n",
       "45  0.054976           3        1.060112  0.00010      0.3\n",
       "34  0.055464           3        1.024756  0.00010      0.3\n",
       "19  0.058497           2        0.524691  0.00100      0.3\n",
       "4   0.060774           3        0.897347  0.00100      0.3\n",
       "16  0.071539           3        0.570232  0.00100      0.3\n",
       "1   0.077009           3        1.000934  0.00001      0.3\n",
       "18  0.078974           3        0.926159  0.00001      0.3"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 1,\n",
       " 'num_nodes': 816,\n",
       " 'scaling_factor': 1.1300291662687787,\n",
       " 'num_nodes_out': 384,\n",
       " 'final_activation': None,\n",
       " 'clip': False,\n",
       " 'batch_size': 32,\n",
       " 'loss_f': MSELoss(),\n",
       " 'optim': 'adam',\n",
       " 'lr': 0.0001,\n",
       " 'batch_norm': False,\n",
       " 'dropout': 0.0,\n",
       " 'shuffle': True,\n",
       " 'num_workers': 4,\n",
       " 'patience': 10,\n",
       " 'epochs': 100}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "conf_final=copy.deepcopy(config)\n",
    "\n",
    "for key,value in results_df.sort_values('loss').iloc[0].to_dict().items():\n",
    "    if key in conf_final:\n",
    "        conf_final[key]=value\n",
    "        \n",
    "conf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_alone(config, model=Net, silent=True, checkpoint_dir=None):\n",
    "    \n",
    "    \n",
    "    phases = ['train','val']\n",
    "\n",
    "    #x_train, x_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "\n",
    "    training_set = matchesDataset(x_train, y_train)\n",
    "    trainBatch = torch.utils.data.DataLoader(training_set, batch_size=config['batch_size'], shuffle=config['shuffle'], num_workers=config['num_workers'])\n",
    "\n",
    "    validation_set = matchesDataset(x_test, y_test)\n",
    "    valBatch = torch.utils.data.DataLoader(validation_set, batch_size=config['batch_size'], shuffle=config['shuffle'], num_workers=config['num_workers'])\n",
    "\n",
    "    earlStop = EarlyStopping(patience=int(config['patience']), keepBest=True)\n",
    "\n",
    "    net = model(int(config['num_layers']), int(config['num_nodes']), config['scaling_factor'], \n",
    "                int(config['num_nodes_out']), config['final_activation'], config['batch_norm'], config['dropout'])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    if config['optim']=='adam':\n",
    "        optimizer = Adam(net.parameters(), lr=config['lr'])\n",
    "    elif config['optim']=='adagrad':\n",
    "        optimizer = Adagrad(net.parameters(), lr=config['lr'])\n",
    "    else:\n",
    "        print('optim error')\n",
    "        return\n",
    "\n",
    "\n",
    "    losses=[[],[]]\n",
    "    mses=[]\n",
    "    diffs=[]\n",
    "    exit=False\n",
    "\n",
    "    for epoch in tqdm(range(config['epochs']), desc='Epoch'):\n",
    "    #for epoch in range(config['epochs']):\n",
    "\n",
    "        if exit:\n",
    "            break\n",
    "\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                net.train(True) \n",
    "\n",
    "                \"\"\" Run the training of the model. \"\"\"    \n",
    "\n",
    "                losses_batch=[]\n",
    "                for batchNum, batch in enumerate(trainBatch):\n",
    "\n",
    "                    x = batch[0]\n",
    "                    y = batch[1]\n",
    "\n",
    "                    \"\"\" Move batches to GPU if available. \"\"\"\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "\n",
    "                    \"\"\" Core of training. \"\"\"\n",
    "\n",
    "                    loss = config['loss_f'](net(x), y)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    if config['clip']:\n",
    "                        net.clp()\n",
    "\n",
    "                    losses_batch.append(loss)\n",
    "\n",
    "                \"\"\" Early stop check. \"\"\"\n",
    "\n",
    "                earlStop(loss, net)\n",
    "                finalepoch = epoch\n",
    "\n",
    "                if earlStop.earlyStop:\n",
    "\n",
    "                    if not silent:\n",
    "                        print('Limit loss improvement reached, stopping the training.')\n",
    "\n",
    "                    exit=True \n",
    "\n",
    "                #losses[0].append(torch.mean(torch.stack(losses_batch)).detach().cpu().numpy())\n",
    "            else:\n",
    "                net.train(False)\n",
    "                net.eval()\n",
    "\n",
    "                val_loss=0\n",
    "                val_mse=0\n",
    "\n",
    "                losses_batch=[]\n",
    "                for batchNum, batch in enumerate(valBatch):\n",
    "\n",
    "                    x = batch[0]\n",
    "                    y = batch[1]\n",
    "\n",
    "                    \"\"\" Move batches to GPU if available. \"\"\"\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "\n",
    "                    \"\"\" Core of training. \"\"\"\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    output=net(x)\n",
    "                    target=y\n",
    "                    loss = config['loss_f'](output, target)\n",
    "\n",
    "                    #losses_batch.append(loss)\n",
    "                    val_loss+=loss.detach().numpy()\n",
    "                    val_mse+=nn.MSELoss()(output, target).detach().numpy()\n",
    "\n",
    "                #losses[1].append(torch.mean(torch.stack(losses_batch)).detach().cpu().numpy())\n",
    "\n",
    "                #with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                #    path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "                #    torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "                #tune.report(loss=(val_loss/batchNum), mse=(val_mse/batchNum))\n",
    "                #tune.report(loss=torch.mean(torch.stack(losses_batch)))\n",
    "\n",
    "    return net, val_loss/batchNum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 24/100 [01:14<03:54,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "net,loss=train_alone(conf_final, model=Net, silent=True, checkpoint_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=net(torch.Tensor(inp)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
      "0      1        1             2          0          0              2      4\n",
      "1      2        1             2          0          0              2      4\n",
      "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
      "0      3        3             4          0          0              4      3\n",
      "1      4        2             3          0          0              3      1\n"
     ]
    }
   ],
   "source": [
    "i=15000\n",
    "cats=['minutes','goals','assists','cards_yellow','cards_red','own_goals']+['goals_against','saves']\n",
    "\n",
    "reframe, byteamframe = revert_output(pred[i])\n",
    "print(byteamframe.astype(int))\n",
    "reframe, byteamframe = revert_output(out[i])\n",
    "print(byteamframe.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 25/100 [01:51<05:35,  4.47s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df=pd.read_hdf(r'/Users/federico comitani/GitHub/sodakick/data/hp_res1_adam.h5',key='df')\n",
    "\n",
    "import copy\n",
    "\n",
    "conf_final=copy.deepcopy(config)\n",
    "\n",
    "for key,value in results_df.sort_values('loss').iloc[0].to_dict().items():\n",
    "    if key in conf_final:\n",
    "        conf_final[key]=value\n",
    "        \n",
    "conf_final\n",
    "\n",
    "net,loss=train_alone(conf_final, model=Net, silent=True, checkpoint_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=net(torch.Tensor(inp)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
      "0      3        2             6          0          0              4      6\n",
      "1      5        4             5          0          0              3      5\n",
      "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
      "0      1        1             4          0          0              1      6\n",
      "1      1        1             1          0          0              1      1\n"
     ]
    }
   ],
   "source": [
    "i=-20000\n",
    "cats=['minutes','goals','assists','cards_yellow','cards_red','own_goals']+['goals_against','saves']\n",
    "\n",
    "reframe, byteamframe = revert_output(pred[i])\n",
    "print(byteamframe.astype(int))\n",
    "reframe, byteamframe = revert_output(out[i])\n",
    "print(byteamframe.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  31%|███       | 31/100 [02:55<06:31,  5.67s/it]\n"
     ]
    }
   ],
   "source": [
    "results_df=pd.read_hdf(r'/Users/federico comitani/GitHub/sodakick/data/hp_res1_wse.h5',key='df')\n",
    "\n",
    "import copy\n",
    "\n",
    "conf_final=copy.deepcopy(config)\n",
    "\n",
    "for key,value in results_df.sort_values('loss').iloc[0].to_dict().items():\n",
    "    if key in conf_final:\n",
    "        conf_final[key]=value\n",
    "        \n",
    "conf_final\n",
    "\n",
    "net,loss=train_alone(conf_final, model=Net, silent=True, checkpoint_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=net(torch.Tensor(inp)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
      "0      4        3             5          0          0              2      4\n",
      "1      2        2             5          0          0              3      6\n",
      "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
      "0      3        2             2          0          0              0      1\n",
      "1      0        0             0          0          0              3      2\n"
     ]
    }
   ],
   "source": [
    "i=10000\n",
    "cats=['minutes','goals','assists','cards_yellow','cards_red','own_goals']+['goals_against','saves']\n",
    "\n",
    "reframe, byteamframe = revert_output(pred[i])\n",
    "print(byteamframe.astype(int))\n",
    "reframe, byteamframe = revert_output(out[i])\n",
    "print(byteamframe.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
