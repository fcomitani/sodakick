{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys, getopt\n",
    "import csv\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import umap\n",
    "from sklearn.decomposition import TruncatedSVD as tsvd\n",
    "\n",
    "def nearZeroVarDropAuto(df,thresh=0.99):\n",
    "    vVal=df.var(axis=0).values\n",
    "    cs=pd.Series(vVal).sort_values(ascending=False).cumsum()\n",
    "    remove=cs[cs>cs.values[-1]*thresh].index.values\n",
    "    return df.drop(df.columns[remove],axis=1)\n",
    "\n",
    "%run SodaKick_download_functions.ipynb\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import SGD, Adagrad, Adam, Adagrad\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    \"\"\" Stops the training if loss doesn't improve after a given number of epochs. \"\"\"\n",
    "\n",
    "    def __init__(self, patience=3, epsilon=1e-5, keepBest=True, silent=True):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs without change before stopping the learning (default 3).\n",
    "            epsilon (float): Minimum change in loss to be considered for early stopping (default 1e-5).\n",
    "            keepBest (bool): Keep track of the best model (memory consuming).\n",
    "        \"\"\"\n",
    "\n",
    "        self.patience = patience\n",
    "        self.epsilon = epsilon\n",
    "        self.counter = 0\n",
    "        \n",
    "        self.bestScore = np.inf\n",
    "     \n",
    "        self.keepBest = keepBest \n",
    "        self.bestModel = None\n",
    "\n",
    "        self.earlyStop = False\n",
    "        self.silent = silent\n",
    "\n",
    "    def __call__(self, loss, model):\n",
    "\n",
    "\n",
    "        \"\"\" Evaluate the loss change between epochs and activates early stop if below epsilon.\n",
    "\n",
    "        Args:\n",
    "            loss (float): current loss.\n",
    "            model (torch model): the current model.\n",
    "        \"\"\"\n",
    "\n",
    "        if loss > self.bestScore - self.epsilon:\n",
    "\n",
    "            self.counter += 1\n",
    "            if not self.silent:\n",
    "                print('EarlyStopping counter: {:d}/{:d}'.format(self.counter,self.patience))\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.earlyStop = True\n",
    "\n",
    "        else:   \n",
    "\n",
    "            self.counter = 0\n",
    "            self.bestScore = loss\n",
    "\n",
    "            if self.keepBest:\n",
    "                self.bestModel = copy.deepcopy(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class matchesDataset(Dataset):\n",
    "\n",
    "    \"\"\" Extend pytorch Dataset class to include cleaning and training set creation, \"\"\"\n",
    "    \n",
    "    def __init__(self, matches, results):\n",
    "\n",
    "        self.matches = torch.tensor(matches, dtype=torch.float32)\n",
    "        self.results = torch.tensor(results, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        \"\"\" Returns the len of the training sample. \"\"\"\n",
    "        \n",
    "        return len(self.matches)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index): \n",
    "\n",
    "        \"\"\" Returns a word, a context word and a list of negative words for training for a given index. \n",
    "\n",
    "        Args:\n",
    "            index (int): index for the word selection.\n",
    "\n",
    "        Returns:\n",
    "            (string, string, list of strings): selected word, context word and a randomly drawn list \n",
    "                                               of negative words.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.matches[index], self.results[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/quirky-keras-custom-and-asymmetric-loss-functions-for-keras-in-r-a8b5271171fe\n",
    "def WSE(output, target, a=1.5, b=.5):\n",
    "    loss = torch.mean(a*torch.minimum(torch.zeros(output.shape[1]),output - target)**2+\\\n",
    "                      b*torch.maximum(torch.zeros(output.shape[1]),output - target)**2)      \n",
    "    return loss\n",
    "\n",
    "def WSEl1(output, target, a=1.5, b=.5):\n",
    "    loss = torch.mean(a*torch.abs(torch.minimum(torch.zeros(output.shape[1]),output - target))+\\\n",
    "                      b*torch.abs(torch.maximum(torch.zeros(output.shape[1]),output - target)))      \n",
    "    return loss\n",
    "\n",
    "def WSE2(output, target, a=1.5, b=.5):\n",
    "    loss = np.mean(a*np.minimum(np.zeros(output.shape[0]),output - target)**2+\\\n",
    "                      b*np.maximum(np.zeros(output.shape[0]),output - target)**2)      \n",
    "    return loss\n",
    "\n",
    "def WSEl12(output, target, a=1.5, b=.5):\n",
    "    loss = np.mean(a*np.abs(np.minimum(np.zeros(output.shape[0]),output - target))+\\\n",
    "                      b*np.abs(np.maximum(np.zeros(output.shape[0]),output - target)))      \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_inp_2a.pkl', 'rb') as pk:\n",
    "    inp=pickle.load(pk)\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_out_2a.pkl', 'rb') as pk:\n",
    "    out=pickle.load(pk)     \n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_inp_2b.pkl', 'rb') as pk:\n",
    "    inpb=pickle.load(pk)\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_out_2b.pkl', 'rb') as pk:\n",
    "    outb=pickle.load(pk)     \n",
    "\n",
    "inp=np.concatenate([inp,inpb])\n",
    "out=np.concatenate([out,outb])\n",
    "\n",
    "def normalize_mins(vec):\n",
    "    for i in range(vec.shape[0]):\n",
    "        vec[i][::8]=vec[i][::8]/90\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def NormalizeMatrix(data):   \n",
    "    for i in range(data.shape[1]):\n",
    "        data[:,i] = NormalizeData(data[:,i])\n",
    "        \n",
    "NormalizeMatrix(inp)\n",
    "np.nan_to_num(inp, copy=False)\n",
    "\n",
    "normalize_mins(out)\n",
    "\n",
    "#scaler = preprocessing.StandardScaler().fit(inp)\n",
    "#inp = scaler.transform(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "         inp, out, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_layers, num_nodes, scaling_factor, num_nodes_out, final_activation):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc = []\n",
    "        self.lr = []\n",
    "        self.fact = final_activation\n",
    "        self.nl = num_layers\n",
    "        power=0\n",
    "        \n",
    "        for i in range(self.nl):\n",
    "            self.fc.append(nn.Linear(int(num_nodes*(scaling_factor**power)), int(num_nodes*(scaling_factor**(power+1)))))\n",
    "            self.lr.append(nn.LeakyReLU())\n",
    "            power+=1\n",
    "        \n",
    "        self.oupt = nn.Linear(int(num_nodes*(scaling_factor**power)), int(num_nodes_out))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x\n",
    "        for i in range(self.nl):\n",
    "            z = self.lr[i](self.fc[i](z))\n",
    "        z = self.oupt(self.fact(z))\n",
    "        return z\n",
    "    \n",
    "    def clp(self):\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.nl):\n",
    "                self.fc[i].weight.copy_ (self.fc[i].weight.data.clamp(min=0)) \n",
    "            self.oupt.weight.copy_ (self.oupt.weight.data.clamp(min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, model=Net, silent=True, checkpoint_dir=None):\n",
    "    \n",
    "    phases = ['train','val']\n",
    "    \n",
    "    #x_train, x_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "    \n",
    "    training_set = matchesDataset(x_train, y_train)\n",
    "    trainBatch = torch.utils.data.DataLoader(training_set, batch_size=config['batch_size'], shuffle=config['shuffle'], num_workers=config['num_workers'])\n",
    "\n",
    "    validation_set = matchesDataset(x_test, y_test)\n",
    "    valBatch = torch.utils.data.DataLoader(validation_set, batch_size=config['batch_size'], shuffle=config['shuffle'], num_workers=config['num_workers'])\n",
    "\n",
    "    earlStop = EarlyStopping(patience=config['patience'], keepBest=False)\n",
    "    \n",
    "    net = model(config['num_layers'], config['num_nodes'], config['scaling_factor'], \n",
    "                config['num_nodes_out'], config['final_activation'])\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    if config['optim']=='adam':\n",
    "        optimizer = Adam(net.parameters(), lr=config['lr'])\n",
    "    elif config['optim']=='adagrad':\n",
    "        optimizer = Adagrad(net.parameters(), lr=config['lr'])\n",
    "    else:\n",
    "        print('optim error')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    losses=[[],[]]\n",
    "    mses=[]\n",
    "    diffs=[]\n",
    "    exit=False\n",
    "    \n",
    "    #for epoch in tqdm(range(epochs), desc='Epoch'):\n",
    "    for epoch in range(config['epochs']):\n",
    "\n",
    "        if exit:\n",
    "            break\n",
    "            \n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                net.train(True) \n",
    "\n",
    "                \"\"\" Run the training of the model. \"\"\"    \n",
    "\n",
    "                losses_batch=[]\n",
    "                for batchNum, batch in enumerate(trainBatch):\n",
    "\n",
    "                    x = batch[0]\n",
    "                    y = batch[1]\n",
    "\n",
    "                    \"\"\" Move batches to GPU if available. \"\"\"\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "\n",
    "                    \"\"\" Core of training. \"\"\"\n",
    "                    \n",
    "                    loss = config['loss_f'](net(x), y)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    if config['clip']:\n",
    "                        net.clp()\n",
    "\n",
    "                    losses_batch.append(loss)\n",
    "\n",
    "                \"\"\" Early stop check. \"\"\"\n",
    "\n",
    "                earlStop(loss, net)\n",
    "                finalepoch = epoch\n",
    "                \n",
    "                if earlStop.earlyStop:\n",
    "\n",
    "                    if not silent:\n",
    "                        print('Limit loss improvement reached, stopping the training.')\n",
    "                        \n",
    "                    exit=True \n",
    "                \n",
    "                #losses[0].append(torch.mean(torch.stack(losses_batch)).detach().cpu().numpy())\n",
    "            else:\n",
    "                net.train(False)\n",
    "                net.eval()\n",
    "                \n",
    "                val_loss=0\n",
    "                val_mse=0\n",
    "      \n",
    "                losses_batch=[]\n",
    "                for batchNum, batch in enumerate(valBatch):\n",
    "\n",
    "                    x = batch[0]\n",
    "                    y = batch[1]\n",
    "\n",
    "                    \"\"\" Move batches to GPU if available. \"\"\"\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "\n",
    "                    \"\"\" Core of training. \"\"\"\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    output=net(x)\n",
    "                    target=y\n",
    "                    loss = config['loss_f'](output, target)\n",
    "\n",
    "                    #losses_batch.append(loss)\n",
    "                    val_loss+=loss.detach().numpy()\n",
    "                    val_mse+=nn.MSELoss()(output, target).detach().numpy()\n",
    "                    \n",
    "                #losses[1].append(torch.mean(torch.stack(losses_batch)).detach().cpu().numpy())\n",
    "                \n",
    "                with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                    path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "                    torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "                tune.report(loss=(val_loss/batchNum), mse=(val_mse/batchNum))\n",
    "                #tune.report(loss=torch.mean(torch.stack(losses_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_output(output,lineup=None):\n",
    "\n",
    "    reframe=pd.DataFrame(output.reshape(50,8),\n",
    "                 columns=['minutes','goals','assists','cards_yellow','cards_red','own_goals','goals_against','saves'])\n",
    "    \n",
    "    reframe[reframe<0] = 0\n",
    "    if lineup is not None:\n",
    "        reframe.index=lineup\n",
    "        reframe.drop([x for x in reframe.index if x.startswith('dummy')], axis=0, inplace=True)\n",
    "        \n",
    "    reframe['minutes']*=90\n",
    "    byteamframe=pd.concat([reframe.iloc[:25,:].sum(axis=0),reframe.iloc[25:,:].sum(axis=0)], axis=1).T\n",
    "    \n",
    "    return reframe, byteamframe[byteamframe.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline WSE: 0.230\n",
      "Baseline WSE l1: 0.139\n",
      "Baseline MSE: 0.153\n",
      "Baseline MSE l1: 0.092\n",
      "-18.0\n",
      "16.566666666666666\n",
      "2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "print('Baseline WSE: {:.3f}'.format(WSE2(np.array([0]*out[0].shape[0]),out[0])))\n",
    "print('Baseline WSE l1: {:.3f}'.format(WSEl12(np.array([0]*out[0].shape[0]),out[0])))\n",
    "print('Baseline MSE: {:.3f}'.format(WSE2(np.array([0]*out[0].shape[0]),out[0], a=1, b=1)))\n",
    "print('Baseline MSE l1: {:.3f}'.format(WSEl12(np.array([0]*out[0].shape[0]),out[0], a=1, b=1)))\n",
    "\n",
    "print((out[1]-out[10]).sum())\n",
    "print((out[50]-out[60]).sum())\n",
    "print((out[100]-out[110]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rtune(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    \n",
    "\n",
    "    config = {\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"num_nodes\": inp.shape[1],\n",
    "        \"scaling_factor\": tune.sample_from(lambda _: np.random.uniform(low=0.5, high=1.0001)),\n",
    "        \"num_nodes_out\": out.shape[1], \n",
    "        \"final_activation\" : torch.tanh,\n",
    "        \"clip\": tune.choice([True, False]),\n",
    "        \"batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "        \"loss_f\": tune.choice([WSE, nn.MSELoss(), nn.L1Loss()]),\n",
    "        \"optim\": tune.choice(['adam', 'adagrad']),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"patience\": 10,\n",
    "        \"epochs\": 50\n",
    "    }\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"mse\",#\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    \n",
    "    reporter = CLIReporter(\n",
    "        metric_columns=[\"loss\", \"mse\", \"training_iteration\"])\n",
    "    \n",
    "    result = tune.run(\n",
    "        train,\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation mse: {}\".format(\n",
    "        best_trial.last_result[\"mse\"]))\n",
    "\n",
    "    best_trained_model = Net(best_trial.config['num_layers'], \n",
    "                             best_trial.config['num_nodes'], best_trial.config['scaling_factor'], \n",
    "                             best_trial.config['num_nodes_out'], best_trial.config['final_activation'])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    return best_trained_model\n",
    "    #test_acc = test_accuracy(best_trained_model, device)\n",
    "    #print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:03,613\tWARNING worker.py:1115 -- Warning: The actor ImplicitFunc has size 84676350 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n",
      "2021-05-26 17:18:03,700\tWARNING util.py:162 -- The `start_trial` operation took 0.652 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 8.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (49 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+-------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+\n",
      "| Trial name        | status   | loc   |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |\n",
      "|-------------------+----------+-------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------|\n",
      "| train_d0405_00000 | RUNNING  |       |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |\n",
      "| train_d0405_00001 | PENDING  |       |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |\n",
      "| train_d0405_00002 | PENDING  |       |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |\n",
      "| train_d0405_00003 | PENDING  |       |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |\n",
      "| train_d0405_00004 | PENDING  |       |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |\n",
      "| train_d0405_00005 | PENDING  |       |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |\n",
      "| train_d0405_00006 | PENDING  |       |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |\n",
      "| train_d0405_00007 | PENDING  |       |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |\n",
      "| train_d0405_00008 | PENDING  |       |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |\n",
      "| train_d0405_00009 | PENDING  |       |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |\n",
      "| train_d0405_00010 | PENDING  |       |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |\n",
      "| train_d0405_00011 | PENDING  |       |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |\n",
      "| train_d0405_00012 | PENDING  |       |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |\n",
      "| train_d0405_00013 | PENDING  |       |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |\n",
      "| train_d0405_00014 | PENDING  |       |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |\n",
      "| train_d0405_00015 | PENDING  |       |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |\n",
      "| train_d0405_00016 | PENDING  |       |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |\n",
      "| train_d0405_00017 | PENDING  |       |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |\n",
      "| train_d0405_00018 | PENDING  |       |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |\n",
      "| train_d0405_00019 | PENDING  |       |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |\n",
      "+-------------------+----------+-------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:05,021\tWARNING util.py:162 -- The `start_trial` operation took 0.730 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:05,702\tWARNING util.py:162 -- The `start_trial` operation took 0.679 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-18-08\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.20462480577684583\n",
      "  mse: 0.11665591260506994\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.398634910583496\n",
      "  time_this_iter_s: 2.398634910583496\n",
      "  time_total_s: 2.398634910583496\n",
      "  timestamp: 1622063888\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (46 PENDING, 4 RUNNING)\n",
      "+-------------------+----------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------+\n",
      "| Trial name        | status   | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |     loss |      mse |   training_iteration |\n",
      "|-------------------+----------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING  | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.204625 | 0.116656 |                    1 |\n",
      "| train_d0405_00001 | RUNNING  |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |          |          |                      |\n",
      "| train_d0405_00002 | RUNNING  |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |          |          |                      |\n",
      "| train_d0405_00003 | RUNNING  |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |          |          |                      |\n",
      "| train_d0405_00004 | PENDING  |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |          |          |                      |\n",
      "| train_d0405_00005 | PENDING  |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |          |          |                      |\n",
      "| train_d0405_00006 | PENDING  |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |          |          |                      |\n",
      "| train_d0405_00007 | PENDING  |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |          |          |                      |\n",
      "| train_d0405_00008 | PENDING  |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |          |          |                      |\n",
      "| train_d0405_00009 | PENDING  |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |          |          |                      |\n",
      "| train_d0405_00010 | PENDING  |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |          |          |                      |\n",
      "| train_d0405_00011 | PENDING  |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |          |          |                      |\n",
      "| train_d0405_00012 | PENDING  |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |          |          |                      |\n",
      "| train_d0405_00013 | PENDING  |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |          |          |                      |\n",
      "| train_d0405_00014 | PENDING  |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |          |          |                      |\n",
      "| train_d0405_00015 | PENDING  |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |          |          |                      |\n",
      "| train_d0405_00016 | PENDING  |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |          |          |                      |\n",
      "| train_d0405_00017 | PENDING  |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |          |          |                      |\n",
      "| train_d0405_00018 | PENDING  |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |          |          |                      |\n",
      "| train_d0405_00019 | PENDING  |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |          |          |                      |\n",
      "+-------------------+----------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:10,308\tWARNING util.py:162 -- The `start_trial` operation took 0.561 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:11,021\tWARNING util.py:162 -- The `start_trial` operation took 0.606 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:11,909\tWARNING util.py:162 -- The `start_trial` operation took 0.782 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:12,676\tWARNING util.py:162 -- The `start_trial` operation took 0.656 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:14,193\tWARNING util.py:162 -- The `start_trial` operation took 1.406 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-18-13\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.26447202832925887\n",
      "  mse: 0.15042695083788463\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.169759035110474\n",
      "  time_this_iter_s: 4.7711241245269775\n",
      "  time_total_s: 7.169759035110474\n",
      "  timestamp: 1622063893\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.15042695083788463 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (46 PENDING, 4 RUNNING)\n",
      "+-------------------+----------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------+\n",
      "| Trial name        | status   | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |     loss |      mse |   training_iteration |\n",
      "|-------------------+----------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING  | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.264472 | 0.150427 |                    2 |\n",
      "| train_d0405_00001 | RUNNING  |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |          |          |                      |\n",
      "| train_d0405_00002 | RUNNING  |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |          |          |                      |\n",
      "| train_d0405_00003 | RUNNING  |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |          |          |                      |\n",
      "| train_d0405_00004 | PENDING  |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |          |          |                      |\n",
      "| train_d0405_00005 | PENDING  |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |          |          |                      |\n",
      "| train_d0405_00006 | PENDING  |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |          |          |                      |\n",
      "| train_d0405_00007 | PENDING  |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |          |          |                      |\n",
      "| train_d0405_00008 | PENDING  |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |          |          |                      |\n",
      "| train_d0405_00009 | PENDING  |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |          |          |                      |\n",
      "| train_d0405_00010 | PENDING  |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |          |          |                      |\n",
      "| train_d0405_00011 | PENDING  |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |          |          |                      |\n",
      "| train_d0405_00012 | PENDING  |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |          |          |                      |\n",
      "| train_d0405_00013 | PENDING  |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |          |          |                      |\n",
      "| train_d0405_00014 | PENDING  |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |          |          |                      |\n",
      "| train_d0405_00015 | PENDING  |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |          |          |                      |\n",
      "| train_d0405_00016 | PENDING  |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |          |          |                      |\n",
      "| train_d0405_00017 | PENDING  |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |          |          |                      |\n",
      "| train_d0405_00018 | PENDING  |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |          |          |                      |\n",
      "| train_d0405_00019 | PENDING  |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |          |          |                      |\n",
      "+-------------------+----------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:15,287\tWARNING util.py:162 -- The `start_trial` operation took 1.027 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:16,246\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00003:\n",
      "  date: 2021-05-26_17-18-14\n",
      "  done: true\n",
      "  experiment_id: 28fed56410564ee889e1da434899fd65\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.4801075195982343\n",
      "  mse: 0.4569682606628963\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88368\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.543630838394165\n",
      "  time_this_iter_s: 4.543630838394165\n",
      "  time_total_s: 4.543630838394165\n",
      "  timestamp: 1622063894\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:16,894\tWARNING util.py:162 -- The `start_trial` operation took 0.632 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:16,909\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00001:\n",
      "  date: 2021-05-26_17-18-15\n",
      "  done: true\n",
      "  experiment_id: 9a25d283ff244373a2db02e5e9c3745e\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.7244432484402376\n",
      "  mse: 0.8466525898260229\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87910\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 8.507484197616577\n",
      "  time_this_iter_s: 8.507484197616577\n",
      "  time_total_s: 8.507484197616577\n",
      "  timestamp: 1622063895\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:17,502\tWARNING util.py:162 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:18,014\tWARNING util.py:162 -- The `process_trial_save` operation took 0.509 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:19,014\tWARNING util.py:162 -- The `start_trial` operation took 0.998 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:19,588\tWARNING util.py:162 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-18-18\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.26085840236572994\n",
      "  mse: 0.1502975441870235\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 12.436723947525024\n",
      "  time_this_iter_s: 5.266964912414551\n",
      "  time_total_s: 12.436723947525024\n",
      "  timestamp: 1622063898\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.4/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.15042695083788463 | Iter 1.000: -0.4569682606628963\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (45 PENDING, 4 RUNNING, 1 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |     loss |      mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.260858 | 0.150298 |                    3 |\n",
      "| train_d0405_00001 | RUNNING    | 192.168.1.5:87910 |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443 | 0.846653 |                    1 |\n",
      "| train_d0405_00002 | RUNNING    |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |          |          |                      |\n",
      "| train_d0405_00004 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |          |          |                      |\n",
      "| train_d0405_00005 | PENDING    |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |          |          |                      |\n",
      "| train_d0405_00006 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |          |          |                      |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |          |          |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |          |          |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |          |          |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |          |          |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |          |          |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |          |          |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |          |          |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |          |          |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |          |          |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |          |          |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |          |          |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |          |          |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |          |          |                      |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108 | 0.456968 |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:21,166\tWARNING util.py:162 -- The `start_trial` operation took 0.714 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-18-20\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.06344199086375096\n",
      "  mse: 0.0776762983378242\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 11.713373184204102\n",
      "  time_this_iter_s: 11.713373184204102\n",
      "  time_total_s: 11.713373184204102\n",
      "  timestamp: 1622063900\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:22,382\tWARNING util.py:162 -- The `process_trial_save` operation took 0.585 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:22,921\tWARNING util.py:162 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:24,273\tWARNING util.py:162 -- The `start_trial` operation took 0.905 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-18-25\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.23120855894826708\n",
      "  mse: 0.1277278381444159\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 19.172168970108032\n",
      "  time_this_iter_s: 6.735445022583008\n",
      "  time_total_s: 19.172168970108032\n",
      "  timestamp: 1622063905\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: -0.1277278381444159 | Iter 2.000: -0.15042695083788463 | Iter 1.000: -0.28681208663398317\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (44 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |     loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+-----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.231209 | 0.127728  |                    4 |\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.063442 | 0.0776763 |                    1 |\n",
      "| train_d0405_00004 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |          |           |                      |\n",
      "| train_d0405_00005 | RUNNING    |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |          |           |                      |\n",
      "| train_d0405_00006 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |          |           |                      |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |          |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |          |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |          |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |          |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |          |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |          |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |          |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |          |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |          |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |          |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |          |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |          |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |          |           |                      |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443 | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108 | 0.456968  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:26,045\tWARNING util.py:162 -- The `start_trial` operation took 0.609 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:26,643\tWARNING util.py:162 -- The `process_trial_save` operation took 0.594 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:27,502\tWARNING util.py:162 -- The `start_trial` operation took 0.857 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00004:\n",
      "  date: 2021-05-26_17-18-30\n",
      "  done: false\n",
      "  experiment_id: ffb37331e7f24a78afe4b4f9ccba24ba\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.06516481664250878\n",
      "  mse: 0.07982335432487375\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88373\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.725322008132935\n",
      "  time_this_iter_s: 7.725322008132935\n",
      "  time_total_s: 7.725322008132935\n",
      "  timestamp: 1622063910\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00004\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:30,753\tWARNING util.py:162 -- The `start_trial` operation took 0.655 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:31,345\tWARNING util.py:162 -- The `process_trial_save` operation took 0.587 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: -0.1277278381444159 | Iter 2.000: -0.15042695083788463 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (44 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.231209  | 0.127728  |                    4 |\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.063442  | 0.0776763 |                    1 |\n",
      "| train_d0405_00004 | RUNNING    | 192.168.1.5:88373 |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0651648 | 0.0798234 |                    1 |\n",
      "| train_d0405_00005 | RUNNING    |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |           |           |                      |\n",
      "| train_d0405_00006 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |           |           |                      |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:32,003\tWARNING util.py:162 -- The `start_trial` operation took 0.637 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-18-30\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.2329246142790431\n",
      "  mse: 0.1343609836129915\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 24.37462306022644\n",
      "  time_this_iter_s: 5.202454090118408\n",
      "  time_total_s: 24.37462306022644\n",
      "  timestamp: 1622063910\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:32,581\tWARNING util.py:162 -- The `start_trial` operation took 0.567 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-18-31\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05780048615166119\n",
      "  mse: 0.05780048615166119\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.752971887588501\n",
      "  time_this_iter_s: 4.752971887588501\n",
      "  time_total_s: 4.752971887588501\n",
      "  timestamp: 1622063911\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:33,125\tWARNING util.py:162 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:34,172\tWARNING util.py:162 -- The `start_trial` operation took 0.550 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:34,710\tWARNING util.py:162 -- The `process_trial_save` operation took 0.536 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:35,493\tWARNING util.py:162 -- The `start_trial` operation took 0.780 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.6/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: -0.1277278381444159 | Iter 2.000: -0.15042695083788463 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (44 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.300631  | 0.173547  |                    6 |\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.063442  | 0.0776763 |                    1 |\n",
      "| train_d0405_00004 | RUNNING    | 192.168.1.5:88373 |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0651648 | 0.0798234 |                    1 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0578005 | 0.0578005 |                    1 |\n",
      "| train_d0405_00006 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |           |           |                      |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-18-37\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.06807616480133112\n",
      "  mse: 0.09214367905960363\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 28.2713520526886\n",
      "  time_this_iter_s: 16.557978868484497\n",
      "  time_total_s: 28.2713520526886\n",
      "  timestamp: 1622063917\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-18-37\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05549825382019792\n",
      "  mse: 0.05549825382019792\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.95530891418457\n",
      "  time_this_iter_s: 6.202337026596069\n",
      "  time_total_s: 10.95530891418457\n",
      "  timestamp: 1622063917\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:38,613\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00004:\n",
      "  date: 2021-05-26_17-18-37\n",
      "  done: true\n",
      "  experiment_id: ffb37331e7f24a78afe4b4f9ccba24ba\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.0744514101130121\n",
      "  mse: 0.09890569176744013\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88373\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 14.78220796585083\n",
      "  time_this_iter_s: 7.0568859577178955\n",
      "  time_total_s: 14.78220796585083\n",
      "  timestamp: 1622063917\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00004\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:40,548\tWARNING util.py:162 -- The `start_trial` operation took 0.733 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:42,147\tWARNING util.py:162 -- The `start_trial` operation took 0.744 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-18-39\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.2629649568171728\n",
      "  mse: 0.15184557012149266\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 32.927902936935425\n",
      "  time_this_iter_s: 2.5762267112731934\n",
      "  time_total_s: 32.927902936935425\n",
      "  timestamp: 1622063919\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: -0.1277278381444159 | Iter 2.000: -0.09552468541352188 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (43 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.262965  | 0.151846  |                    7 |\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0680762 | 0.0921437 |                    2 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0554983 | 0.0554983 |                    2 |\n",
      "| train_d0405_00006 | RUNNING    |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |           |           |                      |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:18:42,780\tWARNING util.py:162 -- The `start_trial` operation took 0.589 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:18:43,735\tWARNING util.py:162 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-18-44\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.05895075024593444\n",
      "  mse: 0.05895075024593444\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 17.636520862579346\n",
      "  time_this_iter_s: 6.681211948394775\n",
      "  time_total_s: 17.636520862579346\n",
      "  timestamp: 1622063924\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00005\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.1/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.13219101425437702 | Iter 4.000: -0.09245720354928857 | Iter 2.000: -0.09552468541352188 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (43 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.249437  | 0.132191  |                    8 |\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0680762 | 0.0921437 |                    2 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0571866 | 0.0571866 |                    4 |\n",
      "| train_d0405_00006 | RUNNING    |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |           |           |                      |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-18-48\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.2522487509108725\n",
      "  mse: 0.15096126887060346\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.419761180877686\n",
      "  time_this_iter_s: 3.0847182273864746\n",
      "  time_total_s: 42.419761180877686\n",
      "  timestamp: 1622063928\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: d0405_00000\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-18-48\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.06739229283788625\n",
      "  mse: 0.08011903835131842\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 39.776944160461426\n",
      "  time_this_iter_s: 11.505592107772827\n",
      "  time_total_s: 39.776944160461426\n",
      "  timestamp: 1622063928\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-18-50\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.0557713256705375\n",
      "  mse: 0.0557713256705375\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 23.96147608757019\n",
      "  time_this_iter_s: 3.059910297393799\n",
      "  time_total_s: 23.96147608757019\n",
      "  timestamp: 1622063930\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00005\n",
      "  \n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-18-51\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.054129510416704066\n",
      "  mse: 0.054129510416704066\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.64436411857605\n",
      "  time_this_iter_s: 5.64436411857605\n",
      "  time_total_s: 5.64436411857605\n",
      "  timestamp: 1622063931\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00006\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.1/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.13219101425437702 | Iter 4.000: -0.09245720354928857 | Iter 2.000: -0.09552468541352188 | Iter 1.000: -0.07982335432487375\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (43 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.303032  | 0.16261   |                   10 |\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0673923 | 0.080119  |                    3 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0557713 | 0.0557713 |                    5 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0541295 | 0.0541295 |                    1 |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-18-56\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 11\n",
      "  loss: 0.2688383509715398\n",
      "  mse: 0.1506910618572008\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 50.068819999694824\n",
      "  time_this_iter_s: 4.4645750522613525\n",
      "  time_total_s: 50.068819999694824\n",
      "  timestamp: 1622063936\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: d0405_00000\n",
      "  \n",
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-18-57\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.059035317085328554\n",
      "  mse: 0.059035317085328554\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 30.988451957702637\n",
      "  time_this_iter_s: 3.767061948776245\n",
      "  time_total_s: 30.988451957702637\n",
      "  timestamp: 1622063937\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00005\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.13219101425437702 | Iter 4.000: -0.09245720354928857 | Iter 2.000: -0.09552468541352188 | Iter 1.000: -0.07982335432487375\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (43 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.268838  | 0.150691  |                   11 |\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0673923 | 0.080119  |                    3 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0590353 | 0.0590353 |                    7 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0541295 | 0.0541295 |                    1 |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-18-59\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05160621641313329\n",
      "  mse: 0.05160621641313329\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 13.31105899810791\n",
      "  time_this_iter_s: 7.66669487953186\n",
      "  time_total_s: 13.31105899810791\n",
      "  timestamp: 1622063939\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00006\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-18-59\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.06772743218085345\n",
      "  mse: 0.08978305726366885\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 51.05659532546997\n",
      "  time_this_iter_s: 11.279651165008545\n",
      "  time_total_s: 51.05659532546997\n",
      "  timestamp: 1622063939\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-19-03\n",
      "  done: false\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 13\n",
      "  loss: 0.2550252179304759\n",
      "  mse: 0.15002264153389705\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 56.89552712440491\n",
      "  time_this_iter_s: 3.5077202320098877\n",
      "  time_total_s: 56.89552712440491\n",
      "  timestamp: 1622063943\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 13\n",
      "  trial_id: d0405_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.09520598283658427 | Iter 4.000: -0.08978305726366885 | Iter 2.000: -0.09214367905960363 | Iter 1.000: -0.07982335432487375\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (43 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00000 | RUNNING    | 192.168.1.5:87911 |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.255025  | 0.150023  |                   13 |\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0677274 | 0.0897831 |                    4 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.058221  | 0.058221  |                    8 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0516062 | 0.0516062 |                    2 |\n",
      "| train_d0405_00007 | PENDING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-19-04\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.05639198253906909\n",
      "  mse: 0.05639198253906909\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 37.76325702667236\n",
      "  time_this_iter_s: 3.653201103210449\n",
      "  time_total_s: 37.76325702667236\n",
      "  timestamp: 1622063944\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: d0405_00005\n",
      "  \n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-19-04\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.050878254105063046\n",
      "  mse: 0.050878254105063046\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 18.808344841003418\n",
      "  time_this_iter_s: 5.497285842895508\n",
      "  time_total_s: 18.808344841003418\n",
      "  timestamp: 1622063944\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:07,826\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00000:\n",
      "  date: 2021-05-26_17-19-06\n",
      "  done: true\n",
      "  experiment_id: 333e5e7a7ae746ee9be3061f7e066609\n",
      "  experiment_tag: 0_batch_size=32,clip=True,loss_f=L1Loss(),lr=0.0066799,num_layers=1,optim=adam,scaling_factor=0.73778\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.28665166241782053\n",
      "  mse: 0.1588169570480074\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 87911\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 59.99139904975891\n",
      "  time_this_iter_s: 3.095871925354004\n",
      "  time_total_s: 59.99139904975891\n",
      "  timestamp: 1622063946\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:09,614\tWARNING util.py:162 -- The `start_trial` operation took 0.918 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.09520598283658427 | Iter 4.000: -0.08978305726366885 | Iter 2.000: -0.09214367905960363 | Iter 1.000: -0.07982335432487375\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (42 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0677274 | 0.0897831 |                    4 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.056392  | 0.056392  |                    9 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0508783 | 0.0508783 |                    3 |\n",
      "| train_d0405_00007 | RUNNING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-19-08\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.05805607184412934\n",
      "  mse: 0.05805607184412934\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 41.87653303146362\n",
      "  time_this_iter_s: 4.11327600479126\n",
      "  time_total_s: 41.87653303146362\n",
      "  timestamp: 1622063948\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d0405_00005\n",
      "  \n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-19-10\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.050730886047377306\n",
      "  mse: 0.050730886047377306\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 24.89227795600891\n",
      "  time_this_iter_s: 6.083933115005493\n",
      "  time_total_s: 24.89227795600891\n",
      "  timestamp: 1622063950\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00006\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-19-11\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.07096054935280015\n",
      "  mse: 0.0885708588449394\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 62.88701820373535\n",
      "  time_this_iter_s: 11.83042287826538\n",
      "  time_total_s: 62.88701820373535\n",
      "  timestamp: 1622063951\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-19-16\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.05565443111672288\n",
      "  mse: 0.05565443111672288\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 50.06972002983093\n",
      "  time_this_iter_s: 3.9898622035980225\n",
      "  time_total_s: 50.06972002983093\n",
      "  timestamp: 1622063956\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00005\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.1/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.09520598283658427 | Iter 4.000: -0.07348481310891504 | Iter 2.000: -0.09214367905960363 | Iter 1.000: -0.07982335432487375\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (42 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0709605 | 0.0885709 |                    5 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0556544 | 0.0556544 |                   12 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0507309 | 0.0507309 |                    4 |\n",
      "| train_d0405_00007 | RUNNING    |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |           |           |                      |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-19-17\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.051007119040278825\n",
      "  mse: 0.051007119040278825\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 31.65747094154358\n",
      "  time_this_iter_s: 6.765192985534668\n",
      "  time_total_s: 31.65747094154358\n",
      "  timestamp: 1622063957\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:19,629\tWARNING util.py:162 -- The `start_trial` operation took 0.638 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-19-17\n",
      "  done: false\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05195740544620682\n",
      "  mse: 0.05195740544620682\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.079741954803467\n",
      "  time_this_iter_s: 4.079741954803467\n",
      "  time_total_s: 4.079741954803467\n",
      "  timestamp: 1622063957\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:20,496\tWARNING util.py:162 -- The `start_trial` operation took 0.839 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:21,018\tWARNING util.py:162 -- The `process_trial_save` operation took 0.509 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:21,622\tWARNING util.py:162 -- The `start_trial` operation took 0.598 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.3/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.09520598283658427 | Iter 4.000: -0.07348481310891504 | Iter 2.000: -0.09214367905960363 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (42 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0709605 | 0.0885709 |                    5 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0584097 | 0.0584097 |                   13 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0510071 | 0.0510071 |                    5 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0519574 | 0.0519574 |                    1 |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-19-23\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.06934100713799982\n",
      "  mse: 0.08595825698884095\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 74.92569327354431\n",
      "  time_this_iter_s: 12.03867506980896\n",
      "  time_total_s: 74.92569327354431\n",
      "  timestamp: 1622063963\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-19-24\n",
      "  done: false\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05075523866450085\n",
      "  mse: 0.05075523866450085\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 11.210233688354492\n",
      "  time_this_iter_s: 7.130491733551025\n",
      "  time_total_s: 11.210233688354492\n",
      "  timestamp: 1622063964\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00007\n",
      "  \n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-19-25\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.05076146165237707\n",
      "  mse: 0.05076146165237707\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 39.384514808654785\n",
      "  time_this_iter_s: 7.727043867111206\n",
      "  time_total_s: 39.384514808654785\n",
      "  timestamp: 1622063965\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d0405_00006\n",
      "  \n",
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-19-24\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.05593302464556126\n",
      "  mse: 0.05593302464556126\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 57.96975302696228\n",
      "  time_this_iter_s: 3.852741003036499\n",
      "  time_total_s: 57.96975302696228\n",
      "  timestamp: 1622063964\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00005\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.09520598283658427 | Iter 4.000: -0.07348481310891504 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (42 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.069341  | 0.0859583 |                    6 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.055933  | 0.055933  |                   14 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0507615 | 0.0507615 |                    6 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0507552 | 0.0507552 |                    2 |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-19-32\n",
      "  done: false\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.05076743127668605\n",
      "  mse: 0.05076743127668605\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 19.662949800491333\n",
      "  time_this_iter_s: 4.463873863220215\n",
      "  time_total_s: 19.662949800491333\n",
      "  timestamp: 1622063972\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00007\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.09520598283658427 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (42 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.069341  | 0.0859583 |                    6 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0567786 | 0.0567786 |                   15 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0507615 | 0.0507615 |                    6 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0507674 | 0.0507674 |                    4 |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-19-33\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 16\n",
      "  loss: 0.055631281808018684\n",
      "  mse: 0.055631281808018684\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 66.62834787368774\n",
      "  time_this_iter_s: 4.05412483215332\n",
      "  time_total_s: 66.62834787368774\n",
      "  timestamp: 1622063973\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  trial_id: d0405_00005\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-19-33\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.07189963911386098\n",
      "  mse: 0.08886576698106878\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.67992806434631\n",
      "  time_this_iter_s: 9.754234790802002\n",
      "  time_total_s: 84.67992806434631\n",
      "  timestamp: 1622063973\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:35,144\tWARNING util.py:162 -- The `start_trial` operation took 0.518 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:36,192\tWARNING util.py:162 -- The `start_trial` operation took 0.568 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:37,202\tWARNING util.py:162 -- The `start_trial` operation took 0.578 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-19-33\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.05048221555702827\n",
      "  mse: 0.05048221555702827\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 47.74681282043457\n",
      "  time_this_iter_s: 8.362298011779785\n",
      "  time_total_s: 47.74681282043457\n",
      "  timestamp: 1622063973\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:37,731\tWARNING util.py:162 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:38,352\tWARNING util.py:162 -- The `process_trial_save` operation took 0.618 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.09520598283658427 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (42 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0718996 | 0.0888658 |                    7 |\n",
      "| train_d0405_00005 | RUNNING    | 192.168.1.5:88454 |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.0556313 | 0.0556313 |                   16 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504822 | 0.0504822 |                    7 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0507674 | 0.0507674 |                    4 |\n",
      "| train_d0405_00008 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:38,954\tWARNING util.py:162 -- The `start_trial` operation took 0.581 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-19-38\n",
      "  done: false\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 17\n",
      "  loss: 0.05705300416974794\n",
      "  mse: 0.05705300416974794\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 71.47224807739258\n",
      "  time_this_iter_s: 4.843900203704834\n",
      "  time_total_s: 71.47224807739258\n",
      "  timestamp: 1622063978\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 17\n",
      "  trial_id: d0405_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:39,818\tWARNING util.py:162 -- The `start_trial` operation took 0.747 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:40,441\tWARNING util.py:162 -- The `process_trial_save` operation took 0.620 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:41,052\tWARNING util.py:162 -- The `start_trial` operation took 0.608 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:41,061\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00005:\n",
      "  date: 2021-05-26_17-19-38\n",
      "  done: true\n",
      "  experiment_id: 9e2c34403e9f45c7809f6edc1cb06c35\n",
      "  experiment_tag: 5_batch_size=32,clip=True,loss_f=MSELoss(),lr=0.018607,num_layers=1,optim=adagrad,scaling_factor=0.86746\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 17\n",
      "  loss: 0.05705300416974794\n",
      "  mse: 0.05705300416974794\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 71.47224807739258\n",
      "  time_this_iter_s: 4.843900203704834\n",
      "  time_total_s: 71.47224807739258\n",
      "  timestamp: 1622063978\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 17\n",
      "  trial_id: d0405_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:42,885\tWARNING util.py:162 -- The `start_trial` operation took 0.952 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:43,411\tWARNING util.py:162 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-19-40\n",
      "  done: false\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.05137828316758661\n",
      "  mse: 0.05137828316758661\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 27.48645281791687\n",
      "  time_this_iter_s: 7.823503017425537\n",
      "  time_total_s: 27.48645281791687\n",
      "  timestamp: 1622063980\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00007\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.09520598283658427 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (41 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0718996 | 0.0888658 |                    7 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504822 | 0.0504822 |                    7 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0513783 | 0.0513783 |                    5 |\n",
      "| train_d0405_00008 | RUNNING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:44,925\tWARNING util.py:162 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-19-44\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 8\n",
      "  loss: 0.07056931557462495\n",
      "  mse: 0.08534854637349353\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 95.99007725715637\n",
      "  time_this_iter_s: 11.310149192810059\n",
      "  time_total_s: 95.99007725715637\n",
      "  timestamp: 1622063984\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-19-44\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 8\n",
      "  loss: 0.05056512938702808\n",
      "  mse: 0.05056512938702808\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 58.80560493469238\n",
      "  time_this_iter_s: 11.058792114257812\n",
      "  time_total_s: 58.80560493469238\n",
      "  timestamp: 1622063984\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d0405_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:47,864\tWARNING util.py:162 -- The `start_trial` operation took 0.604 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:48,963\tWARNING util.py:162 -- The `start_trial` operation took 0.568 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.07178474889614252 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (41 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0705693 | 0.0853485 |                    8 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0505651 | 0.0505651 |                    8 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.052285  | 0.052285  |                    6 |\n",
      "| train_d0405_00008 | RUNNING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |           |           |                      |\n",
      "| train_d0405_00009 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:50,050\tWARNING util.py:162 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:19:52,902\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00008:\n",
      "  date: 2021-05-26_17-19-52\n",
      "  done: true\n",
      "  experiment_id: a0b72df461f842e58e059f03a1d1a06d\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.22639768570661545\n",
      "  mse: 0.15122621311318307\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88992\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.378213167190552\n",
      "  time_this_iter_s: 4.378213167190552\n",
      "  time_total_s: 4.378213167190552\n",
      "  timestamp: 1622063992\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00008\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:19:54,725\tWARNING util.py:162 -- The `start_trial` operation took 0.925 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.07178474889614252 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07982335432487375\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (40 PENDING, 4 RUNNING, 6 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0705693 | 0.0853485 |                    8 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0505651 | 0.0505651 |                    8 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.052285  | 0.052285  |                    6 |\n",
      "| train_d0405_00009 | RUNNING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-19-53\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.050574104663203744\n",
      "  mse: 0.050574104663203744\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 67.86713600158691\n",
      "  time_this_iter_s: 9.061531066894531\n",
      "  time_total_s: 67.86713600158691\n",
      "  timestamp: 1622063993\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: d0405_00006\n",
      "  \n",
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-19-53\n",
      "  done: false\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.05077158317846411\n",
      "  mse: 0.05077158317846411\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 39.931230783462524\n",
      "  time_this_iter_s: 4.774484872817993\n",
      "  time_total_s: 39.931230783462524\n",
      "  timestamp: 1622063993\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00007\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-19-56\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.06818749891484485\n",
      "  mse: 0.0826686243800556\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 107.46981024742126\n",
      "  time_this_iter_s: 11.479732990264893\n",
      "  time_total_s: 107.46981024742126\n",
      "  timestamp: 1622063996\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07982335432487375\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (40 PENDING, 4 RUNNING, 6 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0681875 | 0.0826686 |                    9 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0505741 | 0.0505741 |                    9 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0497309 | 0.0497309 |                    8 |\n",
      "| train_d0405_00009 | RUNNING    |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |           |           |                      |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:01,961\tWARNING util.py:162 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:20:02,929\tWARNING util.py:162 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-20-02\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.050575157868511536\n",
      "  mse: 0.050575157868511536\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 76.40644478797913\n",
      "  time_this_iter_s: 8.539308786392212\n",
      "  time_total_s: 76.40644478797913\n",
      "  timestamp: 1622064002\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d0405_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:04,416\tWARNING util.py:162 -- The `start_trial` operation took 0.527 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-20-05\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.0504789675859844\n",
      "  mse: 0.0504789675859844\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.098349094390869\n",
      "  time_this_iter_s: 6.098349094390869\n",
      "  time_total_s: 6.098349094390869\n",
      "  timestamp: 1622064005\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (40 PENDING, 4 RUNNING, 6 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0681875 | 0.0826686 |                    9 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0505752 | 0.0505752 |                   10 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0497309 | 0.0497309 |                    8 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.050479  | 0.050479  |                    1 |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-20-06\n",
      "  done: false\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.0508725968792158\n",
      "  mse: 0.0508725968792158\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 52.96898078918457\n",
      "  time_this_iter_s: 4.873286724090576\n",
      "  time_total_s: 52.96898078918457\n",
      "  timestamp: 1622064006\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: d0405_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:08,545\tWARNING util.py:162 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-20-09\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.07081839236266473\n",
      "  mse: 0.08988271890317692\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 120.25137305259705\n",
      "  time_this_iter_s: 12.781562805175781\n",
      "  time_total_s: 120.25137305259705\n",
      "  timestamp: 1622064009\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-20-09\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 11\n",
      "  loss: 0.05040360500707346\n",
      "  mse: 0.05040360500707346\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.85095977783203\n",
      "  time_this_iter_s: 7.444514989852905\n",
      "  time_total_s: 83.85095977783203\n",
      "  timestamp: 1622064009\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: d0405_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:11,371\tWARNING util.py:162 -- The `process_trial_save` operation took 0.558 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:20:12,019\tWARNING util.py:162 -- The `start_trial` operation took 0.630 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.07382096643990077 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (40 PENDING, 4 RUNNING, 6 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0708184 | 0.0898827 |                   10 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504036 | 0.0504036 |                   11 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0525939 | 0.0525939 |                   10 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.050479  | 0.050479  |                    1 |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-20-12\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.050106366745689336\n",
      "  mse: 0.050106366745689336\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 12.482494831085205\n",
      "  time_this_iter_s: 6.384145736694336\n",
      "  time_total_s: 12.482494831085205\n",
      "  timestamp: 1622064012\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:14,901\tWARNING util.py:162 -- The `start_trial` operation took 0.517 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-20-16\n",
      "  done: false\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 11\n",
      "  loss: 0.05121364457642331\n",
      "  mse: 0.05121364457642331\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 63.37022280693054\n",
      "  time_this_iter_s: 4.649526834487915\n",
      "  time_total_s: 63.37022280693054\n",
      "  timestamp: 1622064016\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: d0405_00007\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.05549825382019792 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (40 PENDING, 4 RUNNING, 6 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0708184 | 0.0898827 |                   10 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504036 | 0.0504036 |                   11 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0512136 | 0.0512136 |                   11 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0501064 | 0.0501064 |                    2 |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-20-17\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.05047864190795842\n",
      "  mse: 0.05047864190795842\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 91.38772296905518\n",
      "  time_this_iter_s: 7.5367631912231445\n",
      "  time_total_s: 91.38772296905518\n",
      "  timestamp: 1622064017\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:19,315\tWARNING util.py:162 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-20-19\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.049067109001471716\n",
      "  mse: 0.049067109001471716\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 19.765689849853516\n",
      "  time_this_iter_s: 7.2831950187683105\n",
      "  time_total_s: 19.765689849853516\n",
      "  timestamp: 1622064019\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-20-19\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 11\n",
      "  loss: 0.07383240923723754\n",
      "  mse: 0.09940422720768873\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 131.11547112464905\n",
      "  time_this_iter_s: 10.864098072052002\n",
      "  time_total_s: 131.11547112464905\n",
      "  timestamp: 1622064019\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-20-20\n",
      "  done: false\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.04968536351533497\n",
      "  mse: 0.04968536351533497\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 67.6714928150177\n",
      "  time_this_iter_s: 4.301270008087158\n",
      "  time_total_s: 67.6714928150177\n",
      "  timestamp: 1622064020\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:22,586\tWARNING util.py:162 -- The `start_trial` operation took 0.522 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.05549825382019792 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (40 PENDING, 4 RUNNING, 6 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0738324 | 0.0994042 |                   11 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504786 | 0.0504786 |                   12 |\n",
      "| train_d0405_00007 | RUNNING    | 192.168.1.5:88771 |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0490671 | 0.0490671 |                    3 |\n",
      "| train_d0405_00010 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:23,606\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00007:\n",
      "  date: 2021-05-26_17-20-20\n",
      "  done: true\n",
      "  experiment_id: 4ef4e7860716493ea293d7478d9caa17\n",
      "  experiment_tag: 7_batch_size=16,clip=False,loss_f=MSELoss(),lr=0.005317,num_layers=1,optim=adam,scaling_factor=0.84406\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.04968536351533497\n",
      "  mse: 0.04968536351533497\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88771\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 67.6714928150177\n",
      "  time_this_iter_s: 4.301270008087158\n",
      "  time_total_s: 67.6714928150177\n",
      "  timestamp: 1622064020\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:25,389\tWARNING util.py:162 -- The `start_trial` operation took 0.887 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-20-24\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 13\n",
      "  loss: 0.05029680621536339\n",
      "  mse: 0.05029680621536339\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 98.55806183815002\n",
      "  time_this_iter_s: 7.170338869094849\n",
      "  time_total_s: 98.55806183815002\n",
      "  timestamp: 1622064024\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 13\n",
      "  trial_id: d0405_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:27,199\tWARNING util.py:162 -- The `start_trial` operation took 0.525 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-20-26\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.048866249423693206\n",
      "  mse: 0.048866249423693206\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 27.112303733825684\n",
      "  time_this_iter_s: 7.346613883972168\n",
      "  time_total_s: 27.112303733825684\n",
      "  timestamp: 1622064026\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.05549825382019792 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (39 PENDING, 4 RUNNING, 7 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0738324 | 0.0994042 |                   11 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0502968 | 0.0502968 |                   13 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0488662 | 0.0488662 |                    4 |\n",
      "| train_d0405_00010 | RUNNING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-20-30\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.07256417414721321\n",
      "  mse: 0.0953880109331187\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 141.76492428779602\n",
      "  time_this_iter_s: 10.649453163146973\n",
      "  time_total_s: 141.76492428779602\n",
      "  timestamp: 1622064030\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:31,928\tWARNING util.py:162 -- The `start_trial` operation took 0.510 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-20-32\n",
      "  done: false\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.05042844971313196\n",
      "  mse: 0.05042844971313196\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 106.93300104141235\n",
      "  time_this_iter_s: 8.374939203262329\n",
      "  time_total_s: 106.93300104141235\n",
      "  timestamp: 1622064032\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00006\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.05549825382019792 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (39 PENDING, 4 RUNNING, 7 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0725642 | 0.095388  |                   12 |\n",
      "| train_d0405_00006 | RUNNING    | 192.168.1.5:88570 |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0488662 | 0.0488662 |                    4 |\n",
      "| train_d0405_00010 | RUNNING    |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |           |           |                      |\n",
      "| train_d0405_00011 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-20-33\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.04873054722214446\n",
      "  mse: 0.04873054722214446\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 33.69132375717163\n",
      "  time_this_iter_s: 6.579020023345947\n",
      "  time_total_s: 33.69132375717163\n",
      "  timestamp: 1622064033\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:35,561\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00006:\n",
      "  date: 2021-05-26_17-20-32\n",
      "  done: true\n",
      "  experiment_id: 210013a9a44d4c20913ac13e1744ea55\n",
      "  experiment_tag: 6_batch_size=16,clip=False,loss_f=MSELoss(),lr=0.001558,num_layers=2,optim=adagrad,scaling_factor=0.99222\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.05042844971313196\n",
      "  mse: 0.05042844971313196\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 106.93300104141235\n",
      "  time_this_iter_s: 8.374939203262329\n",
      "  time_total_s: 106.93300104141235\n",
      "  timestamp: 1622064032\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00006\n",
      "  \n",
      "Result for train_d0405_00010:\n",
      "  date: 2021-05-26_17-20-35\n",
      "  done: false\n",
      "  experiment_id: a0ffa221fbc54426ba99aacc52b36b82\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.0772642380602303\n",
      "  mse: 0.0772642380602303\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89228\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.689634084701538\n",
      "  time_this_iter_s: 4.689634084701538\n",
      "  time_total_s: 4.689634084701538\n",
      "  timestamp: 1622064035\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00010\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:38,175\tWARNING util.py:162 -- The `start_trial` operation took 1.134 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:20:39,178\tWARNING util.py:162 -- The `process_trial_save` operation took 0.543 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.05549825382019792 | Iter 1.000: -0.0776762983378242\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (38 PENDING, 4 RUNNING, 8 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0725642 | 0.095388  |                   12 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0487305 | 0.0487305 |                    5 |\n",
      "| train_d0405_00010 | RUNNING    | 192.168.1.5:89228 |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0772642 | 0.0772642 |                    1 |\n",
      "| train_d0405_00011 | RUNNING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:39,868\tWARNING util.py:162 -- The `start_trial` operation took 0.669 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-20-40\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.04843945046338965\n",
      "  mse: 0.04843945046338965\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 40.96791386604309\n",
      "  time_this_iter_s: 7.27659010887146\n",
      "  time_total_s: 40.96791386604309\n",
      "  timestamp: 1622064040\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-20-41\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 13\n",
      "  loss: 0.07645384027239155\n",
      "  mse: 0.10599934809348162\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 152.3699803352356\n",
      "  time_this_iter_s: 10.605056047439575\n",
      "  time_total_s: 152.3699803352356\n",
      "  timestamp: 1622064041\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 13\n",
      "  trial_id: d0405_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:43,747\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00010:\n",
      "  date: 2021-05-26_17-20-43\n",
      "  done: true\n",
      "  experiment_id: a0ffa221fbc54426ba99aacc52b36b82\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.06738023380083698\n",
      "  mse: 0.06738023380083698\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89228\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 13.309486150741577\n",
      "  time_this_iter_s: 8.619852066040039\n",
      "  time_total_s: 13.309486150741577\n",
      "  timestamp: 1622064043\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00010\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06143924381051745 | Iter 1.000: -0.0776762983378242\n",
      "Resources requested: 6.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (38 PENDING, 3 RUNNING, 9 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0764538 | 0.105999  |                   13 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0484395 | 0.0484395 |                    6 |\n",
      "| train_d0405_00011 | RUNNING    |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |           |           |                      |\n",
      "| train_d0405_00012 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (29 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:45,532\tWARNING util.py:162 -- The `start_trial` operation took 0.856 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:20:46,134\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00011:\n",
      "  date: 2021-05-26_17-20-46\n",
      "  done: true\n",
      "  experiment_id: ee494a758f084c43b77aad4d1ac522f8\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 2.057696064313253\n",
      "  mse: 4.253414789835612\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89291\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.0216121673583984\n",
      "  time_this_iter_s: 3.0216121673583984\n",
      "  time_total_s: 3.0216121673583984\n",
      "  timestamp: 1622064046\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00011\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:47,667\tWARNING util.py:162 -- The `start_trial` operation took 0.735 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-20-47\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.048549996886183236\n",
      "  mse: 0.048549996886183236\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 47.47140192985535\n",
      "  time_this_iter_s: 6.503488063812256\n",
      "  time_total_s: 47.47140192985535\n",
      "  timestamp: 1622064047\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-20-51\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.0717729787397034\n",
      "  mse: 0.08111831681693302\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 162.85432410240173\n",
      "  time_this_iter_s: 10.484343767166138\n",
      "  time_total_s: 162.85432410240173\n",
      "  timestamp: 1622064051\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.0582209514187915 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06143924381051745 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (36 PENDING, 4 RUNNING, 10 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.071773  | 0.0811183 |                   14 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.04855   | 0.04855   |                    7 |\n",
      "| train_d0405_00012 | RUNNING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |           |           |                      |\n",
      "| train_d0405_00013 | RUNNING    |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |           |           |                      |\n",
      "| train_d0405_00014 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (28 PENDING, 2 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:52,946\tWARNING util.py:162 -- The `start_trial` operation took 0.535 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:20:53,016\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00012:\n",
      "  date: 2021-05-26_17-20-53\n",
      "  done: true\n",
      "  experiment_id: ddc289c1515747cea735a313cd686329\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6034412611098516\n",
      "  mse: 0.9912956271852765\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89333\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.2185330390930176\n",
      "  time_this_iter_s: 3.2185330390930176\n",
      "  time_total_s: 3.2185330390930176\n",
      "  timestamp: 1622064053\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00012\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:54,557\tWARNING util.py:162 -- The `start_trial` operation took 0.736 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-20-53\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 8\n",
      "  loss: 0.04834151594516109\n",
      "  mse: 0.04834151594516109\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 53.74174785614014\n",
      "  time_this_iter_s: 6.27034592628479\n",
      "  time_total_s: 53.74174785614014\n",
      "  timestamp: 1622064053\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:56,214\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00013:\n",
      "  date: 2021-05-26_17-20-56\n",
      "  done: true\n",
      "  experiment_id: fce7116d73f940b4a97ae8a86f689f02\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6985556625184559\n",
      "  mse: 0.7928263105097271\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89346\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.14155912399292\n",
      "  time_this_iter_s: 4.14155912399292\n",
      "  time_total_s: 4.14155912399292\n",
      "  timestamp: 1622064056\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00013\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06143924381051745 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 6.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (35 PENDING, 3 RUNNING, 12 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.071773  | 0.0811183 |                   14 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0483415 | 0.0483415 |                    8 |\n",
      "| train_d0405_00014 | RUNNING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | PENDING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (26 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:20:58,116\tWARNING util.py:162 -- The `start_trial` operation took 1.147 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-00\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.04824955526958494\n",
      "  mse: 0.04824955526958494\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.23366189002991\n",
      "  time_this_iter_s: 7.4919140338897705\n",
      "  time_total_s: 61.23366189002991\n",
      "  timestamp: 1622064060\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-21-02\n",
      "  done: false\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 15\n",
      "  loss: 0.06914614960551262\n",
      "  mse: 0.08164121473536771\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 173.33257913589478\n",
      "  time_this_iter_s: 10.478255033493042\n",
      "  time_total_s: 173.33257913589478\n",
      "  timestamp: 1622064062\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 15\n",
      "  trial_id: d0405_00002\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06143924381051745 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (34 PENDING, 4 RUNNING, 12 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0691461 | 0.0816412 |                   15 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0482496 | 0.0482496 |                    9 |\n",
      "| train_d0405_00014 | RUNNING    |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |           |           |                      |\n",
      "| train_d0405_00015 | RUNNING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (26 PENDING, 4 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:03,497\tWARNING util.py:162 -- The `start_trial` operation took 0.515 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:21:03,511\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00014:\n",
      "  date: 2021-05-26_17-21-01\n",
      "  done: true\n",
      "  experiment_id: 6f626b1e0e5346439ed8e863671e4224\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.23171047227723257\n",
      "  mse: 0.1271963311093194\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89391\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.1120951175689697\n",
      "  time_this_iter_s: 2.1120951175689697\n",
      "  time_total_s: 2.1120951175689697\n",
      "  timestamp: 1622064061\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00014\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:05,185\tWARNING util.py:162 -- The `start_trial` operation took 0.815 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-06\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.04834581379066495\n",
      "  mse: 0.04834581379066495\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 66.93230485916138\n",
      "  time_this_iter_s: 5.69864296913147\n",
      "  time_total_s: 66.93230485916138\n",
      "  timestamp: 1622064066\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06143924381051745 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (33 PENDING, 4 RUNNING, 13 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0691461 | 0.0816412 |                   15 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0483458 | 0.0483458 |                   10 |\n",
      "| train_d0405_00015 | RUNNING    |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |           |           |                      |\n",
      "| train_d0405_00016 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (25 PENDING, 5 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00015:\n",
      "  date: 2021-05-26_17-21-10\n",
      "  done: false\n",
      "  experiment_id: d4539b2726c94ee49022cf2168375b66\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05397623479366302\n",
      "  mse: 0.061914179189240234\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89407\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.216803073883057\n",
      "  time_this_iter_s: 7.216803073883057\n",
      "  time_total_s: 7.216803073883057\n",
      "  timestamp: 1622064070\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00015\n",
      "  \n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-12\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 11\n",
      "  loss: 0.04814519884393496\n",
      "  mse: 0.04814519884393496\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 72.90819978713989\n",
      "  time_this_iter_s: 5.975894927978516\n",
      "  time_total_s: 72.90819978713989\n",
      "  timestamp: 1622064072\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06143924381051745 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (33 PENDING, 4 RUNNING, 13 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00002 | RUNNING    | 192.168.1.5:88365 |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0691461 | 0.0816412 |                   15 |\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0481452 | 0.0481452 |                   11 |\n",
      "| train_d0405_00015 | RUNNING    | 192.168.1.5:89407 |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 | 0.0539762 | 0.0619142 |                    1 |\n",
      "| train_d0405_00016 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (25 PENDING, 5 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:13,874\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00002:\n",
      "  date: 2021-05-26_17-21-12\n",
      "  done: true\n",
      "  experiment_id: 6e5feb2ff4b74a1eb6812a53590b4a78\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 16\n",
      "  loss: 0.07325664561461\n",
      "  mse: 0.08890868057222927\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 88365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 183.9382200241089\n",
      "  time_this_iter_s: 10.605640888214111\n",
      "  time_total_s: 183.9382200241089\n",
      "  timestamp: 1622064072\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  trial_id: d0405_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:15,555\tWARNING util.py:162 -- The `start_trial` operation took 0.841 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00015:\n",
      "  date: 2021-05-26_17-21-18\n",
      "  done: false\n",
      "  experiment_id: d4539b2726c94ee49022cf2168375b66\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05333627931335393\n",
      "  mse: 0.06120084515389274\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89407\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 15.41382122039795\n",
      "  time_this_iter_s: 8.197018146514893\n",
      "  time_total_s: 15.41382122039795\n",
      "  timestamp: 1622064078\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00015\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.07226998119012398 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06120084515389274 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (32 PENDING, 4 RUNNING, 14 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0481452 | 0.0481452 |                   11 |\n",
      "| train_d0405_00015 | RUNNING    | 192.168.1.5:89407 |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 | 0.0533363 | 0.0612008 |                    2 |\n",
      "| train_d0405_00016 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 |           |           |                      |\n",
      "| train_d0405_00017 | RUNNING    |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |           |           |                      |\n",
      "| train_d0405_00018 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (24 PENDING, 6 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-18\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.04823869115070385\n",
      "  mse: 0.04823869115070385\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 79.02006506919861\n",
      "  time_this_iter_s: 6.111865282058716\n",
      "  time_total_s: 79.02006506919861\n",
      "  timestamp: 1622064078\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:20,022\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00016:\n",
      "  date: 2021-05-26_17-21-18\n",
      "  done: true\n",
      "  experiment_id: f667693f75184db7ad764ef15be7d7d1\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 16.10430481854607\n",
      "  mse: 32.20675154293285\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89454\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 9.005326747894287\n",
      "  time_this_iter_s: 9.005326747894287\n",
      "  time_total_s: 9.005326747894287\n",
      "  timestamp: 1622064078\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00016\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:22,479\tWARNING util.py:162 -- The `start_trial` operation took 0.824 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:21:22,922\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00017:\n",
      "  date: 2021-05-26_17-21-22\n",
      "  done: true\n",
      "  experiment_id: f59c112154884eac9a59371f77969fef\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.09451518598056975\n",
      "  mse: 0.1344265178555534\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.5534210205078125\n",
      "  time_this_iter_s: 2.5534210205078125\n",
      "  time_total_s: 2.5534210205078125\n",
      "  timestamp: 1622064082\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00017\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=12\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.07226998119012398 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06120084515389274 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 6.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (31 PENDING, 3 RUNNING, 16 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0482387 | 0.0482387 |                   12 |\n",
      "| train_d0405_00015 | RUNNING    | 192.168.1.5:89407 |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 | 0.0533363 | 0.0612008 |                    2 |\n",
      "| train_d0405_00018 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |           |           |                      |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (22 PENDING, 7 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:24,609\tWARNING util.py:162 -- The `start_trial` operation took 0.844 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-25\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 13\n",
      "  loss: 0.048123072131591685\n",
      "  mse: 0.048123072131591685\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 86.09423685073853\n",
      "  time_this_iter_s: 7.074171781539917\n",
      "  time_total_s: 86.09423685073853\n",
      "  timestamp: 1622064085\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 13\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "Result for train_d0405_00015:\n",
      "  date: 2021-05-26_17-21-26\n",
      "  done: false\n",
      "  experiment_id: d4539b2726c94ee49022cf2168375b66\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.05259785056114197\n",
      "  mse: 0.0581482046886402\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89407\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 23.3398540019989\n",
      "  time_this_iter_s: 7.926032781600952\n",
      "  time_total_s: 23.3398540019989\n",
      "  timestamp: 1622064086\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00015\n",
      "  \n",
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-21-31\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.051613849632087205\n",
      "  mse: 0.051613849632087205\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.058708906173706\n",
      "  time_this_iter_s: 2.058708906173706\n",
      "  time_total_s: 2.058708906173706\n",
      "  timestamp: 1622064091\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00019\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=12\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.07226998119012398 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06120084515389274 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (30 PENDING, 4 RUNNING, 16 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0481231 | 0.0481231 |                   13 |\n",
      "| train_d0405_00015 | RUNNING    | 192.168.1.5:89407 |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 | 0.0525979 | 0.0581482 |                    3 |\n",
      "| train_d0405_00018 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0516138 | 0.0516138 |                    1 |\n",
      "| train_d0405_00020 | PENDING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (22 PENDING, 8 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-31\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.04799620352466317\n",
      "  mse: 0.04799620352466317\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 91.55595183372498\n",
      "  time_this_iter_s: 5.46171498298645\n",
      "  time_total_s: 91.55595183372498\n",
      "  timestamp: 1622064091\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:33,406\tWARNING util.py:162 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:21:35,030\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00015:\n",
      "  date: 2021-05-26_17-21-34\n",
      "  done: true\n",
      "  experiment_id: d4539b2726c94ee49022cf2168375b66\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.051849736821125536\n",
      "  mse: 0.059510225736919574\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89407\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 31.103522062301636\n",
      "  time_this_iter_s: 7.763668060302734\n",
      "  time_total_s: 31.103522062301636\n",
      "  timestamp: 1622064094\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00015\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:36,516\tWARNING util.py:162 -- The `start_trial` operation took 0.698 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.07226998119012398 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.057186568954161236 | Iter 2.000: -0.058349549487045335 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (29 PENDING, 4 RUNNING, 17 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0479962 | 0.0479962 |                   14 |\n",
      "| train_d0405_00018 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |           |           |                      |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0510146 | 0.0510146 |                    2 |\n",
      "| train_d0405_00020 | RUNNING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (21 PENDING, 9 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-21-36\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.050848565552206265\n",
      "  mse: 0.050848565552206265\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.153938055038452\n",
      "  time_this_iter_s: 2.208329200744629\n",
      "  time_total_s: 7.153938055038452\n",
      "  timestamp: 1622064096\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:37,237\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00018:\n",
      "  date: 2021-05-26_17-21-33\n",
      "  done: true\n",
      "  experiment_id: f8b4ccbbf0b2414b87d5fd0f98dae584\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.9116000505054698\n",
      "  mse: 1.618895593811484\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89545\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.889476776123047\n",
      "  time_this_iter_s: 6.889476776123047\n",
      "  time_total_s: 6.889476776123047\n",
      "  timestamp: 1622064093\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00018\n",
      "  \n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-37\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 15\n",
      "  loss: 0.048141788636498595\n",
      "  mse: 0.048141788636498595\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 97.28770995140076\n",
      "  time_this_iter_s: 5.731758117675781\n",
      "  time_total_s: 97.28770995140076\n",
      "  timestamp: 1622064097\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 15\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:40,315\tWARNING util.py:162 -- The `start_trial` operation took 0.703 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:21:41,854\tWARNING util.py:162 -- The `process_trial_save` operation took 0.568 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.07226998119012398 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.058349549487045335 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (28 PENDING, 4 RUNNING, 18 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0481418 | 0.0481418 |                   15 |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0505509 | 0.0505509 |                    4 |\n",
      "| train_d0405_00020 | RUNNING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | RUNNING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (20 PENDING, 10 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:42,405\tWARNING util.py:162 -- The `start_trial` operation took 0.536 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-21-43\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.050297632724756285\n",
      "  mse: 0.050297632724756285\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 14.779431104660034\n",
      "  time_this_iter_s: 4.097295045852661\n",
      "  time_total_s: 14.779431104660034\n",
      "  timestamp: 1622064103\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00019\n",
      "  \n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-44\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 16\n",
      "  loss: 0.04811235421939808\n",
      "  mse: 0.04811235421939808\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 104.38252282142639\n",
      "  time_this_iter_s: 7.094812870025635\n",
      "  time_total_s: 104.38252282142639\n",
      "  timestamp: 1622064104\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.1/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.058349549487045335 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (28 PENDING, 4 RUNNING, 18 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0481124 | 0.0481124 |                   16 |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0502318 | 0.0502318 |                    6 |\n",
      "| train_d0405_00020 | RUNNING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | RUNNING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |           |           |                      |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (20 PENDING, 10 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:48,371\tWARNING util.py:162 -- The `start_trial` operation took 0.611 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-21-49\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.05017661906424023\n",
      "  mse: 0.05017661906424023\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 20.89315915107727\n",
      "  time_this_iter_s: 3.1105191707611084\n",
      "  time_total_s: 20.89315915107727\n",
      "  timestamp: 1622064109\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:50,881\tWARNING util.py:162 -- The `process_trial_save` operation took 0.517 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:21:51,391\tWARNING util.py:162 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00021:\n",
      "  date: 2021-05-26_17-21-50\n",
      "  done: false\n",
      "  experiment_id: 1c909f9d39e34447a4daf02e6a497fa9\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.057405690805000416\n",
      "  mse: 0.0682285928989158\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89665\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.190562009811401\n",
      "  time_this_iter_s: 6.190562009811401\n",
      "  time_total_s: 6.190562009811401\n",
      "  timestamp: 1622064110\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00021\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.1/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05439304040290979 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.058349549487045335 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (28 PENDING, 4 RUNNING, 18 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0481124 | 0.0481124 |                   16 |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0501766 | 0.0501766 |                    7 |\n",
      "| train_d0405_00020 | RUNNING    |                   |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |           |           |                      |\n",
      "| train_d0405_00021 | RUNNING    | 192.168.1.5:89665 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 | 0.0574057 | 0.0682286 |                    1 |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (20 PENDING, 10 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-51\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 17\n",
      "  loss: 0.04801349624553147\n",
      "  mse: 0.04801349624553147\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 112.10221791267395\n",
      "  time_this_iter_s: 7.719695091247559\n",
      "  time_total_s: 112.10221791267395\n",
      "  timestamp: 1622064111\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 17\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:55,326\tWARNING util.py:162 -- The `start_trial` operation took 0.521 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00020:\n",
      "  date: 2021-05-26_17-21-56\n",
      "  done: false\n",
      "  experiment_id: a1d45da56b034a7ca5092d093a468890\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05046426097259802\n",
      "  mse: 0.05417084466008579\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89631\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 16.6910080909729\n",
      "  time_this_iter_s: 16.6910080909729\n",
      "  time_total_s: 16.6910080909729\n",
      "  timestamp: 1622064116\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00020\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.058349549487045335 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (28 PENDING, 4 RUNNING, 18 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0480135 | 0.0480135 |                   17 |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0499917 | 0.0499917 |                    8 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0504643 | 0.0541708 |                    1 |\n",
      "| train_d0405_00021 | RUNNING    | 192.168.1.5:89665 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 | 0.0574057 | 0.0682286 |                    1 |\n",
      "| train_d0405_00022 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (20 PENDING, 10 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:58,249\tWARNING util.py:162 -- The `start_trial` operation took 0.500 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:21:58,264\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00021:\n",
      "  date: 2021-05-26_17-21-57\n",
      "  done: true\n",
      "  experiment_id: 1c909f9d39e34447a4daf02e6a497fa9\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05514549871577936\n",
      "  mse: 0.0663478697924053\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89665\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 12.686216115951538\n",
      "  time_this_iter_s: 6.495654106140137\n",
      "  time_total_s: 12.686216115951538\n",
      "  timestamp: 1622064117\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00021\n",
      "  \n",
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-21-56\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.05003170074806327\n",
      "  mse: 0.05003170074806327\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 27.812285900115967\n",
      "  time_this_iter_s: 4.021490812301636\n",
      "  time_total_s: 27.812285900115967\n",
      "  timestamp: 1622064116\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:21:59,767\tWARNING util.py:162 -- The `process_trial_save` operation took 0.575 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:00,788\tWARNING util.py:162 -- The `start_trial` operation took 1.010 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:02,297\tWARNING util.py:162 -- The `start_trial` operation took 0.582 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-21-59\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 18\n",
      "  loss: 0.04802820354919223\n",
      "  mse: 0.04802820354919223\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 119.96224999427795\n",
      "  time_this_iter_s: 7.860032081604004\n",
      "  time_total_s: 119.96224999427795\n",
      "  timestamp: 1622064119\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 18\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=15\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06120084515389274 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (27 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0480282 | 0.0480282 |                   18 |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0500317 | 0.0500317 |                    9 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0504643 | 0.0541708 |                    1 |\n",
      "| train_d0405_00022 | RUNNING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |           |           |                      |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (19 PENDING, 11 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:03,760\tWARNING util.py:162 -- The `start_trial` operation took 0.507 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-22-03\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.04976354370869342\n",
      "  mse: 0.04976354370869342\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 34.95645618438721\n",
      "  time_this_iter_s: 7.14417028427124\n",
      "  time_total_s: 34.95645618438721\n",
      "  timestamp: 1622064123\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:07,682\tWARNING util.py:162 -- The `process_trial_save` operation took 0.505 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:08,218\tWARNING util.py:162 -- The `start_trial` operation took 0.533 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:08,660\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00022:\n",
      "  date: 2021-05-26_17-22-08\n",
      "  done: true\n",
      "  experiment_id: b3a0d449fba449c5b7e8ccd657c35e4a\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.44579892073358807\n",
      "  mse: 0.8700179713112968\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89776\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.5241849422454834\n",
      "  time_this_iter_s: 2.5241849422454834\n",
      "  time_total_s: 2.5241849422454834\n",
      "  timestamp: 1622064128\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00022\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06120084515389274 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (27 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0480282 | 0.0480282 |                   18 |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0497401 | 0.0497401 |                   11 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0504643 | 0.0541708 |                    1 |\n",
      "| train_d0405_00022 | RUNNING    | 192.168.1.5:89776 |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 | 0.445799  | 0.870018  |                    1 |\n",
      "| train_d0405_00023 | PENDING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (19 PENDING, 11 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-22-08\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 19\n",
      "  loss: 0.04796158131211996\n",
      "  mse: 0.04796158131211996\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 129.09909892082214\n",
      "  time_this_iter_s: 9.13684892654419\n",
      "  time_total_s: 129.09909892082214\n",
      "  timestamp: 1622064128\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 19\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-22-09\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.04968554154038429\n",
      "  mse: 0.04968554154038429\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 40.65222406387329\n",
      "  time_this_iter_s: 2.9114599227905273\n",
      "  time_total_s: 40.65222406387329\n",
      "  timestamp: 1622064129\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:12,929\tWARNING util.py:162 -- The `start_trial` operation took 0.841 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.06120084515389274 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (26 PENDING, 4 RUNNING, 20 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0479616 | 0.0479616 |                   19 |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0497006 | 0.0497006 |                   13 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0504643 | 0.0541708 |                    1 |\n",
      "| train_d0405_00023 | RUNNING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (18 PENDING, 12 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00020:\n",
      "  date: 2021-05-26_17-22-14\n",
      "  done: false\n",
      "  experiment_id: a1d45da56b034a7ca5092d093a468890\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05036356659496532\n",
      "  mse: 0.055543757503961816\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89631\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 34.14843392372131\n",
      "  time_this_iter_s: 17.457425832748413\n",
      "  time_total_s: 34.14843392372131\n",
      "  timestamp: 1622064134\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00020\n",
      "  \n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-22-15\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 0.04791220264399753\n",
      "  mse: 0.04791220264399753\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 135.45036101341248\n",
      "  time_this_iter_s: 6.351262092590332\n",
      "  time_total_s: 135.45036101341248\n",
      "  timestamp: 1622064135\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: d0405_00009\n",
      "  \n",
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-22-16\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.04961354870881353\n",
      "  mse: 0.04961354870881353\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 47.2088840007782\n",
      "  time_this_iter_s: 3.113255023956299\n",
      "  time_total_s: 47.2088840007782\n",
      "  timestamp: 1622064136\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:18,379\tWARNING util.py:162 -- The `process_trial_save` operation took 0.578 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:18,966\tWARNING util.py:162 -- The `start_trial` operation took 0.584 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=16\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.058372301328927276 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (26 PENDING, 4 RUNNING, 20 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00009 | RUNNING    | 192.168.1.5:89052 |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0479122 | 0.0479122 |                   20 |\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0495662 | 0.0495662 |                   15 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0503636 | 0.0555438 |                    2 |\n",
      "| train_d0405_00023 | RUNNING    |                   |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 |           |           |                      |\n",
      "| train_d0405_00024 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (18 PENDING, 12 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-22-23\n",
      "  done: false\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 21\n",
      "  loss: 0.04787707015433732\n",
      "  mse: 0.04787707015433732\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 143.28829383850098\n",
      "  time_this_iter_s: 7.837932825088501\n",
      "  time_total_s: 143.28829383850098\n",
      "  timestamp: 1622064143\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 21\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:23,985\tWARNING util.py:162 -- The `process_trial_save` operation took 0.506 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:24,383\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00023:\n",
      "  date: 2021-05-26_17-22-24\n",
      "  done: true\n",
      "  experiment_id: 2bc49ac78c5c48aeaa43d1afc237d945\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 10.016561536227956\n",
      "  mse: 10.016561536227956\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89848\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.460765838623047\n",
      "  time_this_iter_s: 6.460765838623047\n",
      "  time_total_s: 6.460765838623047\n",
      "  timestamp: 1622064144\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00023\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:24,735\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00009:\n",
      "  date: 2021-05-26_17-22-23\n",
      "  done: true\n",
      "  experiment_id: 927478317038482297ab4432063afaa5\n",
      "  experiment_tag: 9_batch_size=8,clip=False,loss_f=MSELoss(),lr=0.065187,num_layers=2,optim=adagrad,scaling_factor=0.644\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 21\n",
      "  loss: 0.04787707015433732\n",
      "  mse: 0.04787707015433732\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89052\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 143.28829383850098\n",
      "  time_this_iter_s: 7.837932825088501\n",
      "  time_total_s: 143.28829383850098\n",
      "  timestamp: 1622064143\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 21\n",
      "  trial_id: d0405_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:26,284\tWARNING util.py:162 -- The `start_trial` operation took 0.780 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.055631281808018684 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.058372301328927276 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (25 PENDING, 4 RUNNING, 21 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |  0.0495662 |  0.0495662 |                   15 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |  0.0503636 |  0.0555438 |                    2 |\n",
      "| train_d0405_00023 | RUNNING    | 192.168.1.5:89848 |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 | 10.0166    | 10.0166    |                    1 |\n",
      "| train_d0405_00024 | RUNNING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |            |            |                      |\n",
      "| train_d0405_00025 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |            |            |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |            |            |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |            |            |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |            |            |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |            |            |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |            |            |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |            |            |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |            |            |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "... 30 more trials not shown (17 PENDING, 13 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:28,111\tWARNING util.py:162 -- The `start_trial` operation took 1.090 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-22-23\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 16\n",
      "  loss: 0.04946803771668956\n",
      "  mse: 0.04946803771668956\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 54.80351209640503\n",
      "  time_this_iter_s: 3.149744987487793\n",
      "  time_total_s: 54.80351209640503\n",
      "  timestamp: 1622064143\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:29,594\tWARNING util.py:162 -- The `process_trial_save` operation took 0.531 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:30,206\tWARNING util.py:162 -- The `start_trial` operation took 0.600 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.058372301328927276 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (24 PENDING, 4 RUNNING, 22 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0494596 | 0.0494596 |                   17 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0503636 | 0.0555438 |                    2 |\n",
      "| train_d0405_00024 | RUNNING    |                   |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |           |           |                      |\n",
      "| train_d0405_00025 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (16 PENDING, 14 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:33,424\tWARNING util.py:162 -- The `start_trial` operation took 0.519 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00020:\n",
      "  date: 2021-05-26_17-22-32\n",
      "  done: false\n",
      "  experiment_id: a1d45da56b034a7ca5092d093a468890\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.05013510707546683\n",
      "  mse: 0.05307721679701525\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89631\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 52.36598992347717\n",
      "  time_this_iter_s: 18.21755599975586\n",
      "  time_total_s: 52.36598992347717\n",
      "  timestamp: 1622064152\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:34,826\tWARNING util.py:162 -- The `start_trial` operation took 0.575 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-22-35\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 18\n",
      "  loss: 0.04939618884097962\n",
      "  mse: 0.04939618884097962\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 66.02304196357727\n",
      "  time_this_iter_s: 3.1900417804718018\n",
      "  time_total_s: 66.02304196357727\n",
      "  timestamp: 1622064155\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 18\n",
      "  trial_id: d0405_00019\n",
      "  \n",
      "Result for train_d0405_00024:\n",
      "  date: 2021-05-26_17-22-35\n",
      "  done: false\n",
      "  experiment_id: 9af2c262107f4ca99968bd989d0a9acd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.07820155436084383\n",
      "  mse: 0.0588117635675839\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89934\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.3033883571624756\n",
      "  time_this_iter_s: 3.3033883571624756\n",
      "  time_total_s: 3.3033883571624756\n",
      "  timestamp: 1622064155\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00024\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.058372301328927276 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (24 PENDING, 4 RUNNING, 22 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0493962 | 0.0493962 |                   18 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0501351 | 0.0530772 |                    3 |\n",
      "| train_d0405_00024 | RUNNING    | 192.168.1.5:89934 |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 | 0.0782016 | 0.0588118 |                    1 |\n",
      "| train_d0405_00025 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |           |           |                      |\n",
      "| train_d0405_00026 | PENDING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (16 PENDING, 14 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:37,505\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00025:\n",
      "  date: 2021-05-26_17-22-36\n",
      "  done: true\n",
      "  experiment_id: 18cd1d55b0f14f42937a1d86dd339e47\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.12867712965782951\n",
      "  mse: 0.22516196720740375\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89938\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.103420734405518\n",
      "  time_this_iter_s: 4.103420734405518\n",
      "  time_total_s: 4.103420734405518\n",
      "  timestamp: 1622064156\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00025\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:39,051\tWARNING util.py:162 -- The `start_trial` operation took 0.776 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:40,620\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00024:\n",
      "  date: 2021-05-26_17-22-39\n",
      "  done: true\n",
      "  experiment_id: 9af2c262107f4ca99968bd989d0a9acd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.07764757690685135\n",
      "  mse: 0.05857547443537485\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89934\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.685040235519409\n",
      "  time_this_iter_s: 4.381651878356934\n",
      "  time_total_s: 7.685040235519409\n",
      "  timestamp: 1622064159\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00024\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:42,277\tWARNING util.py:162 -- The `start_trial` operation took 0.860 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.6/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.05857547443537485 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (22 PENDING, 4 RUNNING, 24 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0493372 | 0.0493372 |                   19 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0501351 | 0.0530772 |                    3 |\n",
      "| train_d0405_00026 | RUNNING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | RUNNING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (14 PENDING, 16 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:42,864\tWARNING util.py:162 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-22-42\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 0.04931801247100035\n",
      "  mse: 0.04931801247100035\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 73.12528204917908\n",
      "  time_this_iter_s: 4.100429058074951\n",
      "  time_total_s: 73.12528204917908\n",
      "  timestamp: 1622064162\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:43,619\tWARNING util.py:162 -- The `start_trial` operation took 0.739 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:44,246\tWARNING util.py:162 -- The `process_trial_save` operation took 0.574 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:44,761\tWARNING util.py:162 -- The `start_trial` operation took 0.512 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:47,760\tWARNING util.py:162 -- The `start_trial` operation took 0.506 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-22-49\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 22\n",
      "  loss: 0.04932094773366338\n",
      "  mse: 0.04932094773366338\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 80.25925183296204\n",
      "  time_this_iter_s: 2.9959826469421387\n",
      "  time_total_s: 80.25925183296204\n",
      "  timestamp: 1622064169\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 22\n",
      "  trial_id: d0405_00019\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.2/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05397700011542364 | Iter 2.000: -0.05857547443537485 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (22 PENDING, 4 RUNNING, 24 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0493209 | 0.0493209 |                   22 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0501351 | 0.0530772 |                    3 |\n",
      "| train_d0405_00026 | RUNNING    |                   |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |           |           |                      |\n",
      "| train_d0405_00027 | RUNNING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |           |           |                      |\n",
      "| train_d0405_00028 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (14 PENDING, 16 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:50,506\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00026:\n",
      "  date: 2021-05-26_17-22-49\n",
      "  done: true\n",
      "  experiment_id: d9cce5d5d8824a3f89293eb2ddb9fc55\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.3057955276398432\n",
      "  mse: 3.098228965486799\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89937\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.637589931488037\n",
      "  time_this_iter_s: 6.637589931488037\n",
      "  time_total_s: 6.637589931488037\n",
      "  timestamp: 1622064169\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00026\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:52,190\tWARNING util.py:162 -- The `start_trial` operation took 0.803 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00020:\n",
      "  date: 2021-05-26_17-22-51\n",
      "  done: false\n",
      "  experiment_id: a1d45da56b034a7ca5092d093a468890\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.050170758629546446\n",
      "  mse: 0.05304557996637681\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89631\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 71.19544291496277\n",
      "  time_this_iter_s: 18.829452991485596\n",
      "  time_total_s: 71.19544291496277\n",
      "  timestamp: 1622064171\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00020\n",
      "  \n",
      "Result for train_d0405_00027:\n",
      "  date: 2021-05-26_17-22-52\n",
      "  done: false\n",
      "  experiment_id: d7b0b860ae6545bfbd228f920230e244\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05499733590027865\n",
      "  mse: 0.06395940210889367\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90033\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.86824893951416\n",
      "  time_this_iter_s: 3.86824893951416\n",
      "  time_total_s: 3.86824893951416\n",
      "  timestamp: 1622064172\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00027\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=20\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.05857547443537485 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (21 PENDING, 4 RUNNING, 25 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0492083 | 0.0492083 |                   23 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0501708 | 0.0530456 |                    4 |\n",
      "| train_d0405_00027 | RUNNING    | 192.168.1.5:90033 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 | 0.0549973 | 0.0639594 |                    1 |\n",
      "| train_d0405_00028 | RUNNING    |                   |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |           |           |                      |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (13 PENDING, 17 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:56,402\tWARNING util.py:162 -- The `start_trial` operation took 0.544 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-22-57\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 24\n",
      "  loss: 0.04930674674965087\n",
      "  mse: 0.04930674674965087\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 88.08718204498291\n",
      "  time_this_iter_s: 5.077021837234497\n",
      "  time_total_s: 88.08718204498291\n",
      "  timestamp: 1622064177\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 24\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:22:58,508\tWARNING util.py:162 -- The `start_trial` operation took 0.501 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:22:59,696\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00027:\n",
      "  date: 2021-05-26_17-22-59\n",
      "  done: true\n",
      "  experiment_id: d7b0b860ae6545bfbd228f920230e244\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05270826400202863\n",
      "  mse: 0.06004954510751893\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90033\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 11.098694086074829\n",
      "  time_this_iter_s: 7.230445146560669\n",
      "  time_total_s: 11.098694086074829\n",
      "  timestamp: 1622064179\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00027\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:00,055\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00028:\n",
      "  date: 2021-05-26_17-22-59\n",
      "  done: true\n",
      "  experiment_id: 76338f5b0990473d882b24fa4444bf7f\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.6465044191905431\n",
      "  mse: 3.4750388803936185\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90038\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.9645891189575195\n",
      "  time_this_iter_s: 3.9645891189575195\n",
      "  time_total_s: 3.9645891189575195\n",
      "  timestamp: 1622064179\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00028\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.05931250977144689 | Iter 1.000: -0.1271963311093194\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (21 PENDING, 4 RUNNING, 25 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0493067 | 0.0493067 |                   24 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0501708 | 0.0530456 |                    4 |\n",
      "| train_d0405_00027 | RUNNING    | 192.168.1.5:90033 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 | 0.0527083 | 0.0600495 |                    2 |\n",
      "| train_d0405_00028 | RUNNING    | 192.168.1.5:90038 |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 | 1.6465    | 3.47504   |                    1 |\n",
      "| train_d0405_00029 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (13 PENDING, 17 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:01,413\tWARNING util.py:162 -- The `start_trial` operation took 0.696 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:03,084\tWARNING util.py:162 -- The `start_trial` operation took 0.671 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:04,492\tWARNING util.py:162 -- The `start_trial` operation took 0.519 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-23-06\n",
      "  done: false\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 26\n",
      "  loss: 0.049184119062764306\n",
      "  mse: 0.049184119062764306\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 97.17831897735596\n",
      "  time_this_iter_s: 6.400166749954224\n",
      "  time_total_s: 97.17831897735596\n",
      "  timestamp: 1622064186\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 26\n",
      "  trial_id: d0405_00019\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.05931250977144689 | Iter 1.000: -0.1271963311093194\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (19 PENDING, 4 RUNNING, 27 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00019 | RUNNING    | 192.168.1.5:89551 |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 | 0.0491841 | 0.0491841 |                   26 |\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0501708 | 0.0530456 |                    4 |\n",
      "| train_d0405_00029 | RUNNING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |           |           |                      |\n",
      "| train_d0405_00030 | RUNNING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | PENDING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (11 PENDING, 19 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:07,473\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00019:\n",
      "  date: 2021-05-26_17-23-06\n",
      "  done: true\n",
      "  experiment_id: 0a0e4352f7f34aceb1856220c57a3d50\n",
      "  experiment_tag: 19_batch_size=32,clip=False,loss_f=MSELoss(),lr=0.034031,num_layers=2,optim=adagrad,scaling_factor=0.5898\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 26\n",
      "  loss: 0.049184119062764306\n",
      "  mse: 0.049184119062764306\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89551\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 97.17831897735596\n",
      "  time_this_iter_s: 6.400166749954224\n",
      "  time_total_s: 97.17831897735596\n",
      "  timestamp: 1622064186\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 26\n",
      "  trial_id: d0405_00019\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:08,051\tWARNING util.py:162 -- The `start_trial` operation took 0.566 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:08,640\tWARNING util.py:162 -- The `process_trial_save` operation took 0.583 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:09,694\tWARNING util.py:162 -- The `start_trial` operation took 1.037 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00020:\n",
      "  date: 2021-05-26_17-23-09\n",
      "  done: false\n",
      "  experiment_id: a1d45da56b034a7ca5092d093a468890\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.049792582892319734\n",
      "  mse: 0.05294440787504701\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89631\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 89.2970781326294\n",
      "  time_this_iter_s: 18.101635217666626\n",
      "  time_total_s: 89.2970781326294\n",
      "  timestamp: 1622064189\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:11,482\tWARNING util.py:162 -- The `start_trial` operation took 0.513 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00029:\n",
      "  date: 2021-05-26_17-23-11\n",
      "  done: false\n",
      "  experiment_id: 43b898f787aa4aa7bcb5ab5be936400b\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.057914613435665764\n",
      "  mse: 0.0648958526906513\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90151\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.018556833267212\n",
      "  time_this_iter_s: 5.018556833267212\n",
      "  time_total_s: 5.018556833267212\n",
      "  timestamp: 1622064191\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00029\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.05931250977144689 | Iter 1.000: -0.12192612185719467\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (18 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0497926 | 0.0529444 |                    5 |\n",
      "| train_d0405_00029 | RUNNING    | 192.168.1.5:90151 |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 | 0.0579146 | 0.0648959 |                    1 |\n",
      "| train_d0405_00030 | RUNNING    |                   |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |           |           |                      |\n",
      "| train_d0405_00031 | RUNNING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (10 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:12,021\tWARNING util.py:162 -- The `start_trial` operation took 0.514 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:12,682\tWARNING util.py:162 -- The `process_trial_save` operation took 0.656 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:13,204\tWARNING util.py:162 -- The `start_trial` operation took 0.515 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00030:\n",
      "  date: 2021-05-26_17-23-15\n",
      "  done: false\n",
      "  experiment_id: a9bb6a57c6bd422a92d426ebb1d7cedd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.051452891528606416\n",
      "  mse: 0.051452891528606416\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90154\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.585654020309448\n",
      "  time_this_iter_s: 6.585654020309448\n",
      "  time_total_s: 6.585654020309448\n",
      "  timestamp: 1622064195\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:16,680\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00029:\n",
      "  date: 2021-05-26_17-23-16\n",
      "  done: true\n",
      "  experiment_id: 43b898f787aa4aa7bcb5ab5be936400b\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.057277967887265344\n",
      "  mse: 0.06730275139922187\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90151\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.540816068649292\n",
      "  time_this_iter_s: 5.52225923538208\n",
      "  time_total_s: 10.540816068649292\n",
      "  timestamp: 1622064196\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00029\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.11665591260506994\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (18 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0497926 | 0.0529444 |                    5 |\n",
      "| train_d0405_00029 | RUNNING    | 192.168.1.5:90151 |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 | 0.057278  | 0.0673028 |                    2 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.0514529 | 0.0514529 |                    1 |\n",
      "| train_d0405_00031 | RUNNING    |                   |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |           |           |                      |\n",
      "| train_d0405_00032 | PENDING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (10 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:18,290\tWARNING util.py:162 -- The `start_trial` operation took 0.814 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00031:\n",
      "  date: 2021-05-26_17-23-17\n",
      "  done: false\n",
      "  experiment_id: 41a8be65146141efa6fc9ab007333d06\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.0917953256340254\n",
      "  mse: 0.07281006180814334\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90192\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.587430953979492\n",
      "  time_this_iter_s: 2.587430953979492\n",
      "  time_total_s: 2.587430953979492\n",
      "  timestamp: 1622064197\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00031\n",
      "  \n",
      "Result for train_d0405_00030:\n",
      "  date: 2021-05-26_17-23-20\n",
      "  done: false\n",
      "  experiment_id: a9bb6a57c6bd422a92d426ebb1d7cedd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05141671468668124\n",
      "  mse: 0.05141671468668124\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90154\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 12.199944257736206\n",
      "  time_this_iter_s: 5.614290237426758\n",
      "  time_total_s: 12.199944257736206\n",
      "  timestamp: 1622064200\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:22,008\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00031:\n",
      "  date: 2021-05-26_17-23-21\n",
      "  done: true\n",
      "  experiment_id: 41a8be65146141efa6fc9ab007333d06\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.06956657767295837\n",
      "  mse: 0.06185430394751685\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90192\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.402390003204346\n",
      "  time_this_iter_s: 3.8149590492248535\n",
      "  time_total_s: 6.402390003204346\n",
      "  timestamp: 1622064201\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00031\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=24\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (17 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0497926 | 0.0529444 |                    5 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.0514167 | 0.0514167 |                    2 |\n",
      "| train_d0405_00031 | RUNNING    | 192.168.1.5:90192 |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 | 0.0695666 | 0.0618543 |                    2 |\n",
      "| train_d0405_00032 | RUNNING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (9 PENDING, 21 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:23,672\tWARNING util.py:162 -- The `start_trial` operation took 0.862 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00020:\n",
      "  date: 2021-05-26_17-23-25\n",
      "  done: false\n",
      "  experiment_id: a1d45da56b034a7ca5092d093a468890\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.05002399084760862\n",
      "  mse: 0.05349387272315867\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89631\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 105.73178291320801\n",
      "  time_this_iter_s: 16.434704780578613\n",
      "  time_total_s: 105.73178291320801\n",
      "  timestamp: 1622064205\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d0405_00020\n",
      "  \n",
      "Result for train_d0405_00030:\n",
      "  date: 2021-05-26_17-23-26\n",
      "  done: false\n",
      "  experiment_id: a9bb6a57c6bd422a92d426ebb1d7cedd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.05166317206971786\n",
      "  mse: 0.05166317206971786\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90154\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 17.75552225112915\n",
      "  time_this_iter_s: 5.555577993392944\n",
      "  time_total_s: 17.75552225112915\n",
      "  timestamp: 1622064206\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00030\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=24\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.09823963346497185\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (16 PENDING, 4 RUNNING, 30 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.050024  | 0.0534939 |                    6 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.0516632 | 0.0516632 |                    3 |\n",
      "| train_d0405_00032 | RUNNING    |                   |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |           |           |                      |\n",
      "| train_d0405_00033 | RUNNING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |           |           |                      |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (8 PENDING, 22 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:28,294\tWARNING util.py:162 -- The `start_trial` operation took 0.546 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00032:\n",
      "  date: 2021-05-26_17-23-28\n",
      "  done: false\n",
      "  experiment_id: bf44c69a7bdd40729f4de617e7ac48c2\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.13875093144529005\n",
      "  mse: 0.0735487295424237\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90244\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.241923093795776\n",
      "  time_this_iter_s: 6.241923093795776\n",
      "  time_total_s: 6.241923093795776\n",
      "  timestamp: 1622064208\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00032\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:30,096\tWARNING util.py:162 -- The `start_trial` operation took 0.573 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00033:\n",
      "  date: 2021-05-26_17-23-32\n",
      "  done: false\n",
      "  experiment_id: bea8c962adcf48419c1e852a4ef38cbd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.054545553466852977\n",
      "  mse: 0.06142094656825066\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90274\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.8330910205841064\n",
      "  time_this_iter_s: 4.8330910205841064\n",
      "  time_total_s: 4.8330910205841064\n",
      "  timestamp: 1622064212\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00033\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=24\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (16 PENDING, 4 RUNNING, 30 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.050024  | 0.0534939 |                    6 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.0516632 | 0.0516632 |                    3 |\n",
      "| train_d0405_00032 | RUNNING    | 192.168.1.5:90244 |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 | 0.138751  | 0.0735487 |                    1 |\n",
      "| train_d0405_00033 | RUNNING    | 192.168.1.5:90274 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 | 0.0545456 | 0.0614209 |                    1 |\n",
      "| train_d0405_00034 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (8 PENDING, 22 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00030:\n",
      "  date: 2021-05-26_17-23-33\n",
      "  done: false\n",
      "  experiment_id: a9bb6a57c6bd422a92d426ebb1d7cedd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.051675547308781565\n",
      "  mse: 0.051675547308781565\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90154\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 24.98011541366577\n",
      "  time_this_iter_s: 7.224593162536621\n",
      "  time_total_s: 24.98011541366577\n",
      "  timestamp: 1622064213\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:36,364\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00032:\n",
      "  date: 2021-05-26_17-23-36\n",
      "  done: true\n",
      "  experiment_id: bf44c69a7bdd40729f4de617e7ac48c2\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.11484379899852416\n",
      "  mse: 0.062331868138383414\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90244\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 13.919165849685669\n",
      "  time_this_iter_s: 7.677242755889893\n",
      "  time_total_s: 13.919165849685669\n",
      "  timestamp: 1622064216\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00032\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:38,163\tWARNING util.py:162 -- The `start_trial` operation took 0.868 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=25\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.060625195130705835 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (15 PENDING, 4 RUNNING, 31 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.050024  | 0.0534939 |                    6 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.0516755 | 0.0516755 |                    4 |\n",
      "| train_d0405_00033 | RUNNING    | 192.168.1.5:90274 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 | 0.0545456 | 0.0614209 |                    1 |\n",
      "| train_d0405_00034 | RUNNING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (7 PENDING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00033:\n",
      "  date: 2021-05-26_17-23-37\n",
      "  done: false\n",
      "  experiment_id: bea8c962adcf48419c1e852a4ef38cbd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.053624886800261104\n",
      "  mse: 0.05953643918037414\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90274\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 9.890372037887573\n",
      "  time_this_iter_s: 5.057281017303467\n",
      "  time_total_s: 9.890372037887573\n",
      "  timestamp: 1622064217\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00033\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:39,389\tWARNING util.py:162 -- The `start_trial` operation took 0.734 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:39,997\tWARNING util.py:162 -- The `process_trial_save` operation took 0.599 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:40,510\tWARNING util.py:162 -- The `start_trial` operation took 0.511 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00030:\n",
      "  date: 2021-05-26_17-23-41\n",
      "  done: false\n",
      "  experiment_id: a9bb6a57c6bd422a92d426ebb1d7cedd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.051791430746807775\n",
      "  mse: 0.051791430746807775\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90154\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 32.512726068496704\n",
      "  time_this_iter_s: 7.532610654830933\n",
      "  time_total_s: 32.512726068496704\n",
      "  timestamp: 1622064221\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00030\n",
      "  \n",
      "Result for train_d0405_00020:\n",
      "  date: 2021-05-26_17-23-43\n",
      "  done: false\n",
      "  experiment_id: a1d45da56b034a7ca5092d093a468890\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.049941768979325014\n",
      "  mse: 0.0530751034617424\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89631\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 123.3036789894104\n",
      "  time_this_iter_s: 17.571896076202393\n",
      "  time_total_s: 123.3036789894104\n",
      "  timestamp: 1622064223\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00020\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=25\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (15 PENDING, 4 RUNNING, 31 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0499418 | 0.0530751 |                    7 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.0517914 | 0.0517914 |                    5 |\n",
      "| train_d0405_00033 | RUNNING    | 192.168.1.5:90274 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 | 0.0536249 | 0.0595364 |                    2 |\n",
      "| train_d0405_00034 | RUNNING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (7 PENDING, 23 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:44,701\tWARNING util.py:162 -- The `start_trial` operation took 0.502 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00033:\n",
      "  date: 2021-05-26_17-23-43\n",
      "  done: false\n",
      "  experiment_id: bea8c962adcf48419c1e852a4ef38cbd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.05287438806365518\n",
      "  mse: 0.060666251094902264\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90274\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 15.960347175598145\n",
      "  time_this_iter_s: 6.069975137710571\n",
      "  time_total_s: 15.960347175598145\n",
      "  timestamp: 1622064223\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00033\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:46,157\tWARNING util.py:162 -- The `start_trial` operation took 0.565 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00030:\n",
      "  date: 2021-05-26_17-23-47\n",
      "  done: false\n",
      "  experiment_id: a9bb6a57c6bd422a92d426ebb1d7cedd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.051705954749794565\n",
      "  mse: 0.051705954749794565\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90154\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 38.9502170085907\n",
      "  time_this_iter_s: 6.437490940093994\n",
      "  time_total_s: 38.9502170085907\n",
      "  timestamp: 1622064227\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d0405_00030\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=25\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07874982633134897\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (15 PENDING, 4 RUNNING, 31 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0499418 | 0.0530751 |                    7 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.051706  | 0.051706  |                    6 |\n",
      "| train_d0405_00033 | RUNNING    | 192.168.1.5:90274 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 | 0.0528744 | 0.0606663 |                    3 |\n",
      "| train_d0405_00034 | RUNNING    |                   |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |           |           |                      |\n",
      "| train_d0405_00035 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (7 PENDING, 23 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:49,243\tWARNING util.py:162 -- The `start_trial` operation took 0.526 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:50,294\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00033:\n",
      "  date: 2021-05-26_17-23-50\n",
      "  done: true\n",
      "  experiment_id: bea8c962adcf48419c1e852a4ef38cbd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.052339267204789555\n",
      "  mse: 0.05988082526361241\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90274\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 22.339452028274536\n",
      "  time_this_iter_s: 6.379104852676392\n",
      "  time_total_s: 22.339452028274536\n",
      "  timestamp: 1622064230\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00033\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:51,266\tWARNING util.py:162 -- The `process_trial_save` operation took 0.512 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:52,207\tWARNING util.py:162 -- The `start_trial` operation took 0.929 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:23:52,811\tWARNING util.py:162 -- The `start_trial` operation took 0.601 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-23-51\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05069662948303363\n",
      "  mse: 0.05069662948303363\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.419000148773193\n",
      "  time_this_iter_s: 7.419000148773193\n",
      "  time_total_s: 7.419000148773193\n",
      "  timestamp: 1622064231\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:23:53,452\tWARNING util.py:162 -- The `start_trial` operation took 0.608 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=26\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.0776762983378242\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (14 PENDING, 4 RUNNING, 32 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0499418 | 0.0530751 |                    7 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.051706  | 0.051706  |                    6 |\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0506966 | 0.0506966 |                    1 |\n",
      "| train_d0405_00035 | RUNNING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (6 PENDING, 24 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00030:\n",
      "  date: 2021-05-26_17-23-55\n",
      "  done: false\n",
      "  experiment_id: a9bb6a57c6bd422a92d426ebb1d7cedd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.051480427910299865\n",
      "  mse: 0.051480427910299865\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90154\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 46.38897728919983\n",
      "  time_this_iter_s: 7.438760280609131\n",
      "  time_total_s: 46.38897728919983\n",
      "  timestamp: 1622064235\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00030\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-00\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05018671856207006\n",
      "  mse: 0.05018671856207006\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 16.481200218200684\n",
      "  time_this_iter_s: 9.06220006942749\n",
      "  time_total_s: 16.481200218200684\n",
      "  timestamp: 1622064240\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=26\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05056512938702808 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.05979299214394654 | Iter 1.000: -0.0776762983378242\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (14 PENDING, 4 RUNNING, 32 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00020 | RUNNING    | 192.168.1.5:89631 |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 | 0.0499418 | 0.0530751 |                    7 |\n",
      "| train_d0405_00030 | RUNNING    | 192.168.1.5:90154 |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 | 0.0514804 | 0.0514804 |                    7 |\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0501867 | 0.0501867 |                    2 |\n",
      "| train_d0405_00035 | RUNNING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |           |           |                      |\n",
      "| train_d0405_00036 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (6 PENDING, 24 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00035:\n",
      "  date: 2021-05-26_17-24-00\n",
      "  done: false\n",
      "  experiment_id: 2a3a6ccc00b74359a5884ac798a5fc7d\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05742953788666498\n",
      "  mse: 0.06387351204951604\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90420\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.7144739627838135\n",
      "  time_this_iter_s: 2.7144739627838135\n",
      "  time_total_s: 2.7144739627838135\n",
      "  timestamp: 1622064240\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00035\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:01,901\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00030:\n",
      "  date: 2021-05-26_17-24-01\n",
      "  done: true\n",
      "  experiment_id: a9bb6a57c6bd422a92d426ebb1d7cedd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 8\n",
      "  loss: 0.05184462311513284\n",
      "  mse: 0.05184462311513284\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90154\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 52.93243598937988\n",
      "  time_this_iter_s: 6.543458700180054\n",
      "  time_total_s: 52.93243598937988\n",
      "  timestamp: 1622064241\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d0405_00030\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:03,044\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00020:\n",
      "  date: 2021-05-26_17-24-01\n",
      "  done: true\n",
      "  experiment_id: a1d45da56b034a7ca5092d093a468890\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 8\n",
      "  loss: 0.04990430128048448\n",
      "  mse: 0.05251158365212819\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 89631\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 141.4347279071808\n",
      "  time_this_iter_s: 18.131048917770386\n",
      "  time_total_s: 141.4347279071808\n",
      "  timestamp: 1622064241\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d0405_00020\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:04,901\tWARNING util.py:162 -- The `start_trial` operation took 1.085 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:24:05,272\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00035:\n",
      "  date: 2021-05-26_17-24-04\n",
      "  done: true\n",
      "  experiment_id: 2a3a6ccc00b74359a5884ac798a5fc7d\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05794725886413029\n",
      "  mse: 0.06427617796829768\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90420\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.077518939971924\n",
      "  time_this_iter_s: 4.36304497718811\n",
      "  time_total_s: 7.077518939971924\n",
      "  timestamp: 1622064244\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00035\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=29\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05184462311513284 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07747026819902725\n",
      "Resources requested: 6.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (13 PENDING, 3 RUNNING, 34 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0501867 | 0.0501867 |                    2 |\n",
      "| train_d0405_00035 | RUNNING    | 192.168.1.5:90420 |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 | 0.0579473 | 0.0642762 |                    2 |\n",
      "| train_d0405_00036 | RUNNING    |                   |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |           |           |                      |\n",
      "| train_d0405_00037 | PENDING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | PENDING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (4 PENDING, 25 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:06,998\tWARNING util.py:162 -- The `start_trial` operation took 0.820 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:24:08,356\tWARNING util.py:162 -- The `start_trial` operation took 0.670 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-07\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.04971645008772611\n",
      "  mse: 0.04971645008772611\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 23.415255069732666\n",
      "  time_this_iter_s: 6.934054851531982\n",
      "  time_total_s: 23.415255069732666\n",
      "  timestamp: 1622064247\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-24-12\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.052894385531544685\n",
      "  mse: 0.052894385531544685\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.7637650966644287\n",
      "  time_this_iter_s: 3.7637650966644287\n",
      "  time_total_s: 3.7637650966644287\n",
      "  timestamp: 1622064252\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=29\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05184462311513284 | Iter 4.000: -0.05304557996637681 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.0772642380602303\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (11 PENDING, 4 RUNNING, 35 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0497165 | 0.0497165 |                    3 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0528944 | 0.0528944 |                    1 |\n",
      "| train_d0405_00037 | RUNNING    |                   |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |           |           |                      |\n",
      "| train_d0405_00038 | RUNNING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (3 PENDING, 27 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:14,367\tWARNING util.py:162 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-15\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.049257437873850854\n",
      "  mse: 0.049257437873850854\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 32.188437938690186\n",
      "  time_this_iter_s: 8.77318286895752\n",
      "  time_total_s: 32.188437938690186\n",
      "  timestamp: 1622064255\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00037:\n",
      "  date: 2021-05-26_17-24-16\n",
      "  done: false\n",
      "  experiment_id: 7f4ac96b504f4e75b03d3c4ac178c0bd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.07452639157281202\n",
      "  mse: 0.07452639157281202\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90495\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.259089946746826\n",
      "  time_this_iter_s: 5.259089946746826\n",
      "  time_total_s: 5.259089946746826\n",
      "  timestamp: 1622064256\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00037\n",
      "  \n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-24-17\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.05167255949761186\n",
      "  mse: 0.05167255949761186\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 8.328283071517944\n",
      "  time_this_iter_s: 4.564517974853516\n",
      "  time_total_s: 8.328283071517944\n",
      "  timestamp: 1622064257\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=29\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05184462311513284 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.05979299214394654 | Iter 1.000: -0.07589531481652116\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (11 PENDING, 4 RUNNING, 35 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0492574 | 0.0492574 |                    4 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0516726 | 0.0516726 |                    2 |\n",
      "| train_d0405_00037 | RUNNING    | 192.168.1.5:90495 |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 | 0.0745264 | 0.0745264 |                    1 |\n",
      "| train_d0405_00038 | RUNNING    |                   |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |           |           |                      |\n",
      "| train_d0405_00039 | PENDING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (3 PENDING, 27 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00038:\n",
      "  date: 2021-05-26_17-24-17\n",
      "  done: false\n",
      "  experiment_id: eea5f24a441349ed995a13bd34d3e7d6\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05578935282195316\n",
      "  mse: 0.05870993321432787\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90498\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.191213130950928\n",
      "  time_this_iter_s: 4.191213130950928\n",
      "  time_total_s: 4.191213130950928\n",
      "  timestamp: 1622064257\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00038\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:21,701\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00037:\n",
      "  date: 2021-05-26_17-24-21\n",
      "  done: true\n",
      "  experiment_id: 7f4ac96b504f4e75b03d3c4ac178c0bd\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.07841735359500436\n",
      "  mse: 0.07841735359500436\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90495\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.44373083114624\n",
      "  time_this_iter_s: 5.184640884399414\n",
      "  time_total_s: 10.44373083114624\n",
      "  timestamp: 1622064261\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00037\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:23,216\tWARNING util.py:162 -- The `start_trial` operation took 0.775 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=30\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05184462311513284 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07452639157281202\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (10 PENDING, 4 RUNNING, 36 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0492574 | 0.0492574 |                    4 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0516726 | 0.0516726 |                    2 |\n",
      "| train_d0405_00038 | RUNNING    | 192.168.1.5:90498 |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 | 0.0557894 | 0.0587099 |                    1 |\n",
      "| train_d0405_00039 | RUNNING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (2 PENDING, 28 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-24-23\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.05304816649073646\n",
      "  mse: 0.05304816649073646\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 14.320202112197876\n",
      "  time_this_iter_s: 5.991919040679932\n",
      "  time_total_s: 14.320202112197876\n",
      "  timestamp: 1622064263\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-21\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.04894685128375011\n",
      "  mse: 0.04894685128375011\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 38.194363832473755\n",
      "  time_this_iter_s: 6.005925893783569\n",
      "  time_total_s: 38.194363832473755\n",
      "  timestamp: 1622064261\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:24,278\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00038:\n",
      "  date: 2021-05-26_17-24-22\n",
      "  done: true\n",
      "  experiment_id: eea5f24a441349ed995a13bd34d3e7d6\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.054491680992000247\n",
      "  mse: 0.06038735600955346\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90498\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 9.598536014556885\n",
      "  time_this_iter_s: 5.407322883605957\n",
      "  time_total_s: 9.598536014556885\n",
      "  timestamp: 1622064262\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00038\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:27,196\tWARNING util.py:162 -- The `start_trial` operation took 0.834 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=31\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05184462311513284 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07452639157281202\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (9 PENDING, 4 RUNNING, 37 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0489469 | 0.0489469 |                    5 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0511505 | 0.0511505 |                    4 |\n",
      "| train_d0405_00039 | RUNNING    |                   |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |           |           |                      |\n",
      "| train_d0405_00040 | RUNNING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (1 PENDING, 29 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-24-30\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05164309516549111\n",
      "  mse: 0.05164309516549111\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.178818941116333\n",
      "  time_this_iter_s: 4.178818941116333\n",
      "  time_total_s: 4.178818941116333\n",
      "  timestamp: 1622064270\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-30\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.04856410153648433\n",
      "  mse: 0.04856410153648433\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 47.0578510761261\n",
      "  time_this_iter_s: 8.863487243652344\n",
      "  time_total_s: 47.0578510761261\n",
      "  timestamp: 1622064270\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-24-31\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.052137719555979685\n",
      "  mse: 0.052137719555979685\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 22.404617071151733\n",
      "  time_this_iter_s: 3.527520179748535\n",
      "  time_total_s: 22.404617071151733\n",
      "  timestamp: 1622064271\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=31\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05184462311513284 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (9 PENDING, 4 RUNNING, 37 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0485641 | 0.0485641 |                    6 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0521377 | 0.0521377 |                    5 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0508091 | 0.0508091 |                    2 |\n",
      "| train_d0405_00040 | RUNNING    |                   |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |           |           |                      |\n",
      "| train_d0405_00041 | PENDING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (1 PENDING, 29 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:35,591\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00040:\n",
      "  date: 2021-05-26_17-24-34\n",
      "  done: true\n",
      "  experiment_id: d61a527fdd254f08a4775844a7cc6bb8\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 5.668022133055187\n",
      "  mse: 30.892944608415878\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90623\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.0764667987823486\n",
      "  time_this_iter_s: 3.0764667987823486\n",
      "  time_total_s: 3.0764667987823486\n",
      "  timestamp: 1622064274\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00040\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:36,983\tWARNING util.py:162 -- The `start_trial` operation took 0.699 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:24:37,502\tWARNING worker.py:1115 -- The actor or task with ID ffffffffffffffff65059d52d706bce30fb8973001000000 cannot be scheduled right now. It requires {CPU_group_4cddfc6fd122c1010c5ee1949c39fec7: 2.000000}, {CPU_group_0_4cddfc6fd122c1010c5ee1949c39fec7: 2.000000} for placement, but this node only has remaining {0.000000/8.000000 CPU, 4.365848 GiB/4.365848 GiB memory, 2.182924 GiB/2.182924 GiB object_store_memory, 0.000000/2.000000 CPU_group_0_8913d1bdb45bc4a370efe8e1587a8884, 1.000000/1.000000 node:192.168.1.5, 0.000000/2.000000 CPU_group_0_4fc2d060e64dae735e7065288c1e4d36, 2.000000/2.000000 CPU_group_0_4cddfc6fd122c1010c5ee1949c39fec7, 0.000000/2.000000 CPU_group_8913d1bdb45bc4a370efe8e1587a8884, 2.000000/2.000000 CPU_group_4cddfc6fd122c1010c5ee1949c39fec7, 0.000000/2.000000 CPU_group_687cf31d877f7774f53c00e21badfc96, 0.000000/2.000000 CPU_group_0_687cf31d877f7774f53c00e21badfc96, 0.000000/2.000000 CPU_group_4fc2d060e64dae735e7065288c1e4d36}\n",
      ". In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-24-35\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.05171661265194416\n",
      "  mse: 0.05171661265194416\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.093394994735718\n",
      "  time_this_iter_s: 3.6887779235839844\n",
      "  time_total_s: 26.093394994735718\n",
      "  timestamp: 1622064275\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-37\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.04861031267791986\n",
      "  mse: 0.04861031267791986\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 54.04423499107361\n",
      "  time_this_iter_s: 6.98638391494751\n",
      "  time_total_s: 54.04423499107361\n",
      "  timestamp: 1622064277\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-24-38\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.05063431743970689\n",
      "  mse: 0.05063431743970689\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 12.669607877731323\n",
      "  time_this_iter_s: 4.189741849899292\n",
      "  time_total_s: 12.669607877731323\n",
      "  timestamp: 1622064278\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=32\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05184462311513284 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07452639157281202\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (8 PENDING, 4 RUNNING, 38 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0486103 | 0.0486103 |                    7 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0517166 | 0.0517166 |                    6 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0506343 | 0.0506343 |                    3 |\n",
      "| train_d0405_00041 | RUNNING    |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |           |           |                      |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00041:\n",
      "  date: 2021-05-26_17-24-43\n",
      "  done: false\n",
      "  experiment_id: 910e0a4b73564de3927b56203bc37cac\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05888011924484197\n",
      "  mse: 0.06627676337957382\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90692\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.127993106842041\n",
      "  time_this_iter_s: 3.127993106842041\n",
      "  time_total_s: 3.127993106842041\n",
      "  timestamp: 1622064283\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00041\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=32\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05184462311513284 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (8 PENDING, 4 RUNNING, 38 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0486103 | 0.0486103 |                    7 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0517309 | 0.0517309 |                    7 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0505368 | 0.0505368 |                    4 |\n",
      "| train_d0405_00041 | RUNNING    | 192.168.1.5:90692 |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 | 0.0588801 | 0.0662768 |                    1 |\n",
      "| train_d0405_00042 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-45\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 8\n",
      "  loss: 0.04816733580082655\n",
      "  mse: 0.04816733580082655\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.77548003196716\n",
      "  time_this_iter_s: 7.731245040893555\n",
      "  time_total_s: 61.77548003196716\n",
      "  timestamp: 1622064285\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-24-44\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 8\n",
      "  loss: 0.05117672016578061\n",
      "  mse: 0.05117672016578061\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 35.57138419151306\n",
      "  time_this_iter_s: 3.773005247116089\n",
      "  time_total_s: 35.57138419151306\n",
      "  timestamp: 1622064284\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-24-47\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.050448148511350155\n",
      "  mse: 0.050448148511350155\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 21.53141188621521\n",
      "  time_this_iter_s: 4.239211082458496\n",
      "  time_total_s: 21.53141188621521\n",
      "  timestamp: 1622064287\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: d0405_00039\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:49,156\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00041:\n",
      "  date: 2021-05-26_17-24-47\n",
      "  done: true\n",
      "  experiment_id: 910e0a4b73564de3927b56203bc37cac\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.057145386013914556\n",
      "  mse: 0.06395130613270927\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90692\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.005431175231934\n",
      "  time_this_iter_s: 3.8774380683898926\n",
      "  time_total_s: 7.005431175231934\n",
      "  timestamp: 1622064287\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00041\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:24:50,657\tWARNING util.py:162 -- The `start_trial` operation took 0.733 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.7/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05117672016578061 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (7 PENDING, 4 RUNNING, 39 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0481673 | 0.0481673 |                    8 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0511767 | 0.0511767 |                    8 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0504481 | 0.0504481 |                    5 |\n",
      "| train_d0405_00042 | RUNNING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-51\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.04790365626925931\n",
      "  mse: 0.04790365626925931\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 67.52040910720825\n",
      "  time_this_iter_s: 5.744929075241089\n",
      "  time_total_s: 67.52040910720825\n",
      "  timestamp: 1622064291\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-24-54\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.05288862091089998\n",
      "  mse: 0.05288862091089998\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 45.277403116226196\n",
      "  time_this_iter_s: 3.9660651683807373\n",
      "  time_total_s: 45.277403116226196\n",
      "  timestamp: 1622064294\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-24-56\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 7\n",
      "  loss: 0.050338986559825785\n",
      "  mse: 0.050338986559825785\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 30.763160943984985\n",
      "  time_this_iter_s: 4.603353977203369\n",
      "  time_total_s: 30.763160943984985\n",
      "  timestamp: 1622064296\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 7\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05117672016578061 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (7 PENDING, 4 RUNNING, 39 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0479037 | 0.0479037 |                    9 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0528886 | 0.0528886 |                   10 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.050339  | 0.050339  |                    7 |\n",
      "| train_d0405_00042 | RUNNING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-24-59\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.0477444730589495\n",
      "  mse: 0.0477444730589495\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 75.32271218299866\n",
      "  time_this_iter_s: 7.802303075790405\n",
      "  time_total_s: 75.32271218299866\n",
      "  timestamp: 1622064299\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d0405_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:00,586\tWARNING util.py:162 -- The `start_trial` operation took 0.608 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-25-01\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 8\n",
      "  loss: 0.050297185625223555\n",
      "  mse: 0.050297185625223555\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 35.900086879730225\n",
      "  time_this_iter_s: 5.136925935745239\n",
      "  time_total_s: 35.900086879730225\n",
      "  timestamp: 1622064301\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 8\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (7 PENDING, 4 RUNNING, 39 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0477445 | 0.0477445 |                   10 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.051972  | 0.051972  |                   11 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0502972 | 0.0502972 |                    8 |\n",
      "| train_d0405_00042 | RUNNING    |                   |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |           |           |                      |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-25-02\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.05058890465824377\n",
      "  mse: 0.05058890465824377\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 53.376952171325684\n",
      "  time_this_iter_s: 4.401710033416748\n",
      "  time_total_s: 53.376952171325684\n",
      "  timestamp: 1622064302\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "Result for train_d0405_00042:\n",
      "  date: 2021-05-26_17-25-02\n",
      "  done: false\n",
      "  experiment_id: 6971167505d2464b8ac667f2d97b38fc\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.11305880765704547\n",
      "  mse: 0.05990238895311075\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90794\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 8.101820945739746\n",
      "  time_this_iter_s: 8.101820945739746\n",
      "  time_total_s: 8.101820945739746\n",
      "  timestamp: 1622064302\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00042\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-25-05\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 11\n",
      "  loss: 0.04801486785359242\n",
      "  mse: 0.04801486785359242\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 82.02108311653137\n",
      "  time_this_iter_s: 6.698370933532715\n",
      "  time_total_s: 82.02108311653137\n",
      "  timestamp: 1622064305\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.0735487295424237\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (7 PENDING, 4 RUNNING, 39 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0480149 | 0.0480149 |                   11 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0505889 | 0.0505889 |                   12 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0502709 | 0.0502709 |                    9 |\n",
      "| train_d0405_00042 | RUNNING    | 192.168.1.5:90794 |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 | 0.113059  | 0.0599024 |                    1 |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-25-07\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 13\n",
      "  loss: 0.051161144549647965\n",
      "  mse: 0.051161144549647965\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 58.06533408164978\n",
      "  time_this_iter_s: 4.688381910324097\n",
      "  time_total_s: 58.06533408164978\n",
      "  timestamp: 1622064307\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 13\n",
      "  trial_id: d0405_00036\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:09,498\tWARNING util.py:162 -- The `start_trial` operation took 0.635 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-25-12\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.0502372849294368\n",
      "  mse: 0.0502372849294368\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 46.446305990219116\n",
      "  time_this_iter_s: 6.081843852996826\n",
      "  time_total_s: 46.446305990219116\n",
      "  timestamp: 1622064312\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.0735487295424237\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (7 PENDING, 4 RUNNING, 39 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0480149 | 0.0480149 |                   11 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0511611 | 0.0511611 |                   13 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0502373 | 0.0502373 |                   10 |\n",
      "| train_d0405_00042 | RUNNING    | 192.168.1.5:90794 |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 | 0.113059  | 0.0599024 |                    1 |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-25-12\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.04744421280920506\n",
      "  mse: 0.04744421280920506\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 88.98083996772766\n",
      "  time_this_iter_s: 6.959756851196289\n",
      "  time_total_s: 88.98083996772766\n",
      "  timestamp: 1622064312\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00042:\n",
      "  date: 2021-05-26_17-25-13\n",
      "  done: false\n",
      "  experiment_id: 6971167505d2464b8ac667f2d97b38fc\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.08978979710270377\n",
      "  mse: 0.05688988277140786\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90794\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 18.647331714630127\n",
      "  time_this_iter_s: 10.54551076889038\n",
      "  time_total_s: 18.647331714630127\n",
      "  timestamp: 1622064313\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00042\n",
      "  \n",
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-25-13\n",
      "  done: false\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.05184056370386055\n",
      "  mse: 0.05184056370386055\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 63.99015021324158\n",
      "  time_this_iter_s: 5.924816131591797\n",
      "  time_total_s: 63.99015021324158\n",
      "  timestamp: 1622064313\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00036\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:16,823\tWARNING util.py:162 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:17,968\tWARNING util.py:162 -- The `start_trial` operation took 0.560 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:17,977\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00036:\n",
      "  date: 2021-05-26_17-25-13\n",
      "  done: true\n",
      "  experiment_id: 223a1f49677d4fd2b1ec427e4404fa6c\n",
      "  experiment_tag: 36_batch_size=32,clip=False,loss_f=MSELoss(),lr=0.044304,num_layers=3,optim=adam,scaling_factor=0.78417\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.05184056370386055\n",
      "  mse: 0.05184056370386055\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90486\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 63.99015021324158\n",
      "  time_this_iter_s: 5.924816131591797\n",
      "  time_total_s: 63.99015021324158\n",
      "  timestamp: 1622064313\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00036\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.0735487295424237\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (7 PENDING, 4 RUNNING, 39 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0474442 | 0.0474442 |                   12 |\n",
      "| train_d0405_00036 | RUNNING    | 192.168.1.5:90486 |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 | 0.0518406 | 0.0518406 |                   14 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0502373 | 0.0502373 |                   10 |\n",
      "| train_d0405_00042 | RUNNING    | 192.168.1.5:90794 |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 | 0.0897898 | 0.0568899 |                    2 |\n",
      "| train_d0405_00043 | PENDING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:18,596\tWARNING util.py:162 -- The `start_trial` operation took 0.597 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:19,132\tWARNING util.py:162 -- The `process_trial_save` operation took 0.535 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:20,275\tWARNING util.py:162 -- The `start_trial` operation took 1.140 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:20,856\tWARNING util.py:162 -- The `start_trial` operation took 0.574 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-25-19\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 11\n",
      "  loss: 0.05019029820447459\n",
      "  mse: 0.05019029820447459\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 53.37099003791809\n",
      "  time_this_iter_s: 6.924684047698975\n",
      "  time_total_s: 53.37099003791809\n",
      "  timestamp: 1622064319\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 11\n",
      "  trial_id: d0405_00039\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:21,432\tWARNING util.py:162 -- The `start_trial` operation took 0.552 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:22,010\tWARNING util.py:162 -- The `process_trial_save` operation took 0.575 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:22,595\tWARNING util.py:162 -- The `start_trial` operation took 0.581 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-25-23\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 13\n",
      "  loss: 0.0473842823987498\n",
      "  mse: 0.0473842823987498\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 100.05365514755249\n",
      "  time_this_iter_s: 11.072815179824829\n",
      "  time_total_s: 100.05365514755249\n",
      "  timestamp: 1622064323\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 13\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.0735487295424237\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (6 PENDING, 4 RUNNING, 40 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0473843 | 0.0473843 |                   13 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0501903 | 0.0501903 |                   11 |\n",
      "| train_d0405_00042 | RUNNING    | 192.168.1.5:90794 |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 | 0.0897898 | 0.0568899 |                    2 |\n",
      "| train_d0405_00043 | RUNNING    |                   |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |           |           |                      |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00042:\n",
      "  date: 2021-05-26_17-25-24\n",
      "  done: false\n",
      "  experiment_id: 6971167505d2464b8ac667f2d97b38fc\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.08593116030097007\n",
      "  mse: 0.05759291686117649\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90794\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 30.36756181716919\n",
      "  time_this_iter_s: 11.720230102539062\n",
      "  time_total_s: 30.36756181716919\n",
      "  timestamp: 1622064324\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00042\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:26,539\tWARNING util.py:162 -- The `start_trial` operation took 0.669 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-25-26\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 12\n",
      "  loss: 0.05014714719179798\n",
      "  mse: 0.05014714719179798\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.691450119018555\n",
      "  time_this_iter_s: 7.320460081100464\n",
      "  time_total_s: 60.691450119018555\n",
      "  timestamp: 1622064326\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 12\n",
      "  trial_id: d0405_00039\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:28,357\tWARNING util.py:162 -- The `start_trial` operation took 0.603 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:29,125\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00043:\n",
      "  date: 2021-05-26_17-25-29\n",
      "  done: true\n",
      "  experiment_id: d6e787f813cf4c7180d16ada184c0f74\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.08316312845618952\n",
      "  mse: 0.08316312845618952\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90973\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.3350400924682617\n",
      "  time_this_iter_s: 3.3350400924682617\n",
      "  time_total_s: 3.3350400924682617\n",
      "  timestamp: 1622064329\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00043\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=34\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (6 PENDING, 4 RUNNING, 40 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0473843 | 0.0473843 |                   13 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0501471 | 0.0501471 |                   12 |\n",
      "| train_d0405_00042 | RUNNING    | 192.168.1.5:90794 |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 | 0.0859312 | 0.0575929 |                    3 |\n",
      "| train_d0405_00043 | RUNNING    | 192.168.1.5:90973 |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 | 0.0831631 | 0.0831631 |                    1 |\n",
      "| train_d0405_00044 | PENDING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:30,865\tWARNING util.py:162 -- The `start_trial` operation took 0.926 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-25-31\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.04725699417073937\n",
      "  mse: 0.04725699417073937\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 107.99283719062805\n",
      "  time_this_iter_s: 7.9391820430755615\n",
      "  time_total_s: 107.99283719062805\n",
      "  timestamp: 1622064331\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:32,268\tWARNING util.py:162 -- The `start_trial` operation took 0.538 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:32,919\tWARNING util.py:162 -- The `process_trial_save` operation took 0.648 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-25-32\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 13\n",
      "  loss: 0.050121212487711626\n",
      "  mse: 0.050121212487711626\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 66.78886198997498\n",
      "  time_this_iter_s: 6.097411870956421\n",
      "  time_total_s: 66.78886198997498\n",
      "  timestamp: 1622064332\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 13\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=34\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05141304639332435 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (5 PENDING, 4 RUNNING, 41 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.047257  | 0.047257  |                   14 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0501212 | 0.0501212 |                   13 |\n",
      "| train_d0405_00042 | RUNNING    | 192.168.1.5:90794 |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 | 0.0859312 | 0.0575929 |                    3 |\n",
      "| train_d0405_00044 | RUNNING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | PENDING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:34,746\tWARNING util.py:162 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:35,533\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00042:\n",
      "  date: 2021-05-26_17-25-35\n",
      "  done: true\n",
      "  experiment_id: 6971167505d2464b8ac667f2d97b38fc\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.0783540138426949\n",
      "  mse: 0.05613016729407451\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90794\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 41.10959267616272\n",
      "  time_this_iter_s: 10.74203085899353\n",
      "  time_total_s: 41.10959267616272\n",
      "  timestamp: 1622064335\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00042\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:37,718\tWARNING util.py:162 -- The `start_trial` operation took 1.269 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:38,633\tWARNING util.py:162 -- The `start_trial` operation took 0.910 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-25-40\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 14\n",
      "  loss: 0.05006138121380525\n",
      "  mse: 0.05006138121380525\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 74.1004090309143\n",
      "  time_this_iter_s: 7.311547040939331\n",
      "  time_total_s: 74.1004090309143\n",
      "  timestamp: 1622064340\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 14\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=35\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (4 PENDING, 4 RUNNING, 42 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.047257  | 0.047257  |                   14 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0500614 | 0.0500614 |                   14 |\n",
      "| train_d0405_00044 | RUNNING    |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |           |           |                      |\n",
      "| train_d0405_00045 | RUNNING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | PENDING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 | 2.0577    | 4.25341   |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-25-40\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 15\n",
      "  loss: 0.04719219818053877\n",
      "  mse: 0.04719219818053877\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 117.098473072052\n",
      "  time_this_iter_s: 9.10563588142395\n",
      "  time_total_s: 117.098473072052\n",
      "  timestamp: 1622064340\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 15\n",
      "  trial_id: d0405_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:41,806\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00044:\n",
      "  date: 2021-05-26_17-25-41\n",
      "  done: true\n",
      "  experiment_id: b8429f24660244aa837e79667cf48fc5\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.16893831214734487\n",
      "  mse: 0.11727834723535038\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91025\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.246193170547485\n",
      "  time_this_iter_s: 4.246193170547485\n",
      "  time_total_s: 4.246193170547485\n",
      "  timestamp: 1622064341\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00044\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:43,204\tWARNING util.py:162 -- The `start_trial` operation took 0.688 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:44,730\tWARNING util.py:162 -- The `start_trial` operation took 0.751 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=36\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05254965976235412 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07452639157281202\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (3 PENDING, 4 RUNNING, 43 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0471922 | 0.0471922 |                   15 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0500489 | 0.0500489 |                   15 |\n",
      "| train_d0405_00045 | RUNNING    |                   |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |           |           |                      |\n",
      "| train_d0405_00046 | RUNNING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | PENDING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 | 2.0577    | 4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 | 0.603441  | 0.991296  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:46,775\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00045:\n",
      "  date: 2021-05-26_17-25-46\n",
      "  done: true\n",
      "  experiment_id: 90a25ad1e02940ae83952e2e80c5d161\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 5.272827784220378\n",
      "  mse: 26.75925672621954\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91062\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.674935817718506\n",
      "  time_this_iter_s: 3.674935817718506\n",
      "  time_total_s: 3.674935817718506\n",
      "  timestamp: 1622064346\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00045\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:48,483\tWARNING util.py:162 -- The `start_trial` operation took 0.865 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:49,053\tWARNING util.py:162 -- The `start_trial` operation took 0.566 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-25-50\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 16\n",
      "  loss: 0.05001901623738163\n",
      "  mse: 0.05001901623738163\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.36709189414978\n",
      "  time_this_iter_s: 5.392781019210815\n",
      "  time_total_s: 84.36709189414978\n",
      "  timestamp: 1622064350\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=37\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.05001901623738163 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.07589531481652116\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (2 PENDING, 4 RUNNING, 44 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0471922 | 0.0471922 |                   15 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.050019  | 0.050019  |                   16 |\n",
      "| train_d0405_00046 | RUNNING    |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |           |           |                      |\n",
      "| train_d0405_00047 | RUNNING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | PENDING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 | 2.0577    | 4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 | 0.603441  | 0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 | 0.698556  | 0.792826  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-25-50\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 16\n",
      "  loss: 0.047005254074054606\n",
      "  mse: 0.047005254074054606\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 126.84496998786926\n",
      "  time_this_iter_s: 9.74649691581726\n",
      "  time_total_s: 126.84496998786926\n",
      "  timestamp: 1622064350\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  trial_id: d0405_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:51,916\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00046:\n",
      "  date: 2021-05-26_17-25-51\n",
      "  done: true\n",
      "  experiment_id: 8a49767aac1a48c395c89428f32699cc\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.3083064215523856\n",
      "  mse: 0.5166343670515787\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91099\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.9353010654449463\n",
      "  time_this_iter_s: 2.9353010654449463\n",
      "  time_total_s: 2.9353010654449463\n",
      "  timestamp: 1622064351\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00046\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:25:54,288\tWARNING util.py:162 -- The `start_trial` operation took 0.929 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:25:54,831\tWARNING util.py:162 -- The `start_trial` operation took 0.541 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-25-58\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 17\n",
      "  loss: 0.046916266158223155\n",
      "  mse: 0.046916266158223155\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 134.28177690505981\n",
      "  time_this_iter_s: 7.436806917190552\n",
      "  time_total_s: 134.28177690505981\n",
      "  timestamp: 1622064358\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 17\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=38\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.06004954510751893 | Iter 1.000: -0.0772642380602303\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (1 PENDING, 4 RUNNING, 45 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0469163 | 0.0469163 |                   17 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0500024 | 0.0500024 |                   17 |\n",
      "| train_d0405_00047 | RUNNING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00048 | RUNNING    |                   |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |           |           |                      |\n",
      "| train_d0405_00049 | PENDING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 | 2.0577    | 4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 | 0.603441  | 0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 | 0.698556  | 0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 | 0.23171   | 0.127196  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00048:\n",
      "  date: 2021-05-26_17-25-59\n",
      "  done: false\n",
      "  experiment_id: e91c7ba554d1451b9f2e701097e93176\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.1534678822471982\n",
      "  mse: 0.07065819008719354\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91125\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.5112781524658203\n",
      "  time_this_iter_s: 1.5112781524658203\n",
      "  time_total_s: 1.5112781524658203\n",
      "  timestamp: 1622064359\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00048\n",
      "  \n",
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-25-59\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 18\n",
      "  loss: 0.04999216532005983\n",
      "  mse: 0.04999216532005983\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 93.48734092712402\n",
      "  time_this_iter_s: 4.4372239112854\n",
      "  time_total_s: 93.48734092712402\n",
      "  timestamp: 1622064359\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 18\n",
      "  trial_id: d0405_00039\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:26:01,606\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00048:\n",
      "  date: 2021-05-26_17-26-01\n",
      "  done: true\n",
      "  experiment_id: e91c7ba554d1451b9f2e701097e93176\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.12936458381868543\n",
      "  mse: 0.061496456464131675\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91125\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.2307112216949463\n",
      "  time_this_iter_s: 1.719433069229126\n",
      "  time_total_s: 3.2307112216949463\n",
      "  timestamp: 1622064361\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00048\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:26:03,193\tWARNING util.py:162 -- The `start_trial` operation took 0.686 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.8/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=39\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07589531481652116\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (4 RUNNING, 46 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0469163 | 0.0469163 |                   17 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0499922 | 0.0499922 |                   18 |\n",
      "| train_d0405_00047 | RUNNING    |                   |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |           |           |                      |\n",
      "| train_d0405_00049 | RUNNING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 | 2.0577    | 4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 | 0.603441  | 0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 | 0.698556  | 0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 | 0.23171   | 0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 | 0.0518497 | 0.0595102 |                    4 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00047:\n",
      "  date: 2021-05-26_17-26-02\n",
      "  done: false\n",
      "  experiment_id: 6ebea7e0a62441b4abf52e6eb00719f8\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.06726854811696445\n",
      "  mse: 0.05545409304254195\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91122\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 8.9288010597229\n",
      "  time_this_iter_s: 8.9288010597229\n",
      "  time_total_s: 8.9288010597229\n",
      "  timestamp: 1622064362\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00047\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-03\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 18\n",
      "  loss: 0.0469078501138617\n",
      "  mse: 0.0469078501138617\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 140.00534391403198\n",
      "  time_this_iter_s: 5.723567008972168\n",
      "  time_total_s: 140.00534391403198\n",
      "  timestamp: 1622064363\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 18\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-26-09\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 0.04996572671567692\n",
      "  mse: 0.04996572671567692\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 103.14776492118835\n",
      "  time_this_iter_s: 4.473331928253174\n",
      "  time_total_s: 103.14776492118835\n",
      "  timestamp: 1622064369\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=39\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07452639157281202\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (4 RUNNING, 46 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |      loss |       mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 | 0.0469079 | 0.0469079 |                   18 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 | 0.0499657 | 0.0499657 |                   20 |\n",
      "| train_d0405_00047 | RUNNING    | 192.168.1.5:91122 |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   | 0.0672685 | 0.0554541 |                    1 |\n",
      "| train_d0405_00049 | RUNNING    |                   |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |           |           |                      |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 | 0.286652  | 0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 | 0.724443  | 0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 | 0.0732566 | 0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 | 0.480108  | 0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  | 0.0744514 | 0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 | 0.057053  | 0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 | 0.0504284 | 0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 | 0.0496854 | 0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 | 0.226398  | 0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 | 0.0478771 | 0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 | 0.0673802 | 0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 | 2.0577    | 4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 | 0.603441  | 0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 | 0.698556  | 0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 | 0.23171   | 0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 | 0.0518497 | 0.0595102 |                    4 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+-----------+-----------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-09\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 19\n",
      "  loss: 0.04685579973327763\n",
      "  mse: 0.04685579973327763\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 146.12314796447754\n",
      "  time_this_iter_s: 6.117804050445557\n",
      "  time_total_s: 146.12314796447754\n",
      "  timestamp: 1622064369\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 19\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00049:\n",
      "  date: 2021-05-26_17-26-10\n",
      "  done: false\n",
      "  experiment_id: 6d888f6257b14fd6bef70ea920bc5134\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.05768645359646706\n",
      "  mse: 0.06533168380459149\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91226\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.139950752258301\n",
      "  time_this_iter_s: 3.139950752258301\n",
      "  time_total_s: 3.139950752258301\n",
      "  timestamp: 1622064370\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d0405_00049\n",
      "  \n",
      "Result for train_d0405_00047:\n",
      "  date: 2021-05-26_17-26-13\n",
      "  done: false\n",
      "  experiment_id: 6ebea7e0a62441b4abf52e6eb00719f8\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.06055903614443891\n",
      "  mse: 0.055476840684080826\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91122\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 19.830190896987915\n",
      "  time_this_iter_s: 10.901389837265015\n",
      "  time_total_s: 19.830190896987915\n",
      "  timestamp: 1622064373\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00047\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:26:13,963\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': <function WSE at 0x14d1fb8c0>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00049:\n",
      "  date: 2021-05-26_17-26-13\n",
      "  done: true\n",
      "  experiment_id: 6d888f6257b14fd6bef70ea920bc5134\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.056626184533039726\n",
      "  mse: 0.06373511219308489\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91226\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.2980780601501465\n",
      "  time_this_iter_s: 3.1581273078918457\n",
      "  time_total_s: 6.2980780601501465\n",
      "  timestamp: 1622064373\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: d0405_00049\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=40\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 6.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (3 RUNNING, 47 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |  0.0468558 |  0.0468558 |                   19 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |  0.0499657 |  0.0499657 |                   20 |\n",
      "| train_d0405_00047 | RUNNING    | 192.168.1.5:91122 |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |  0.060559  |  0.0554768 |                    2 |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |  0.226398  |  0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |  0.0478771 |  0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |  0.0673802 |  0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |  2.0577    |  4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |  0.603441  |  0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |  0.698556  |  0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |  0.23171   |  0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |  0.0518497 |  0.0595102 |                    4 |\n",
      "| train_d0405_00016 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 | 16.1043    | 32.2068    |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-26-14\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 21\n",
      "  loss: 0.049888269252636855\n",
      "  mse: 0.049888269252636855\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 108.00331902503967\n",
      "  time_this_iter_s: 4.855554103851318\n",
      "  time_total_s: 108.00331902503967\n",
      "  timestamp: 1622064374\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 21\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-16\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 0.0467655502478866\n",
      "  mse: 0.0467655502478866\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 152.3271632194519\n",
      "  time_this_iter_s: 6.204015254974365\n",
      "  time_total_s: 152.3271632194519\n",
      "  timestamp: 1622064376\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00047:\n",
      "  date: 2021-05-26_17-26-21\n",
      "  done: false\n",
      "  experiment_id: 6ebea7e0a62441b4abf52e6eb00719f8\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 3\n",
      "  loss: 0.057261865103946014\n",
      "  mse: 0.05561387302244411\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91122\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 28.533254861831665\n",
      "  time_this_iter_s: 8.70306396484375\n",
      "  time_total_s: 28.533254861831665\n",
      "  timestamp: 1622064381\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 3\n",
      "  trial_id: d0405_00047\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=40\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 6.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (3 RUNNING, 47 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |  0.0467656 |  0.0467656 |                   20 |\n",
      "| train_d0405_00039 | RUNNING    | 192.168.1.5:90501 |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |  0.0498936 |  0.0498936 |                   22 |\n",
      "| train_d0405_00047 | RUNNING    | 192.168.1.5:91122 |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |  0.0572619 |  0.0556139 |                    3 |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |  0.226398  |  0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |  0.0478771 |  0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |  0.0673802 |  0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |  2.0577    |  4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |  0.603441  |  0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |  0.698556  |  0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |  0.23171   |  0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |  0.0518497 |  0.0595102 |                    4 |\n",
      "| train_d0405_00016 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 | 16.1043    | 32.2068    |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-21\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 21\n",
      "  loss: 0.04672475265448584\n",
      "  mse: 0.04672475265448584\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 158.00034308433533\n",
      "  time_this_iter_s: 5.673179864883423\n",
      "  time_total_s: 158.00034308433533\n",
      "  timestamp: 1622064381\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 21\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-26-22\n",
      "  done: false\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 23\n",
      "  loss: 0.04985437944312306\n",
      "  mse: 0.04985437944312306\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 116.5799081325531\n",
      "  time_this_iter_s: 4.080258131027222\n",
      "  time_total_s: 116.5799081325531\n",
      "  timestamp: 1622064382\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 23\n",
      "  trial_id: d0405_00039\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:26:23,135\tWARNING util.py:162 -- The `process_trial_save` operation took 0.502 s, which may be a performance bottleneck.\n",
      "2021-05-26 17:26:23,152\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00039:\n",
      "  date: 2021-05-26_17-26-22\n",
      "  done: true\n",
      "  experiment_id: 9cb92d013f9d4bb7bf7e7cf9b928f932\n",
      "  experiment_tag: 39_batch_size=8,clip=False,loss_f=MSELoss(),lr=0.0012582,num_layers=1,optim=adagrad,scaling_factor=0.57432\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 23\n",
      "  loss: 0.04985437944312306\n",
      "  mse: 0.04985437944312306\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 116.5799081325531\n",
      "  time_this_iter_s: 4.080258131027222\n",
      "  time_total_s: 116.5799081325531\n",
      "  timestamp: 1622064382\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 23\n",
      "  trial_id: d0405_00039\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-27\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 22\n",
      "  loss: 0.04676541243405903\n",
      "  mse: 0.04676541243405903\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 163.73625493049622\n",
      "  time_this_iter_s: 5.735911846160889\n",
      "  time_total_s: 163.73625493049622\n",
      "  timestamp: 1622064387\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 22\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=40\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.051675547308781565 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 4.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (2 RUNNING, 48 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |  0.0467654 |  0.0467654 |                   22 |\n",
      "| train_d0405_00047 | RUNNING    | 192.168.1.5:91122 |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |  0.0572619 |  0.0556139 |                    3 |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |  0.226398  |  0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |  0.0478771 |  0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |  0.0673802 |  0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |  2.0577    |  4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |  0.603441  |  0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |  0.698556  |  0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |  0.23171   |  0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |  0.0518497 |  0.0595102 |                    4 |\n",
      "| train_d0405_00016 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 | 16.1043    | 32.2068    |                    1 |\n",
      "| train_d0405_00017 | TERMINATED |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |  0.0945152 |  0.134427  |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:26:29,666\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': L1Loss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00047:\n",
      "  date: 2021-05-26_17-26-29\n",
      "  done: true\n",
      "  experiment_id: 6ebea7e0a62441b4abf52e6eb00719f8\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 4\n",
      "  loss: 0.055660580558811915\n",
      "  mse: 0.055398032792350824\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 91122\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 36.47389078140259\n",
      "  time_this_iter_s: 7.940635919570923\n",
      "  time_total_s: 36.47389078140259\n",
      "  timestamp: 1622064389\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 4\n",
      "  trial_id: d0405_00047\n",
      "  \n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-35\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 24\n",
      "  loss: 0.04653151355245534\n",
      "  mse: 0.04653151355245534\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 171.49257016181946\n",
      "  time_this_iter_s: 3.6069750785827637\n",
      "  time_total_s: 171.49257016181946\n",
      "  timestamp: 1622064395\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 24\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |  0.0465315 |  0.0465315 |                   24 |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |  0.226398  |  0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |  0.0478771 |  0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |  0.0673802 |  0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |  2.0577    |  4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |  0.603441  |  0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |  0.698556  |  0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |  0.23171   |  0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |  0.0518497 |  0.0595102 |                    4 |\n",
      "| train_d0405_00016 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 | 16.1043    | 32.2068    |                    1 |\n",
      "| train_d0405_00017 | TERMINATED |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |  0.0945152 |  0.134427  |                    1 |\n",
      "| train_d0405_00018 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |  0.9116    |  1.6189    |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-42\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 26\n",
      "  loss: 0.046396632437758586\n",
      "  mse: 0.046396632437758586\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 178.64850211143494\n",
      "  time_this_iter_s: 3.5726990699768066\n",
      "  time_total_s: 178.64850211143494\n",
      "  timestamp: 1622064402\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 26\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |  0.0463966 |  0.0463966 |                   26 |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |  0.226398  |  0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |  0.0478771 |  0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |  0.0673802 |  0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |  2.0577    |  4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |  0.603441  |  0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |  0.698556  |  0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |  0.23171   |  0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |  0.0518497 |  0.0595102 |                    4 |\n",
      "| train_d0405_00016 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 | 16.1043    | 32.2068    |                    1 |\n",
      "| train_d0405_00017 | TERMINATED |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |  0.0945152 |  0.134427  |                    1 |\n",
      "| train_d0405_00018 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |  0.9116    |  1.6189    |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-49\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 28\n",
      "  loss: 0.04631301437449806\n",
      "  mse: 0.04631301437449806\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 186.13845801353455\n",
      "  time_this_iter_s: 3.712239980697632\n",
      "  time_total_s: 186.13845801353455\n",
      "  timestamp: 1622064409\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 28\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |  0.046313  |  0.046313  |                   28 |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |  0.226398  |  0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |  0.0478771 |  0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |  0.0673802 |  0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |  2.0577    |  4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |  0.603441  |  0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |  0.698556  |  0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |  0.23171   |  0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |  0.0518497 |  0.0595102 |                    4 |\n",
      "| train_d0405_00016 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 | 16.1043    | 32.2068    |                    1 |\n",
      "| train_d0405_00017 | TERMINATED |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |  0.0945152 |  0.134427  |                    1 |\n",
      "| train_d0405_00018 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |  0.9116    |  1.6189    |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n",
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-57\n",
      "  done: false\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 30\n",
      "  loss: 0.046365230968769856\n",
      "  mse: 0.046365230968769856\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 193.45936703681946\n",
      "  time_this_iter_s: 3.6435160636901855\n",
      "  time_total_s: 193.45936703681946\n",
      "  timestamp: 1622064417\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 30\n",
      "  trial_id: d0405_00034\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc               |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00034 | RUNNING    | 192.168.1.5:90352 |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |  0.0463652 |  0.0463652 |                   30 |\n",
      "| train_d0405_00000 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |                   |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |                   |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |                   |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |                   |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |                   |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |  0.226398  |  0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |                   |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |  0.0478771 |  0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |                   |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |  0.0673802 |  0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |  2.0577    |  4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |                   |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |  0.603441  |  0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |                   |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |  0.698556  |  0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |                   |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |  0.23171   |  0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |                   |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |  0.0518497 |  0.0595102 |                    4 |\n",
      "| train_d0405_00016 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 | 16.1043    | 32.2068    |                    1 |\n",
      "| train_d0405_00017 | TERMINATED |                   |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |  0.0945152 |  0.134427  |                    1 |\n",
      "| train_d0405_00018 | TERMINATED |                   |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |  0.9116    |  1.6189    |                    1 |\n",
      "+-------------------+------------+-------------------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "... 30 more trials not shown (30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:26:57,488\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_f': MSELoss()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_d0405_00034:\n",
      "  date: 2021-05-26_17-26-57\n",
      "  done: true\n",
      "  experiment_id: 2305e7bb0170491a9a87de349fe49677\n",
      "  experiment_tag: 34_batch_size=8,clip=False,loss_f=MSELoss(),lr=0.00017859,num_layers=1,optim=adam,scaling_factor=0.82039\n",
      "  hostname: RT5292M-GGB.local\n",
      "  iterations_since_restore: 30\n",
      "  loss: 0.046365230968769856\n",
      "  mse: 0.046365230968769856\n",
      "  node_ip: 192.168.1.5\n",
      "  pid: 90352\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 193.45936703681946\n",
      "  time_this_iter_s: 3.6435160636901855\n",
      "  time_total_s: 193.45936703681946\n",
      "  timestamp: 1622064417\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 30\n",
      "  trial_id: d0405_00034\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 17:26:57,912\tINFO tune.py:549 -- Total run time: 553.41 seconds (552.79 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.9/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=41\n",
      "Bracket: Iter 32.000: None | Iter 16.000: -0.049743526977035595 | Iter 8.000: -0.05087092477640434 | Iter 4.000: -0.05236056363757918 | Iter 2.000: -0.060218450558536196 | Iter 1.000: -0.07403756055761786\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.37 GiB heap, 0.0/2.18 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_17-17-44\n",
      "Number of trials: 50/50 (50 TERMINATED)\n",
      "+-------------------+------------+-------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "| Trial name        | status     | loc   |   batch_size | clip   | loss_f                        |          lr |   num_layers | optim   |   scaling_factor |       loss |        mse |   training_iteration |\n",
      "|-------------------+------------+-------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------|\n",
      "| train_d0405_00000 | TERMINATED |       |           32 | True   | L1Loss()                      | 0.00667986  |            1 | adam    |         0.737776 |  0.286652  |  0.158817  |                   14 |\n",
      "| train_d0405_00001 | TERMINATED |       |           16 | True   | L1Loss()                      | 0.016433    |            2 | adam    |         0.935584 |  0.724443  |  0.846653  |                    1 |\n",
      "| train_d0405_00002 | TERMINATED |       |            8 | True   | <function WSE at 0x14d1fb8c0> | 0.00197403  |            2 | adam    |         0.816021 |  0.0732566 |  0.0889087 |                   16 |\n",
      "| train_d0405_00003 | TERMINATED |       |           32 | True   | L1Loss()                      | 0.0123279   |            1 | adagrad |         0.930793 |  0.480108  |  0.456968  |                    1 |\n",
      "| train_d0405_00004 | TERMINATED |       |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00340198  |            1 | adam    |         0.94587  |  0.0744514 |  0.0989057 |                    2 |\n",
      "| train_d0405_00005 | TERMINATED |       |           32 | True   | MSELoss()                     | 0.0186072   |            1 | adagrad |         0.867464 |  0.057053  |  0.057053  |                   17 |\n",
      "| train_d0405_00006 | TERMINATED |       |           16 | False  | MSELoss()                     | 0.00155798  |            2 | adagrad |         0.992215 |  0.0504284 |  0.0504284 |                   14 |\n",
      "| train_d0405_00007 | TERMINATED |       |           16 | False  | MSELoss()                     | 0.00531697  |            1 | adam    |         0.844057 |  0.0496854 |  0.0496854 |                   12 |\n",
      "| train_d0405_00008 | TERMINATED |       |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.000107741 |            3 | adagrad |         0.689263 |  0.226398  |  0.151226  |                    1 |\n",
      "| train_d0405_00009 | TERMINATED |       |            8 | False  | MSELoss()                     | 0.0651873   |            2 | adagrad |         0.643997 |  0.0478771 |  0.0478771 |                   21 |\n",
      "| train_d0405_00010 | TERMINATED |       |           32 | False  | MSELoss()                     | 0.00220805  |            3 | adagrad |         0.891499 |  0.0673802 |  0.0673802 |                    2 |\n",
      "| train_d0405_00011 | TERMINATED |       |           32 | True   | L1Loss()                      | 0.000101523 |            2 | adam    |         0.649116 |  2.0577    |  4.25341   |                    1 |\n",
      "| train_d0405_00012 | TERMINATED |       |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0667954   |            1 | adam    |         0.929789 |  0.603441  |  0.991296  |                    1 |\n",
      "| train_d0405_00013 | TERMINATED |       |           32 | True   | L1Loss()                      | 0.0169359   |            2 | adagrad |         0.895803 |  0.698556  |  0.792826  |                    1 |\n",
      "| train_d0405_00014 | TERMINATED |       |           64 | True   | L1Loss()                      | 0.00519185  |            1 | adam    |         0.689945 |  0.23171   |  0.127196  |                    1 |\n",
      "| train_d0405_00015 | TERMINATED |       |            8 | False  | <function WSE at 0x14d1fb8c0> | 0.000287083 |            1 | adam    |         0.987757 |  0.0518497 |  0.0595102 |                    4 |\n",
      "| train_d0405_00016 | TERMINATED |       |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.000125928 |            3 | adagrad |         0.921188 | 16.1043    | 32.2068    |                    1 |\n",
      "| train_d0405_00017 | TERMINATED |       |           64 | False  | L1Loss()                      | 0.000200456 |            3 | adam    |         0.742733 |  0.0945152 |  0.134427  |                    1 |\n",
      "| train_d0405_00018 | TERMINATED |       |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.0417116   |            2 | adam    |         0.953263 |  0.9116    |  1.6189    |                    1 |\n",
      "| train_d0405_00019 | TERMINATED |       |           32 | False  | MSELoss()                     | 0.0340315   |            2 | adagrad |         0.589798 |  0.0491841 |  0.0491841 |                   26 |\n",
      "| train_d0405_00020 | TERMINATED |       |            8 | False  | L1Loss()                      | 0.00406654  |            3 | adam    |         0.990851 |  0.0499043 |  0.0525116 |                    8 |\n",
      "| train_d0405_00021 | TERMINATED |       |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0714041   |            2 | adagrad |         0.879978 |  0.0551455 |  0.0663479 |                    2 |\n",
      "| train_d0405_00022 | TERMINATED |       |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000438471 |            2 | adam    |         0.635733 |  0.445799  |  0.870018  |                    1 |\n",
      "| train_d0405_00023 | TERMINATED |       |            8 | True   | MSELoss()                     | 0.000182252 |            2 | adagrad |         0.538641 | 10.0166    | 10.0166    |                    1 |\n",
      "| train_d0405_00024 | TERMINATED |       |           32 | True   | L1Loss()                      | 0.000850275 |            1 | adam    |         0.801186 |  0.0776476 |  0.0585755 |                    2 |\n",
      "| train_d0405_00025 | TERMINATED |       |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00139843  |            1 | adagrad |         0.636399 |  0.128677  |  0.225162  |                    1 |\n",
      "| train_d0405_00026 | TERMINATED |       |           32 | True   | L1Loss()                      | 0.0318253   |            3 | adam    |         0.879941 |  1.3058    |  3.09823   |                    1 |\n",
      "| train_d0405_00027 | TERMINATED |       |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.0135728   |            1 | adagrad |         0.876869 |  0.0527083 |  0.0600495 |                    2 |\n",
      "| train_d0405_00028 | TERMINATED |       |           64 | True   | L1Loss()                      | 0.038364    |            2 | adam    |         0.956446 |  1.6465    |  3.47504   |                    1 |\n",
      "| train_d0405_00029 | TERMINATED |       |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.0931132   |            3 | adagrad |         0.893712 |  0.057278  |  0.0673028 |                    2 |\n",
      "| train_d0405_00030 | TERMINATED |       |           16 | True   | MSELoss()                     | 0.00621064  |            3 | adagrad |         0.763164 |  0.0518446 |  0.0518446 |                    8 |\n",
      "| train_d0405_00031 | TERMINATED |       |           64 | False  | <function WSE at 0x14d1fb8c0> | 0.00148648  |            3 | adam    |         0.757871 |  0.0695666 |  0.0618543 |                    2 |\n",
      "| train_d0405_00032 | TERMINATED |       |           16 | True   | L1Loss()                      | 0.00401857  |            2 | adagrad |         0.917115 |  0.114844  |  0.0623319 |                    2 |\n",
      "| train_d0405_00033 | TERMINATED |       |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.000467081 |            1 | adam    |         0.902106 |  0.0523393 |  0.0598808 |                    4 |\n",
      "| train_d0405_00034 | TERMINATED |       |            8 | False  | MSELoss()                     | 0.000178591 |            1 | adam    |         0.820389 |  0.0463652 |  0.0463652 |                   30 |\n",
      "| train_d0405_00035 | TERMINATED |       |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.00174031  |            1 | adam    |         0.919799 |  0.0579473 |  0.0642762 |                    2 |\n",
      "| train_d0405_00036 | TERMINATED |       |           32 | False  | MSELoss()                     | 0.0443035   |            3 | adam    |         0.784166 |  0.0518406 |  0.0518406 |                   14 |\n",
      "| train_d0405_00037 | TERMINATED |       |           16 | True   | MSELoss()                     | 0.00892973  |            1 | adam    |         0.851035 |  0.0784174 |  0.0784174 |                    2 |\n",
      "| train_d0405_00038 | TERMINATED |       |           16 | False  | <function WSE at 0x14d1fb8c0> | 0.00674081  |            2 | adagrad |         0.676063 |  0.0544917 |  0.0603874 |                    2 |\n",
      "| train_d0405_00039 | TERMINATED |       |            8 | False  | MSELoss()                     | 0.00125823  |            1 | adagrad |         0.574322 |  0.0498544 |  0.0498544 |                   23 |\n",
      "| train_d0405_00040 | TERMINATED |       |           64 | True   | L1Loss()                      | 0.000171463 |            3 | adagrad |         0.833385 |  5.66802   | 30.8929    |                    1 |\n",
      "| train_d0405_00041 | TERMINATED |       |           16 | True   | <function WSE at 0x14d1fb8c0> | 0.00749856  |            1 | adagrad |         0.544053 |  0.0571454 |  0.0639513 |                    2 |\n",
      "| train_d0405_00042 | TERMINATED |       |            8 | True   | L1Loss()                      | 0.00938797  |            3 | adagrad |         0.709303 |  0.078354  |  0.0561302 |                    4 |\n",
      "| train_d0405_00043 | TERMINATED |       |           32 | False  | MSELoss()                     | 0.000628935 |            3 | adam    |         0.630458 |  0.0831631 |  0.0831631 |                    1 |\n",
      "| train_d0405_00044 | TERMINATED |       |           32 | False  | <function WSE at 0x14d1fb8c0> | 0.00029727  |            3 | adam    |         0.585795 |  0.168938  |  0.117278  |                    1 |\n",
      "| train_d0405_00045 | TERMINATED |       |           64 | True   | L1Loss()                      | 0.00015962  |            3 | adagrad |         0.781288 |  5.27283   | 26.7593    |                    1 |\n",
      "| train_d0405_00046 | TERMINATED |       |           32 | True   | <function WSE at 0x14d1fb8c0> | 0.0371802   |            1 | adam    |         0.724322 |  0.308306  |  0.516634  |                    1 |\n",
      "| train_d0405_00047 | TERMINATED |       |            8 | True   | L1Loss()                      | 0.0025568   |            3 | adagrad |         0.7754   |  0.0556606 |  0.055398  |                    4 |\n",
      "| train_d0405_00048 | TERMINATED |       |           64 | False  | L1Loss()                      | 0.0414242   |            1 | adagrad |         0.577998 |  0.129365  |  0.0614965 |                    2 |\n",
      "| train_d0405_00049 | TERMINATED |       |           64 | True   | <function WSE at 0x14d1fb8c0> | 0.000945297 |            2 | adam    |         0.795822 |  0.0566262 |  0.0637351 |                    2 |\n",
      "+-------------------+------------+-------+--------------+--------+-------------------------------+-------------+--------------+---------+------------------+------------+------------+----------------------+\n",
      "\n",
      "\n",
      "Best trial config: {'num_layers': 1, 'num_nodes': 1150, 'scaling_factor': 0.8203891979424993, 'num_nodes_out': 400, 'final_activation': <built-in method tanh of type object at 0x141730c30>, 'clip': False, 'batch_size': 8, 'loss_f': MSELoss(), 'optim': 'adam', 'lr': 0.00017859135777257323, 'shuffle': True, 'num_workers': 4, 'patience': 10, 'epochs': 50}\n",
      "Best trial final validation loss: 0.046365230968769856\n",
      "Best trial final validation mse: 0.046365230968769856\n"
     ]
    }
   ],
   "source": [
    "btm = run_rtune(num_samples=50, max_num_epochs=50, gpus_per_trial=0)\n",
    "#https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#tune-search-alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      goals   assists  cards_yellow  cards_red  own_goals  goals_against  \\\n",
      "0  0.524458  0.038081      0.173317   0.519007   0.509316       1.307664   \n",
      "1  0.169901  0.518472      0.627050   0.271117   0.254911       1.080686   \n",
      "\n",
      "      saves  \n",
      "0  1.536534  \n",
      "1  0.516705  \n",
      "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
      "0    4.0      4.0           4.0        0.0        0.0            1.0    2.0\n",
      "1    1.0      1.0           2.0        0.0        0.0            4.0    2.0\n"
     ]
    }
   ],
   "source": [
    "pred=btm(torch.Tensor(inp)).detach().cpu().numpy()[3]\n",
    "cats=['minutes','goals','assists','cards_yellow','cards_red','own_goals']+['goals_against','saves']\n",
    "\n",
    "reframe, byteamframe = revert_output(pred)\n",
    "print(byteamframe)\n",
    "reframe, byteamframe = revert_output(out[3])\n",
    "print(byteamframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
