{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys, getopt\n",
    "import csv\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import umap\n",
    "from sklearn.decomposition import TruncatedSVD as tsvd\n",
    "\n",
    "def nearZeroVarDropAuto(df,thresh=0.99):\n",
    "    vVal=df.var(axis=0).values\n",
    "    cs=pd.Series(vVal).sort_values(ascending=False).cumsum()\n",
    "    remove=cs[cs>cs.values[-1]*thresh].index.values\n",
    "    return df.drop(df.columns[remove],axis=1)\n",
    "\n",
    "%run SodaKick_download_functions.ipynb\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import SGD, Adagrad, Adam, Adagrad\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    \"\"\" Stops the training if loss doesn't improve after a given number of epochs. \"\"\"\n",
    "\n",
    "    def __init__(self, patience=3, epsilon=1e-5, keepBest=True, silent=True):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs without change before stopping the learning (default 3).\n",
    "            epsilon (float): Minimum change in loss to be considered for early stopping (default 1e-5).\n",
    "            keepBest (bool): Keep track of the best model (memory consuming).\n",
    "        \"\"\"\n",
    "\n",
    "        self.patience = patience\n",
    "        self.epsilon = epsilon\n",
    "        self.counter = 0\n",
    "        \n",
    "        self.bestScore = np.inf\n",
    "     \n",
    "        self.keepBest = keepBest \n",
    "        self.bestModel = None\n",
    "\n",
    "        self.earlyStop = False\n",
    "        self.silent = silent\n",
    "\n",
    "    def __call__(self, loss, model):\n",
    "\n",
    "\n",
    "        \"\"\" Evaluate the loss change between epochs and activates early stop if below epsilon.\n",
    "\n",
    "        Args:\n",
    "            loss (float): current loss.\n",
    "            model (torch model): the current model.\n",
    "        \"\"\"\n",
    "\n",
    "        if loss > self.bestScore - self.epsilon:\n",
    "\n",
    "            self.counter += 1\n",
    "            if not self.silent:\n",
    "                print('EarlyStopping counter: {:d}/{:d}'.format(self.counter,self.patience))\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.earlyStop = True\n",
    "\n",
    "        else:   \n",
    "\n",
    "            self.counter = 0\n",
    "            self.bestScore = loss\n",
    "\n",
    "            if self.keepBest:\n",
    "                self.bestModel = copy.deepcopy(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class matchesDataset(Dataset):\n",
    "\n",
    "    \"\"\" Extend pytorch Dataset class to include cleaning and training set creation, \"\"\"\n",
    "    \n",
    "    def __init__(self, matches, results):\n",
    "\n",
    "        self.matches = torch.tensor(matches, dtype=torch.float32)\n",
    "        self.results = torch.tensor(results, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        \"\"\" Returns the len of the training sample. \"\"\"\n",
    "        \n",
    "        return len(self.matches)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index): \n",
    "\n",
    "        \"\"\" Returns a word, a context word and a list of negative words for training for a given index. \n",
    "\n",
    "        Args:\n",
    "            index (int): index for the word selection.\n",
    "\n",
    "        Returns:\n",
    "            (string, string, list of strings): selected word, context word and a randomly drawn list \n",
    "                                               of negative words.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.matches[index], self.results[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/quirky-keras-custom-and-asymmetric-loss-functions-for-keras-in-r-a8b5271171fe\n",
    "def WSE(output, target, a=1.5, b=.5):\n",
    "    loss = torch.mean(a*torch.minimum(torch.zeros(output.shape[1]),output - target)**2+\\\n",
    "                      b*torch.maximum(torch.zeros(output.shape[1]),output - target)**2)      \n",
    "    return loss\n",
    "\n",
    "def WSEl1(output, target, a=1.5, b=.5):\n",
    "    loss = torch.mean(a*torch.abs(torch.minimum(torch.zeros(output.shape[1]),output - target))+\\\n",
    "                      b*torch.abs(torch.maximum(torch.zeros(output.shape[1]),output - target)))      \n",
    "    return loss\n",
    "\n",
    "def WSE2(output, target, a=1.5, b=.5):\n",
    "    loss = np.mean(a*np.minimum(np.zeros(output.shape[0]),output - target)**2+\\\n",
    "                      b*np.maximum(np.zeros(output.shape[0]),output - target)**2)      \n",
    "    return loss\n",
    "\n",
    "def WSEl12(output, target, a=1.5, b=.5):\n",
    "    loss = np.mean(a*np.abs(np.minimum(np.zeros(output.shape[0]),output - target))+\\\n",
    "                      b*np.abs(np.maximum(np.zeros(output.shape[0]),output - target)))      \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_inp_2a.pkl', 'rb') as pk:\n",
    "    inp=pickle.load(pk)\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_out_2a.pkl', 'rb') as pk:\n",
    "    out=pickle.load(pk)     \n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_inp_2b.pkl', 'rb') as pk:\n",
    "    inpb=pickle.load(pk)\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_out_2b.pkl', 'rb') as pk:\n",
    "    outb=pickle.load(pk)     \n",
    "\n",
    "inp=np.concatenate([inp,inpb])\n",
    "out=np.concatenate([out,outb])\n",
    "\n",
    "def normalize_mins(vec):\n",
    "    for i in range(vec.shape[0]):\n",
    "        vec[i][::8]=vec[i][::8]/90\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def NormalizeMatrix(data):   \n",
    "    for i in range(data.shape[1]):\n",
    "        data[:,i] = NormalizeData(data[:,i])\n",
    "        \n",
    "NormalizeMatrix(inp)\n",
    "np.nan_to_num(inp, copy=False)\n",
    "\n",
    "normalize_mins(out)\n",
    "\n",
    "#scaler = preprocessing.StandardScaler().fit(inp)\n",
    "#inp = scaler.transform(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "         inp, out, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_layers, num_nodes, scaling_factor, num_nodes_out, final_activation):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.fc = []\n",
    "        self.lr = []\n",
    "        self.fact = final_activation\n",
    "        self.nl = num_layers\n",
    "        power=0\n",
    "        \n",
    "        for i in range(self.nl):\n",
    "            self.fc.append(nn.Linear(num_nodes*scaling_factor**power, num_nodes*scaling_factor**(power+1)))\n",
    "            self.lr.append(nn.LeakyReLU())\n",
    "            power+=1\n",
    "        \n",
    "        self.oupt = nn.Linear(num_nodes*scaling_factor**power, num_nodes_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x\n",
    "        for i in range(self.nl):\n",
    "            z = self.lr[i](self.fc[i](z))\n",
    "        z = self.oupt(self.fact(z))\n",
    "        return z\n",
    "    \n",
    "    def clp(self):\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.nl):\n",
    "                self.fc[i].weight.copy_ (self.fc[i].weight.data.clamp(min=0)) \n",
    "            self.oupt.weight.copy_ (self.oupt.weight.data.clamp(min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, model=Net, silent=True, checkpoint_dir=None):\n",
    "    \n",
    "    phases = ['train','val']\n",
    "    \n",
    "    #x_train, x_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "    \n",
    "    training_set = matchesDataset(x_train, y_train)\n",
    "    trainBatch = torch.utils.data.DataLoader(training_set, batch_size=config['batch_size'], shuffle=config['shuffle'], num_workers=config['num_workers'])\n",
    "\n",
    "    validation_set = matchesDataset(x_test, y_test)\n",
    "    valBatch = torch.utils.data.DataLoader(validation_set, batch_size=config['batch_size'], shuffle=config['shuffle'], num_workers=config['num_workers'])\n",
    "\n",
    "    earlStop = EarlyStopping(patience=config['patience'], keepBest=False)\n",
    "    net = model(config)\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    if config['optim']=='adam':\n",
    "        optimizer = Adam(net.parameters(), lr=config['lr'])\n",
    "    elif config['optim']=='adagrad':\n",
    "        optimizer = Adagrad(net.parameters(), lr=config['lr'])\n",
    "    else:\n",
    "        print('optim error')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    losses=[[],[]]\n",
    "    mses=[]\n",
    "    diffs=[]\n",
    "    exit=False\n",
    "    \n",
    "    #for epoch in tqdm(range(epochs), desc='Epoch'):\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        if exit:\n",
    "            break\n",
    "            \n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                net.train(True) \n",
    "\n",
    "                \"\"\" Run the training of the model. \"\"\"    \n",
    "\n",
    "                losses_batch=[]\n",
    "                for batchNum, batch in enumerate(trainBatch):\n",
    "\n",
    "                    x = batch[0]\n",
    "                    y = batch[1]\n",
    "\n",
    "                    \"\"\" Move batches to GPU if available. \"\"\"\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "\n",
    "                    \"\"\" Core of training. \"\"\"\n",
    "                    \n",
    "                    loss = config['loss_f'](net(x), y)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    if config['clip']:\n",
    "                        net.clp()\n",
    "\n",
    "                    losses_batch.append(loss)\n",
    "\n",
    "                \"\"\" Early stop check. \"\"\"\n",
    "\n",
    "                earlStop(loss, net)\n",
    "                finalepoch = epoch\n",
    "                \n",
    "                if earlStop.earlyStop:\n",
    "\n",
    "                    if not silent:\n",
    "                        print('Limit loss improvement reached, stopping the training.')\n",
    "                        \n",
    "                    exit=True \n",
    "                \n",
    "                losses[0].append(torch.mean(torch.stack(losses_batch)).detach().cpu().numpy())\n",
    "            else:\n",
    "                net.train(False)\n",
    "                net.eval()\n",
    "                \n",
    "                val_loss=0\n",
    "                val_mse=0\n",
    "      \n",
    "                losses_batch=[]\n",
    "                for batchNum, batch in enumerate(valBatch):\n",
    "\n",
    "                    x = batch[0]\n",
    "                    y = batch[1]\n",
    "\n",
    "                    \"\"\" Move batches to GPU if available. \"\"\"\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        x = x.cuda()\n",
    "                        y = y.cuda()\n",
    "\n",
    "                    \"\"\" Core of training. \"\"\"\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    output=net(x)\n",
    "                    target=y\n",
    "                    loss = config['loss_f'](output, target)\n",
    "\n",
    "                    #losses_batch.append(loss)\n",
    "                    val_loss+=loss\n",
    "                    val_mse+=nn.MSELoss()(output, target)\n",
    "                    \n",
    "                losses[1].append(torch.mean(torch.stack(losses_batch)).detach().cpu().numpy())\n",
    "                \n",
    "                with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                    path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "                    torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "                tune.report(loss=(val_loss/batchNum), mse=(val_mse/batchNum))\n",
    "                #tune.report(loss=torch.mean(torch.stack(losses_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x1e6246c50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.checkpoint_dir(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_output(output,lineup):\n",
    "\n",
    "    reframe=pd.DataFrame(output.reshape(50,8), index=lineup.index,\n",
    "                 columns=['minutes','goals','assists','cards_yellow','cards_red','own_goals','goals_against','saves'])\n",
    "    reframe.drop([x for x in reframe.index if x.startswith('dummy')], axis=0, inplace=True)\n",
    "    byteamframe=pd.concat([reframe.loc[[x for x in reframe.index if x in lineup[lineup['team']==0].index]].sum(axis=0),\n",
    "                        reframe.loc[[x for x in reframe.index if x in lineup[lineup['team']==1].index]].sum(axis=0)], axis=1).T\n",
    "    \n",
    "    reframe['minutes']=reframe['minutes']*90\n",
    "    \n",
    "    return reframe, byteamframe[byteamframe.columns[1:]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline WSE: 0.230\n",
      "Baseline WSE l1: 0.139\n",
      "Baseline MSE: 0.153\n",
      "Baseline MSE l1: 0.092\n",
      "-18.0\n",
      "16.566666666666666\n",
      "2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "print('Baseline WSE: {:.3f}'.format(WSE2(np.array([0]*out[0].shape[0]),out[0])))\n",
    "print('Baseline WSE l1: {:.3f}'.format(WSEl12(np.array([0]*out[0].shape[0]),out[0])))\n",
    "print('Baseline MSE: {:.3f}'.format(WSE2(np.array([0]*out[0].shape[0]),out[0], a=1, b=1)))\n",
    "print('Baseline MSE l1: {:.3f}'.format(WSEl12(np.array([0]*out[0].shape[0]),out[0], a=1, b=1)))\n",
    "\n",
    "print((out[1]-out[10]).sum())\n",
    "print((out[50]-out[60]).sum())\n",
    "print((out[100]-out[110]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.tune.sample.Float at 0x15f314350>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.loguniform(1e-4, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(5000*1.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    \n",
    "\n",
    "    config = {\n",
    "        \"num_layers\": tune.choice([1, 2, 3]),\n",
    "        \"num_nodes\": inp.shape[1],\n",
    "        \"scaling_factor\": tune.sample_from(lambda _: np.random.uniform(low=0.5, high=1.0001)),\n",
    "        \"num_nodes_out\": out.shape[1], \n",
    "        \"final_activation\" : torch.tanh,\n",
    "        \"clip\": tune.choice([True, False]),\n",
    "        \"batch_size\": tune.choice([8, 16, 32]),\n",
    "        \"loss_f\": tune.choice([WSE, nn.MSELoss(), nn.L1Loss()]),\n",
    "        \"optim\": tune.choice(['adam', 'adagrad']),\n",
    "        \"lr\": 1e-3,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"patience\": 10,\n",
    "    }\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    \n",
    "    reporter = CLIReporter(\n",
    "        metric_columns=[\"loss\", \"mse\", \"training_iteration\"])\n",
    "    \n",
    "    result = tune.run(\n",
    "        train,\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation mse: {}\".format(\n",
    "        best_trial.last_result[\"mse\"]))\n",
    "\n",
    "    best_trained_model = Net(best_trial.config)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    #test_acc = test_accuracy(best_trained_model, device)\n",
    "    #print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 15:26:03,510\tWARNING worker.py:1115 -- Warning: The actor ImplicitFunc has size 84675864 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n",
      "2021-05-26 15:26:03,606\tWARNING util.py:162 -- The `start_trial` operation took 0.710 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.0/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2.0/8 CPUs, 0/0 GPUs, 0.0/4.04 GiB heap, 0.0/2.02 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_15-25-58\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------+\n",
      "| Trial name        | status   | loc   |   batch_size | clip   | loss_f                        |   num_layers | optim   |   scaling_factor |\n",
      "|-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------|\n",
      "| train_32f52_00000 | RUNNING  |       |           16 | False  | MSELoss()                     |            3 | adagrad |         0.732012 |\n",
      "| train_32f52_00001 | PENDING  |       |           16 | False  | L1Loss()                      |            2 | adam    |         0.660085 |\n",
      "| train_32f52_00002 | PENDING  |       |           16 | True   | MSELoss()                     |            2 | adam    |         0.747746 |\n",
      "| train_32f52_00003 | PENDING  |       |            8 | False  | <function WSE at 0x14eaa0a70> |            2 | adagrad |         0.814732 |\n",
      "| train_32f52_00004 | PENDING  |       |           16 | False  | <function WSE at 0x14eaa0a70> |            2 | adagrad |         0.996516 |\n",
      "| train_32f52_00005 | PENDING  |       |           32 | True   | L1Loss()                      |            3 | adagrad |         0.890031 |\n",
      "| train_32f52_00006 | PENDING  |       |            8 | False  | <function WSE at 0x14eaa0a70> |            1 | adagrad |         0.785324 |\n",
      "| train_32f52_00007 | PENDING  |       |           16 | False  | <function WSE at 0x14eaa0a70> |            3 | adam    |         0.792605 |\n",
      "| train_32f52_00008 | PENDING  |       |           32 | False  | MSELoss()                     |            1 | adam    |         0.84182  |\n",
      "| train_32f52_00009 | PENDING  |       |            8 | False  | MSELoss()                     |            3 | adagrad |         0.577279 |\n",
      "+-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 15:26:04,242\tWARNING util.py:162 -- The `start_trial` operation took 0.606 s, which may be a performance bottleneck.\n",
      "2021-05-26 15:26:04,890\tWARNING util.py:162 -- The `start_trial` operation took 0.647 s, which may be a performance bottleneck.\n",
      "2021-05-26 15:26:05,584\tWARNING util.py:162 -- The `start_trial` operation took 0.693 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m 2021-05-26 15:26:06,120\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"//miniconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74303)\u001b[0m \n",
      "2021-05-26 15:26:06,375\tERROR trial_runner.py:732 -- Trial train_32f52_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 702, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 686, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/worker.py\", line 1481, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74303, ip=10.0.1.101)\n",
      "  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74303, ip=10.0.1.101)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "NameError: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_32f52_00000:\n",
      "  {}\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m 2021-05-26 15:26:06,571\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"//miniconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m \n",
      "2021-05-26 15:26:07,030\tWARNING util.py:162 -- The `start_trial` operation took 0.650 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m 2021-05-26 15:26:07,195\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"//miniconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m \n",
      "2021-05-26 15:26:07,338\tERROR trial_runner.py:732 -- Trial train_32f52_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 702, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 686, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/worker.py\", line 1481, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74304, ip=10.0.1.101)\n",
      "  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74304, ip=10.0.1.101)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "NameError: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_32f52_00001:\n",
      "  {}\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 15:26:07,972\tWARNING util.py:162 -- The `start_trial` operation took 0.632 s, which may be a performance bottleneck.\n",
      "2021-05-26 15:26:08,323\tERROR trial_runner.py:732 -- Trial train_32f52_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 702, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 686, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/worker.py\", line 1481, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74298, ip=10.0.1.101)\n",
      "  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74298, ip=10.0.1.101)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "NameError: name 'model' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_32f52_00002:\n",
      "  {}\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m 2021-05-26 15:26:08,615\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"//miniconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m \n",
      "2021-05-26 15:26:09,135\tWARNING util.py:162 -- The `start_trial` operation took 0.807 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.4/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/4.04 GiB heap, 0.0/2.02 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_15-25-58\n",
      "Number of trials: 10/10 (3 ERROR, 3 PENDING, 4 RUNNING)\n",
      "+-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------+\n",
      "| Trial name        | status   | loc   |   batch_size | clip   | loss_f                        |   num_layers | optim   |   scaling_factor |\n",
      "|-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------|\n",
      "| train_32f52_00003 | RUNNING  |       |            8 | False  | <function WSE at 0x14eaa0a70> |            2 | adagrad |         0.814732 |\n",
      "| train_32f52_00004 | RUNNING  |       |           16 | False  | <function WSE at 0x14eaa0a70> |            2 | adagrad |         0.996516 |\n",
      "| train_32f52_00005 | RUNNING  |       |           32 | True   | L1Loss()                      |            3 | adagrad |         0.890031 |\n",
      "| train_32f52_00006 | RUNNING  |       |            8 | False  | <function WSE at 0x14eaa0a70> |            1 | adagrad |         0.785324 |\n",
      "| train_32f52_00007 | PENDING  |       |           16 | False  | <function WSE at 0x14eaa0a70> |            3 | adam    |         0.792605 |\n",
      "| train_32f52_00008 | PENDING  |       |           32 | False  | MSELoss()                     |            1 | adam    |         0.84182  |\n",
      "| train_32f52_00009 | PENDING  |       |            8 | False  | MSELoss()                     |            3 | adagrad |         0.577279 |\n",
      "| train_32f52_00000 | ERROR    |       |           16 | False  | MSELoss()                     |            3 | adagrad |         0.732012 |\n",
      "| train_32f52_00001 | ERROR    |       |           16 | False  | L1Loss()                      |            2 | adam    |         0.660085 |\n",
      "| train_32f52_00002 | ERROR    |       |           16 | True   | MSELoss()                     |            2 | adam    |         0.747746 |\n",
      "+-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------+\n",
      "Number of errored trials: 3\n",
      "+-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name        |   # failures | error file                                                                                                                                                                                                   |\n",
      "|-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_32f52_00000 |            1 | /Users/federico comitani/ray_results/train_2021-05-26_15-25-58/train_32f52_00000_0_batch_size=16,clip=False,loss_f=MSELoss(),num_layers=3,optim=adagrad,scaling_factor=0.73201_2021-05-26_15-26-02/error.txt |\n",
      "| train_32f52_00001 |            1 | /Users/federico comitani/ray_results/train_2021-05-26_15-25-58/train_32f52_00001_1_batch_size=16,clip=False,loss_f=L1Loss(),num_layers=2,optim=adam,scaling_factor=0.66008_2021-05-26_15-26-03/error.txt     |\n",
      "| train_32f52_00002 |            1 | /Users/federico comitani/ray_results/train_2021-05-26_15-25-58/train_32f52_00002_2_batch_size=16,clip=True,loss_f=MSELoss(),num_layers=2,optim=adam,scaling_factor=0.74775_2021-05-26_15-26-04/error.txt     |\n",
      "+-------------------+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 15:26:09,501\tERROR trial_runner.py:732 -- Trial train_32f52_00003: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 702, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 686, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/worker.py\", line 1481, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74332, ip=10.0.1.101)\n",
      "  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74332, ip=10.0.1.101)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m 2021-05-26 15:26:09,503\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"//miniconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_32f52_00003:\n",
      "  {}\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 15:26:10,147\tWARNING util.py:162 -- The `start_trial` operation took 0.643 s, which may be a performance bottleneck.\n",
      "2021-05-26 15:26:10,329\tWARNING tune.py:507 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2021-05-26 15:26:10,581\tERROR trial_runner.py:732 -- Trial train_32f52_00004: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 702, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 686, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/worker.py\", line 1481, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74335, ip=10.0.1.101)\n",
      "  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=74335, ip=10.0.1.101)\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-50-db55d1fe5971>\", line 14, in train\n",
      "NameError: name 'model' is not defined\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m 2021-05-26 15:26:10,658\tERROR worker.py:382 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   File \"python/ray/_raylet.pyx\", line 599, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   File \"python/ray/_raylet.pyx\", line 392, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 400, in load_actor_class\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m     job_id, actor_creation_function_descriptor)\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 496, in _load_actor_class_from_gcs\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m     actor_class = pickle.loads(pickled_class)\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   File \"//miniconda3/lib/python3.7/site-packages/torch/__init__.py\", line 189, in <module>\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m     _load_global_deps()\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   File \"//miniconda3/lib/python3.7/site-packages/torch/__init__.py\", line 142, in _load_global_deps\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m     ctypes.CDLL(lib_path, mode=ctypes.RTLD_GLOBAL)\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   File \"//miniconda3/lib/python3.7/ctypes/__init__.py\", line 364, in __init__\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m     self._handle = _dlopen(self._name, mode)\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/worker.py\", line 379, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m 2021-05-26 15:26:10,632\tERROR worker.py:382 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"python/ray/_raylet.pyx\", line 599, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"python/ray/_raylet.pyx\", line 392, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 400, in load_actor_class\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     job_id, actor_creation_function_descriptor)\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 496, in _load_actor_class_from_gcs\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     actor_class = pickle.loads(pickled_class)\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/__init__.py\", line 2, in <module>\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     from ray.tune.tune import run_experiments, run\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/tune.py\", line 19, in <module>\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     from ray.tune.ray_trial_executor import RayTrialExecutor\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 17, in <module>\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     from ray.tune.durable_trainable import DurableTrainable\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/durable_trainable.py\", line 10, in <module>\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     from ray.tune.syncer import get_cloud_sync_client\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/syncer.py\", line 21, in <module>\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     from ray.tune.cluster_info import get_ssh_key, get_ssh_user\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/tune/cluster_info.py\", line 1, in <module>\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     import getpass\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"//miniconda3/lib/python3.7/getpass.py\", line 173, in <module>\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     import termios\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   File \"/Users/federico comitani/.local/lib/python3.7/site-packages/ray/worker.py\", line 379, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m SystemExit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_32f52_00004:\n",
      "  {}\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/16.0 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 6.0/8 CPUs, 0/0 GPUs, 0.0/4.04 GiB heap, 0.0/2.02 GiB objects\n",
      "Result logdir: /Users/federico comitani/ray_results/train_2021-05-26_15-25-58\n",
      "Number of trials: 10/10 (5 ERROR, 2 PENDING, 3 RUNNING)\n",
      "+-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------+\n",
      "| Trial name        | status   | loc   |   batch_size | clip   | loss_f                        |   num_layers | optim   |   scaling_factor |\n",
      "|-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------|\n",
      "| train_32f52_00005 | RUNNING  |       |           32 | True   | L1Loss()                      |            3 | adagrad |         0.890031 |\n",
      "| train_32f52_00006 | RUNNING  |       |            8 | False  | <function WSE at 0x14eaa0a70> |            1 | adagrad |         0.785324 |\n",
      "| train_32f52_00007 | RUNNING  |       |           16 | False  | <function WSE at 0x14eaa0a70> |            3 | adam    |         0.792605 |\n",
      "| train_32f52_00008 | PENDING  |       |           32 | False  | MSELoss()                     |            1 | adam    |         0.84182  |\n",
      "| train_32f52_00009 | PENDING  |       |            8 | False  | MSELoss()                     |            3 | adagrad |         0.577279 |\n",
      "| train_32f52_00000 | ERROR    |       |           16 | False  | MSELoss()                     |            3 | adagrad |         0.732012 |\n",
      "| train_32f52_00001 | ERROR    |       |           16 | False  | L1Loss()                      |            2 | adam    |         0.660085 |\n",
      "| train_32f52_00002 | ERROR    |       |           16 | True   | MSELoss()                     |            2 | adam    |         0.747746 |\n",
      "| train_32f52_00003 | ERROR    |       |            8 | False  | <function WSE at 0x14eaa0a70> |            2 | adagrad |         0.814732 |\n",
      "| train_32f52_00004 | ERROR    |       |           16 | False  | <function WSE at 0x14eaa0a70> |            2 | adagrad |         0.996516 |\n",
      "+-------------------+----------+-------+--------------+--------+-------------------------------+--------------+---------+------------------+\n",
      "Number of errored trials: 5\n",
      "+-------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name        |   # failures | error file                                                                                                                                                                                                                      |\n",
      "|-------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_32f52_00000 |            1 | /Users/federico comitani/ray_results/train_2021-05-26_15-25-58/train_32f52_00000_0_batch_size=16,clip=False,loss_f=MSELoss(),num_layers=3,optim=adagrad,scaling_factor=0.73201_2021-05-26_15-26-02/error.txt                    |\n",
      "| train_32f52_00001 |            1 | /Users/federico comitani/ray_results/train_2021-05-26_15-25-58/train_32f52_00001_1_batch_size=16,clip=False,loss_f=L1Loss(),num_layers=2,optim=adam,scaling_factor=0.66008_2021-05-26_15-26-03/error.txt                        |\n",
      "| train_32f52_00002 |            1 | /Users/federico comitani/ray_results/train_2021-05-26_15-25-58/train_32f52_00002_2_batch_size=16,clip=True,loss_f=MSELoss(),num_layers=2,optim=adam,scaling_factor=0.74775_2021-05-26_15-26-04/error.txt                        |\n",
      "| train_32f52_00003 |            1 | /Users/federico comitani/ray_results/train_2021-05-26_15-25-58/train_32f52_00003_3_batch_size=8,clip=False,loss_f=<function WSE at 0x14eaa0a70>,num_layers=2,optim=adagrad,scaling_factor=0.81473_2021-05-26_15-26-04/error.txt |\n",
      "| train_32f52_00004 |            1 | /Users/federico comitani/ray_results/train_2021-05-26_15-25-58/train_32f52_00004_4_batch_size=16,clip=False,loss_f=<function WSE at 0x14eaa0a70>,num_layers=2,optim=adagrad,scaling_factor=0.9965_2021-05-26_15-26-05/error.txt |\n",
      "+-------------------+--------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 15:26:10,844\tERROR tune.py:545 -- Trials did not complete: [train_32f52_00000, train_32f52_00001, train_32f52_00002, train_32f52_00003, train_32f52_00004, train_32f52_00005, train_32f52_00006, train_32f52_00007, train_32f52_00008, train_32f52_00009]\n",
      "2021-05-26 15:26:10,844\tINFO tune.py:549 -- Total run time: 12.64 seconds (11.96 seconds for the tuning loop).\n",
      "2021-05-26 15:26:10,845\tWARNING tune.py:554 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
      "2021-05-26 15:26:10,853\tWARNING experiment_analysis.py:580 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-979ccb093e96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-d1a3f036f2c0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best trial config: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     print(\"Best trial final validation loss: {}\".format(\n\u001b[1;32m     41\u001b[0m         best_trial.last_result[\"loss\"]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      goals   assists  cards_yellow  cards_red  own_goals  goals_against  \\\n",
      "0  1.571054  1.131036      2.305363   0.181507   0.124638       1.737184   \n",
      "1  1.362419  1.026369      2.779735   0.322705   0.215665       1.503933   \n",
      "\n",
      "      saves  \n",
      "0  2.677974  \n",
      "1  3.405122  \n",
      "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
      "0    4.0      4.0           4.0        0.0        0.0            1.0    2.0\n",
      "1    1.0      1.0           2.0        0.0        0.0            4.0    2.0\n"
     ]
    }
   ],
   "source": [
    "pred=nt(torch.Tensor(inptmp)).detach().cpu().numpy()[3]\n",
    "cats=['minutes','goals','assists','cards_yellow','cards_red','own_goals']+['goals_against','saves']\n",
    "\n",
    "reframe, byteamframe = revert_output(pred)\n",
    "print(byteamframe)\n",
    "reframe, byteamframe = revert_output(out[3])\n",
    "print(byteamframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
