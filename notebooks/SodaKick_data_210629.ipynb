{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player index, team may matter in chosing who plays first and who doesn't\n",
    "#for now I won't use them, but should be considered \n",
    "#also role may be important, for now only goalkeeper will be accounted for in the final dataframe\n",
    "#if a team is away or home depends on the order of the report so team 0 will be home, team 1 away\n",
    "\n",
    "\n",
    "#it seems some players are missing in the list of players (e.g. Antonino Barilla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys, getopt\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import umap\n",
    "from sklearn.decomposition import TruncatedSVD as tsvd\n",
    "\n",
    "def nearZeroVarDropAuto(df,thresh=0.99):\n",
    "    vVal=df.var(axis=0).values\n",
    "    cs=pd.Series(vVal).sort_values(ascending=False).cumsum()\n",
    "    remove=cs[cs>cs.values[-1]*thresh].index.values\n",
    "    return df.drop(df.columns[remove],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run SodaKick_download_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outfield=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Outfield.hdf',key='pl')\n",
    "df_team=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Team.hdf',key='pl')\n",
    "df_vs=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Vs.hdf',key='pl')\n",
    "df_keeper=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_keeper.hdf',key='pl')\n",
    "df_fix=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_fix.hdf',key='pl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up Outfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outfield(df_outfield):\n",
    "\n",
    "    df_outfield=df_outfield.fillna(0)\n",
    "\n",
    "    #df_outfield=df_outfield.drop(['birth_year'],axis=1)\n",
    "    #df_outfield['age']=df_outfield['age'].apply(lambda x: x.split('-')[0]).astype(int)\n",
    "    df_outfield=df_outfield.drop(['age'],axis=1)\n",
    "\n",
    "    df_outfield.nationality = pd.Categorical(df_outfield.nationality)\n",
    "    df_outfield.position = pd.Categorical(df_outfield.position)\n",
    "    df_outfield.squad = pd.Categorical(df_outfield.squad)\n",
    "\n",
    "    nat_dict=dict( enumerate(df_outfield.nationality.cat.categories ) )\n",
    "    pos_dict=dict( enumerate(df_outfield.position.cat.categories ) )\n",
    "    squ_dict=dict( enumerate(df_outfield.squad.cat.categories ) )\n",
    "\n",
    "    #df_outfield['nationality_code']=df_outfield.nationality.cat.codes\n",
    "    #df_outfield['position_code']=df_outfield.position.cat.codes\n",
    "    #df_outfield['squad_code']=df_outfield.squad.cat.codes\n",
    "\n",
    "    df_outfield.set_index('player', inplace=True, drop=True)\n",
    "    df_outfield=df_outfield[[x for x in df_outfield.columns if '90' not in x]]\n",
    "    df_outfield=df_outfield.loc[:, ~(df_outfield==0).all(axis=0)]\n",
    "\n",
    "    #position code category should be ordered from GK, DF to FW\n",
    "    df_outfull=df_outfield.copy(deep=True)\n",
    "    df_outfull['nationality_code']=df_outfield.nationality.cat.codes\n",
    "    df_outfull['position_code']=df_outfield.position.cat.codes\n",
    "    df_outfull['squad_code']=df_outfield.squad.cat.codes\n",
    "\n",
    "\n",
    "    df_outfield=df_outfield.drop('nationality',axis=1)\n",
    "    df_outfield=df_outfield.drop('position',axis=1)\n",
    "    df_outfield=df_outfield.drop('squad',axis=1)\n",
    "\n",
    "    #normalize game starts and minutes by the number of games played\n",
    "    df_outfield[['games_starts','minutes']]=df_outfield[['games_starts','minutes']].div(df_outfield['games'], axis=0)\n",
    "\n",
    "\n",
    "    #normalize by minutes played\n",
    "    df_outfield[df_outfield.columns.difference(['nationality_code','position_code','squad_code']+\\\n",
    "                                               ['birth_year', 'games', 'games_starts', 'minutes']+\\\n",
    "                                               [x for x in df_outfield.columns if 'x' in x]+\\\n",
    "                                               [x for x in df_outfield.columns if '_pct' in x])] = \\\n",
    "    df_outfield[df_outfield.columns.difference(['nationality_code','position_code','squad_code']+\\\n",
    "                                                   ['birth_year', 'games', 'games_starts', 'minutes']+\\\n",
    "                                                   [x for x in df_outfield.columns if 'x' in x]+\\\n",
    "                                                   [x for x in df_outfield.columns if '_pct' in x])]\\\n",
    "                                                   .div(df_outfield['minutes'],axis=0)\n",
    "\n",
    "    df_outfield=df_outfield.astype(float)\n",
    "    df_outfield['birth_year']=df_outfield['birth_year'].astype(int)\n",
    "    #print(df_outfield.shape)\n",
    "    df_outall=df_outfield.copy(deep=True)\n",
    "\n",
    "    todrop=['players_dribbled_past','passes_short','touches','touches_live_ball','passes_medium','passes_live','passes','passes_received',\n",
    "    'passes_received_pct','npxg_net', 'carry_progressive_distance', 'npxg','passes_ground','dribbles','pens_att','pressures_mid_3rd',\n",
    "    'sca_passes_live', 'games_starts', 'passes_long', 'blocked_passes']+['passes_completed','dribbles_vs','pass_targets','touches_mid_3rd','touches_att_3rd','sca_passes_dead','progressive_carries','carries_into_final_third',\n",
    "          'corner_kicks_out', 'gca_passes_live','passes_into_final_third','tackles_def_3rd','corner_kicks_in']+[x for x in df_outfield.columns if '3rd' in x]+[x for x in df_outfield.columns if 'pct' in x]\n",
    "    ['shots_on_target_pct','npxg_per_shot','xg_net','passes_pct','passes_progressive_distance','passes_pct_short','passes_pct_medium','passes_pct_long','xa_net',\n",
    "    'corner_kicks_straight', 'passes_low', 'passes_high',\n",
    "    'passes_left_foot', 'passes_right_foot', 'passes_head',\n",
    "    'throw_ins', 'passes_other_body','passes_offsides', 'passes_oob','dribble_tackles_pct','pressure_regain_pct','dribbles_completed_pct',\n",
    "    'aerials_won_pct']\n",
    "    \n",
    "    df_outfield.drop([x for x in todrop if x in df_outfield.columns],axis=1,inplace=True)\n",
    "    #print(df_outfield.shape)\n",
    "    \n",
    "    ### remove duplicate players \n",
    "    #except for the year\n",
    "    age=df_outfield['birth_year'][~df_outfield.index.duplicated(keep='first')]\n",
    "    df_outfield=df_outfield.sum(level=0)\n",
    "    df_outfield['birth_year']=age\n",
    "    #print(df_outfield.shape)\n",
    "    \n",
    "    #ugly because of the duplicate players with different positions in different teams\n",
    "    df_gk_extra=df_outfield.loc[df_outfull[df_outfull['position']=='GK'].index.unique()]\n",
    "    df_outfield=df_outfield.loc[df_outfull[df_outfull['position']!='GK'].index.unique()]\n",
    "    df_outfull=df_outfull.loc[df_outfield.index]\n",
    "\n",
    "    \n",
    "    \n",
    "    return df_outfield, df_outall, df_gk_extra\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up Keeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_keeper(df_keeper, df_gk_extra):\n",
    "    df_keeper=df_keeper.fillna(0)\n",
    "\n",
    "    #df_keeper=df_keeper.drop(['birth_year'],axis=1)\n",
    "    #df_keeper['age']=df_keeper['age'].apply(lambda x: x.split('-')[0]).astype(int)\n",
    "    df_keeper=df_keeper.drop(['age'],axis=1)\n",
    "    df_keeper.columns=[x[:-3] if x.endswith('_gk') else x for x in df_keeper.columns]\n",
    "\n",
    "    df_keeper.nationality = pd.Categorical(df_keeper.nationality)\n",
    "    df_keeper.position = pd.Categorical(df_keeper.position)\n",
    "    df_keeper.squad = pd.Categorical(df_keeper.squad)\n",
    "\n",
    "    nat_dict=dict( enumerate(df_keeper.nationality.cat.categories ) )\n",
    "    pos_dict=dict( enumerate(df_keeper.position.cat.categories ) )\n",
    "    squ_dict=dict( enumerate(df_keeper.squad.cat.categories ) )\n",
    "\n",
    "    df_keeper.set_index('player', inplace=True, drop=True)\n",
    "    df_keeper=df_keeper[[x for x in df_keeper.columns if '90' not in x]]\n",
    "    df_keeper=df_keeper.loc[:, ~(df_keeper==0).all(axis=0)]\n",
    "\n",
    "\n",
    "\n",
    "    #position code category should be ordered from GK, DF to FW\n",
    "    df_keefull=df_keeper.copy(deep=True)\n",
    "    df_keefull['nationality_code']=df_keeper.nationality.cat.codes\n",
    "    df_keefull['position_code']=df_keeper.position.cat.codes\n",
    "    df_keefull['squad_code']=df_keeper.squad.cat.codes\n",
    "\n",
    "\n",
    "    df_keeper=df_keeper.drop('nationality',axis=1)\n",
    "    df_keeper=df_keeper.drop('position',axis=1)\n",
    "    df_keeper=df_keeper.drop('squad',axis=1)\n",
    "\n",
    "    #normalize game starts and minutes by the number of games played\n",
    "    df_keeper[['games_starts','minutes']]=df_keeper[['games_starts','minutes']].div(df_keeper['games'], axis=0)\n",
    "\n",
    "\n",
    "    #normalize by minutes played\n",
    "    df_keeper[df_keeper.columns.difference(['nationality_code','position_code','squad_code']+\\\n",
    "                                               ['birth_year', 'games', 'games_starts', 'minutes']+\\\n",
    "                                               [x for x in df_keeper.columns if 'x' in x]+\\\n",
    "                                               [x for x in df_keeper.columns if '_pct' in x])] = \\\n",
    "        df_keeper[df_keeper.columns.difference(['nationality_code','position_code','squad_code']+\\\n",
    "                                                   ['birth_year', 'games', 'games_starts', 'minutes']+\\\n",
    "                                                   [x for x in df_keeper.columns if 'x' in x]+\\\n",
    "                                                   [x for x in df_keeper.columns if '_pct' in x])]\\\n",
    "                                                   .div(df_keeper['minutes'],axis=0)\n",
    "\n",
    "    df_keeper=df_keeper.astype(float)\n",
    "    df_keeper['birth_year']=df_keeper['birth_year'].astype(int)\n",
    "    #print(df_keeper.shape)\n",
    "    df_keeall=df_keeper.copy(deep=True)\n",
    "\n",
    "    todrop=['games_starts','save_pct','clean_sheets_pct','passes_throws','passes_launched','wins','losses','draws']+[x for x in df_keeper.columns if 'pct' in x]\n",
    "    df_keeper.drop([x for x in todrop if x in df_keeper.columns],axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    age=df_keeper['birth_year'][~df_keeper.index.duplicated(keep='first')]\n",
    "    df_keeper=df_keeper.sum(level=0)\n",
    "    df_keeper['birth_year']=age\n",
    "    #print(df_keeper.shape)\n",
    "    \n",
    "    df_keeper=pd.concat([df_keeper,df_gk_extra],axis=1)\n",
    "    df_keeper = df_keeper.loc[:,~df_keeper.columns.duplicated()]\n",
    "    df_keeper=df_keeper.loc[:, ~(df_keeper==0).all(axis=0)]\n",
    "    \n",
    "    return df_keeper, df_keeall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_outfield=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Outfield_clean.hdf',key='pl')\n",
    "#df_keeper=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Keeper_clean.hdf',key='pl')\n",
    "\n",
    "def clean_players(df_outfield, df_keeper):\n",
    "    \n",
    "    df_outfield, df_outfield_all, df_gk_extra = clean_outfield(df_outfield)\n",
    "    df_keeper, df_keall = clean_keeper(df_keeper, df_gk_extra)\n",
    "    \n",
    "    df_outfield['keeper']=0\n",
    "    df_keeper['keeper']=1\n",
    "\n",
    "    df_players=pd.concat([df_outfield,df_keeper],axis=0).fillna(0)\n",
    "    \n",
    "    return df_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Team from Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_team_from_lineup(lineup, df_players):\n",
    "\n",
    "    df_players=df_players.loc[lineup.index.intersection(df_players.index)]\n",
    "\n",
    "    df_players=df_players.append(pd.DataFrame(np.nan, columns=df_players.columns, index=lineup.index.difference(df_players.index)))\n",
    "    df_players=df_players.loc[lineup.index].fillna(0)\n",
    "    \n",
    "    df_players['bench']=lineup['bench']\n",
    "    df_players['team']=lineup['team']\n",
    "    #missing=df_players[df_players.isna().any(axis=1)].index\n",
    "\n",
    "    #df_players = df_players[~df_players.index.duplicated(keep='first')]\n",
    "    #df_players = df_players.fillna(0)\n",
    "    \n",
    "    return df_players, lineup.index.difference(df_players.index)\n",
    "\n",
    "def fillto50(lineup):\n",
    "    team1=lineup[lineup['team']==0]\n",
    "    if len(team1)<24:\n",
    "        team1=team1.append(pd.DataFrame([[0,1,lineup['formation'].iloc[0]]]*(24-team1.shape[0]), \n",
    "                                        columns=team1.columns, \n",
    "                                        index=['dummy1'+str(x) for x in range((24-team1.shape[0]))]))\n",
    "\n",
    "    team2=lineup[lineup['team']==1]\n",
    "    if len(team2)<24:\n",
    "        team2=team2.append(pd.DataFrame([[0,1,lineup['formation'].iloc[0]]]*(24-team2.shape[0]), \n",
    "                                        columns=team2.columns, \n",
    "                                        index=['dummy2'+str(x) for x in range((24-team2.shape[0]))]))\n",
    "\n",
    "    return pd.concat([team1,team2],axis=0)\n",
    "\n",
    "#df_players.drop(['wins','draws','losses'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_report(match, df_players):\n",
    "    \n",
    "        team1,team2,gk1,gk2,shots,lineup=get_report_data(path=match)\n",
    "        teams=pd.concat([team1,team2],axis=0).reset_index(drop=True)\n",
    "        gks=pd.concat([gk1,gk2],axis=0).reset_index(drop=True)\n",
    "\n",
    "        teams.set_index('player',drop=True,inplace=True)\n",
    "        gks.set_index('player',drop=True,inplace=True)\n",
    "        lineup.set_index('player',drop=True,inplace=True)\n",
    "\n",
    "        lineup['bench']=lineup['bench'].astype(int)\n",
    "        lineup.team=(lineup.team==lineup.team.unique()[1]).astype(int)\n",
    "        lineup=fillto50(lineup)\n",
    "                     \n",
    "        teams=teams[['minutes','goals','assists','cards_yellow','cards_red','own_goals']]\n",
    "        gks.columns=[x[:-3] if x.endswith('_gk') else x for x in gks.columns]\n",
    "        gks=gks[['goals_against','saves']]\n",
    "        #results=pd.concat([teams,gks],axis=1).loc[lineup.index].fillna(0)\n",
    "        \n",
    "        results=pd.concat([teams,gks],axis=1)\n",
    "        results=results.append(pd.DataFrame(np.nan, columns=results.columns, index=lineup.index.difference(results.index)))\n",
    "        results=results.loc[lineup.index].fillna(0)\n",
    "        \n",
    "        inp, missing=build_team_from_lineup(lineup, df_players)\n",
    "\n",
    "        #possibly redundant\n",
    "        results.loc[missing]=0\n",
    "        \n",
    "        return inp, results, lineup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixs=[]\n",
    "for series in ['SA2021','SA1920','BL2021','BL1920','LU2021','LU1920','PL2021','PL1920','LL2021','LL1920']+\\\n",
    "              ['SA1819','SA1718','BL1819','BL1718','LU1819','LU1718','PL1819','PL1718','LL1819','LL1718']:\n",
    "    \n",
    "    df_fixs.append(pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/'+series+'_Fix.hdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allplayers by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players=[]\n",
    "allpl_year=[]\n",
    "    \n",
    "for year in ['1718','1819','1920','2021']:\n",
    "    \n",
    "    for league in ['SA','BL','LU','PL','LL']:\n",
    "        \n",
    "        series=league+year\n",
    "        df_outfield = pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/'+series+'_Outfield.hdf')\n",
    "        df_keeper = pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/'+series+'_Keeper.hdf')\n",
    "        cp = clean_players(df_outfield, df_keeper)\n",
    "        if 'gca_og_for' in cp:\n",
    "            #this is available only for the last year\n",
    "            cp.drop(['gca_og_for'],axis=1,inplace=True) \n",
    "        if 'corner_kicks_straight' in cp:\n",
    "            #this is available only for the last year\n",
    "            cp.drop(['corner_kicks_straight'],axis=1,inplace=True) \n",
    "\n",
    "        df_players.append(cp.replace(np.inf,0))#.fillna(0).astype(float))\n",
    "\n",
    "    \n",
    "    ay = pd.concat(df_players, axis=0).fillna(0).astype(float)\n",
    "    \n",
    "    age=ay['birth_year'][~ay.index.duplicated(keep='first')]\n",
    "    ay=ay.sum(level=0)\n",
    "    ay['birth_year']=age\n",
    "    \n",
    "    allpl_year.append(ay)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(allpl_year)):\n",
    "    for j in range(len(allpl_year)):\n",
    "        if i!=j:\n",
    "            missing=allpl_year[j].index.difference(allpl_year[i].index)\n",
    "            missingDf=pd.DataFrame(np.nan,columns=allpl_year[j].columns,index=missing)\n",
    "            missingDf['birth_year']=allpl_year[j]['birth_year'].loc[missing]\n",
    "            allpl_year[i]=allpl_year[i].append(missingDf)\n",
    "            \n",
    "for i in range(len(allpl_year)):\n",
    "    allpl_year[i]=allpl_year[i].sort_index()\n",
    "    \n",
    "#fillna if you want to keep them as separate channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge them with weights\n",
    "from functools import reduce\n",
    "import copy\n",
    "allpl_yr_nu=copy.deepcopy(allpl_year)\n",
    "\n",
    "allpl_weighted=[]\n",
    "while len(allpl_yr_nu)>0:\n",
    "    \n",
    "    current=allpl_yr_nu.pop()\n",
    "    columns=current.columns\n",
    "    weight=1.0\n",
    "    \n",
    "    by=current['birth_year']\n",
    "    current.drop(['birth_year'],axis=1,inplace=True)\n",
    "    \n",
    "    div=pd.Series([1]*current.shape[0], index=current.index)\n",
    "    \n",
    "    for i in range(len(allpl_yr_nu))[::-1]:\n",
    "    \n",
    "        ######HERE IS THE WEIGHT\n",
    "        weight=weight/4\n",
    "        ########################\n",
    "        \n",
    "        to_add=allpl_yr_nu[i]*weight\n",
    "        to_add.drop(['birth_year'],axis=1,inplace=True)\n",
    "\n",
    "        notmissing=np.where(~to_add.isnull().all(1))\n",
    "        div.iloc[notmissing]+=weight\n",
    "\n",
    "        to_add=to_add.fillna(0)\n",
    "        \n",
    "\n",
    "        current=current.add(to_add)\n",
    "        \n",
    "    current=current.divide(div,axis=0)\n",
    "    current.dropna(how='all',axis=0,inplace=True)\n",
    "\n",
    "    current['birth_year']=by.loc[current.index]\n",
    "    \n",
    "    allpl_weighted.append(current[columns])\n",
    "    \n",
    "allpl_weighted=allpl_weighted[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "allpl=pd.concat(allpl_weighted, axis=0)\n",
    "allpl.drop(['keeper'], axis=1, inplace=True)\n",
    "\n",
    "ts=tsvd(n_components=int(allpl.shape[1])-1, random_state=32)\n",
    "ts.fit(allpl)\n",
    "tsvd_var_ratios = ts.explained_variance_ratio_\n",
    "\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "\n",
    "    total_variance = 0.0\n",
    "    n_components = 0\n",
    "\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance += explained_variance        \n",
    "        n_components += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "\n",
    "    return n_components\n",
    "\n",
    "# Run function\n",
    "num_comp=select_n_components(tsvd_var_ratios, 0.9999)\n",
    "print(num_comp)\n",
    "ts=tsvd(n_components=num_comp, random_state=32)\n",
    "ts.fit(allpl)\n",
    "\n",
    "allpl_weighted_ts=[]\n",
    "for i,play in enumerate(allpl_weighted):\n",
    "    #print(ts.transform(play))\n",
    "    #print([x for x in allpl.columns if x not in play.columns])\n",
    "    kp = play['keeper']\n",
    "    play = play.drop(['keeper'],axis=1)\n",
    "    try:\n",
    "        ts.transform(play)\n",
    "    except:\n",
    "        print(i)\n",
    "    allpl_weighted_ts.append(pd.DataFrame(ts.transform(play), index=play.index))\n",
    "    allpl_weighted_ts[-1]['keeper'] = kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open(r'/Users/federico comitani/GitHub/sodakick/data/allplayers_weighted.pkl', 'wb') as pk:\\n    pickle.dump(allpl_weighted,pk)\\n    \\nwith open(r'/Users/federico comitani/GitHub/sodakick/data/allplayers_weighted_tsvd.pkl', 'wb') as pk:\\n    pickle.dump(allpl_weighted_ts,pk)\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"with open(r'/Users/federico comitani/GitHub/sodakick/data/allplayers_weighted.pkl', 'wb') as pk:\n",
    "    pickle.dump(allpl_weighted,pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/allplayers_weighted_tsvd.pkl', 'wb') as pk:\n",
    "    pickle.dump(allpl_weighted_ts,pk)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_year_dict={'1718': allpl_weighted_ts[0],\n",
    "                   '1819': allpl_weighted_ts[1],\n",
    "                   '1920': allpl_weighted_ts[2],\n",
    "                   '2021': allpl_weighted_ts[3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now build them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2021\n",
      "357\n",
      "SA1920\n",
      "737\n",
      "BL2021\n",
      "1024\n",
      "BL1920\n",
      "1330\n",
      "LU2021\n",
      "1689\n",
      "LU1920\n",
      "1968\n",
      "PL2021\n",
      "2315\n",
      "PL1920\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "lineups=[]\n",
    "\n",
    "exit=False\n",
    "for i,series in enumerate(['SA2021','SA1920','BL2021','BL1920','LU2021','LU1920','PL2021','PL1920','LL2021','LL1920']):\n",
    "    \n",
    "    print(series)\n",
    "    \n",
    "    for match in df_fixs[i]['match_report'].values:\n",
    "\n",
    "        try:\n",
    "\n",
    "            inp, results, lineup = clean_report(match, players_year_dict[series[2:]])\n",
    "            \n",
    "            if inp.shape[0]<48:\n",
    "                print(match)\n",
    "                exit=True\n",
    "                break\n",
    "            \n",
    "            inputs.append(inp.astype(float).values.flatten())\n",
    "            outputs.append(results.astype(float).values.flatten())\n",
    "            lineups.append(lineup.reset_index())\n",
    "            \n",
    "        except:\n",
    "\n",
    "            pass\n",
    "        \n",
    "    if exit:\n",
    "        break\n",
    "        \n",
    "    print(len(inputs))\n",
    "    \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)\n",
    "\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp_a_210614.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out_a_210614.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_lineup_a_210614.pkl', 'wb') as pk:\n",
    "    pickle.dump(lineups,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA1819\n",
      "357\n",
      "SA1718\n",
      "737\n",
      "BL1819\n",
      "1024\n",
      "BL1718\n",
      "1330\n",
      "LU1819\n",
      "1688\n",
      "LU1718\n",
      "1967\n",
      "PL1819\n",
      "2314\n",
      "PL1718\n",
      "2692\n",
      "LL1819\n",
      "3044\n",
      "LL1718\n",
      "3421\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "lineups=[]\n",
    "\n",
    "exit=False\n",
    "for i,series in enumerate(['SA1819','SA1718','BL1819','BL1718','LU1819','LU1718','PL1819','PL1718','LL1819','LL1718']):\n",
    "    \n",
    "    print(series)\n",
    "    \n",
    "    for match in df_fixs[i]['match_report'].values:\n",
    "\n",
    "        try:\n",
    "\n",
    "            inp, results, lineup = clean_report(match, players_year_dict[series[2:]])\n",
    "            \n",
    "            if inp.shape[0]<48:\n",
    "                print(match)\n",
    "                exit=True\n",
    "                break\n",
    "\n",
    "            inputs.append(inp.astype(float).values.flatten())\n",
    "            outputs.append(results.astype(float).values.flatten())\n",
    "            lineups.append(lineup.reset_index())\n",
    "            \n",
    "        except:\n",
    "\n",
    "            pass\n",
    "\n",
    "    print(len(inputs))\n",
    "    \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)\n",
    "\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp_b_210614.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out_b_210614.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_lineup_b_210614.pkl', 'wb') as pk:\n",
    "    pickle.dump(lineups,pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying and merging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp_a.pkl', 'rb') as pk:\n",
    "    inputs=pickle.load(pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out_a.pkl', 'rb') as pk:\n",
    "    outputs=pickle.load(pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp_b.pkl', 'rb') as pk:\n",
    "    inputs2=pickle.load(pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out_b.pkl', 'rb') as pk:\n",
    "    outputs2=pickle.load(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=np.concatenate([inputs,inputs2])\n",
    "outputs=np.concatenate([outputs,outputs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
