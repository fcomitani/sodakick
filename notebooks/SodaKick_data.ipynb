{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player index, team may matter in chosing who plays first and who doesn't\n",
    "#for now I won't use them, but should be considered \n",
    "#also role may be important, for now only goalkeeper will be accounted for in the final dataframe\n",
    "#if a team is away or home depends on the order of the report so team 0 will be home, team 1 away\n",
    "\n",
    "\n",
    "#it seems some players are missing in the list of players (e.g. Antonino Barilla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys, getopt\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import umap\n",
    "from sklearn.decomposition import TruncatedSVD as tsvd\n",
    "\n",
    "def nearZeroVarDropAuto(df,thresh=0.99):\n",
    "    vVal=df.var(axis=0).values\n",
    "    cs=pd.Series(vVal).sort_values(ascending=False).cumsum()\n",
    "    remove=cs[cs>cs.values[-1]*thresh].index.values\n",
    "    return df.drop(df.columns[remove],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run SodaKick_download_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outfield=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Outfield.hdf',key='pl')\n",
    "df_team=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Team.hdf',key='pl')\n",
    "df_vs=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Vs.hdf',key='pl')\n",
    "df_keeper=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_keeper.hdf',key='pl')\n",
    "df_fix=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_fix.hdf',key='pl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up Outfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outfield(df_outfield):\n",
    "\n",
    "    df_outfield=df_outfield.fillna(0)\n",
    "\n",
    "    #df_outfield=df_outfield.drop(['birth_year'],axis=1)\n",
    "    #df_outfield['age']=df_outfield['age'].apply(lambda x: x.split('-')[0]).astype(int)\n",
    "    df_outfield=df_outfield.drop(['age'],axis=1)\n",
    "\n",
    "    df_outfield.nationality = pd.Categorical(df_outfield.nationality)\n",
    "    df_outfield.position = pd.Categorical(df_outfield.position)\n",
    "    df_outfield.squad = pd.Categorical(df_outfield.squad)\n",
    "\n",
    "    nat_dict=dict( enumerate(df_outfield.nationality.cat.categories ) )\n",
    "    pos_dict=dict( enumerate(df_outfield.position.cat.categories ) )\n",
    "    squ_dict=dict( enumerate(df_outfield.squad.cat.categories ) )\n",
    "\n",
    "    #df_outfield['nationality_code']=df_outfield.nationality.cat.codes\n",
    "    #df_outfield['position_code']=df_outfield.position.cat.codes\n",
    "    #df_outfield['squad_code']=df_outfield.squad.cat.codes\n",
    "\n",
    "    df_outfield.set_index('player', inplace=True, drop=True)\n",
    "    df_outfield=df_outfield[[x for x in df_outfield.columns if '90' not in x]]\n",
    "    df_outfield=df_outfield.loc[:, ~(df_outfield==0).all(axis=0)]\n",
    "\n",
    "    #position code category should be ordered from GK, DF to FW\n",
    "    df_outfull=df_outfield.copy(deep=True)\n",
    "    df_outfull['nationality_code']=df_outfield.nationality.cat.codes\n",
    "    df_outfull['position_code']=df_outfield.position.cat.codes\n",
    "    df_outfull['squad_code']=df_outfield.squad.cat.codes\n",
    "\n",
    "\n",
    "    df_outfield=df_outfield.drop('nationality',axis=1)\n",
    "    df_outfield=df_outfield.drop('position',axis=1)\n",
    "    df_outfield=df_outfield.drop('squad',axis=1)\n",
    "\n",
    "    #normalize game starts and minutes by the number of games played\n",
    "    df_outfield[['games_starts','minutes']]=df_outfield[['games_starts','minutes']].div(df_outfield['games'], axis=0)\n",
    "\n",
    "\n",
    "    #normalize by minutes played\n",
    "    df_outfield[df_outfield.columns.difference(['nationality_code','position_code','squad_code']+\\\n",
    "                                               ['birth_year', 'games', 'games_starts', 'minutes']+\\\n",
    "                                               [x for x in df_outfield.columns if 'x' in x]+\\\n",
    "                                               [x for x in df_outfield.columns if '_pct' in x])] = \\\n",
    "    df_outfield[df_outfield.columns.difference(['nationality_code','position_code','squad_code']+\\\n",
    "                                                   ['birth_year', 'games', 'games_starts', 'minutes']+\\\n",
    "                                                   [x for x in df_outfield.columns if 'x' in x]+\\\n",
    "                                                   [x for x in df_outfield.columns if '_pct' in x])]\\\n",
    "                                                   .div(df_outfield['minutes'],axis=0)\n",
    "\n",
    "    df_outfield=df_outfield.astype(float)\n",
    "    df_outfield['birth_year']=df_outfield['birth_year'].astype(int)\n",
    "    #print(df_outfield.shape)\n",
    "    df_outall=df_outfield.copy(deep=True)\n",
    "\n",
    "    todrop=['players_dribbled_past','passes_short','touches','touches_live_ball','passes_medium','passes_live','passes','passes_received',\n",
    "    'passes_received_pct','npxg_net', 'carry_progressive_distance', 'npxg','passes_ground','dribbles','pens_att','pressures_mid_3rd',\n",
    "    'sca_passes_live', 'games_starts', 'passes_long', 'blocked_passes']+['passes_completed','dribbles_vs','pass_targets','touches_mid_3rd','touches_att_3rd','sca_passes_dead','progressive_carries','carries_into_final_third',\n",
    "          'corner_kicks_out', 'gca_passes_live','passes_into_final_third','tackles_def_3rd','corner_kicks_in']+[x for x in df_outfield.columns if '3rd' in x]+[x for x in df_outfield.columns if 'pct' in x]\n",
    "    ['shots_on_target_pct','npxg_per_shot','xg_net','passes_pct','passes_progressive_distance','passes_pct_short','passes_pct_medium','passes_pct_long','xa_net',\n",
    "    'corner_kicks_straight', 'passes_low', 'passes_high',\n",
    "    'passes_left_foot', 'passes_right_foot', 'passes_head',\n",
    "    'throw_ins', 'passes_other_body','passes_offsides', 'passes_oob','dribble_tackles_pct','pressure_regain_pct','dribbles_completed_pct',\n",
    "    'aerials_won_pct']\n",
    "    \n",
    "    df_outfield.drop([x for x in todrop if x in df_outfield.columns],axis=1,inplace=True)\n",
    "    #print(df_outfield.shape)\n",
    "    \n",
    "    ### remove duplicate players \n",
    "    #except for the year\n",
    "    age=df_outfield['birth_year'][~df_outfield.index.duplicated(keep='first')]\n",
    "    df_outfield=df_outfield.sum(level=0)\n",
    "    df_outfield['birth_year']=age\n",
    "    #print(df_outfield.shape)\n",
    "    \n",
    "    #ugly because of the duplicate players with different positions in different teams\n",
    "    df_gk_extra=df_outfield.loc[df_outfull[df_outfull['position']=='GK'].index.unique()]\n",
    "    df_outfield=df_outfield.loc[df_outfull[df_outfull['position']!='GK'].index.unique()]\n",
    "    df_outfull=df_outfull.loc[df_outfield.index]\n",
    "\n",
    "    \n",
    "    \n",
    "    return df_outfield, df_outall, df_gk_extra\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation removal, now skipping\n",
    "\"\"\"def corr_pairs(df):\n",
    "    correlated=[] # Set of all the names of deleted columns\n",
    "    corr_matrix = df.corr().abs()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1,len(corr_matrix.columns)):\n",
    "            correlated.append((df.columns[i],df.columns[j],corr_matrix.iloc[i, j]))\n",
    "    \n",
    "    return pd.DataFrame(correlated, columns=['col1','col2','correlation']).sort_values('correlation',ascending=False)\n",
    "\n",
    "corr_cols=corr_pairs(df_outfield)\n",
    "sns.distplot(corr_cols['correlation'])\n",
    "\n",
    "def iteremove_corr(df,thr, limit=-1):\n",
    "    \n",
    "    tmp=df.copy(deep=True)\n",
    "    print(tmp.shape[1], end=' ')\n",
    "    step=0\n",
    "    \n",
    "    while True and step!=limit:\n",
    "        \n",
    "        correlated=[] # Set of all the names of deleted columns\n",
    "        corr_matrix = tmp.corr().abs()\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1,len(corr_matrix.columns)):\n",
    "                correlated.append((tmp.columns[i],tmp.columns[j],corr_matrix.iloc[i, j]))\n",
    "\n",
    "        corr_cols=pd.DataFrame(correlated, columns=['col1','col2','correlation']).sort_values('correlation',ascending=False)\n",
    "\n",
    "        if corr_cols['correlation'].iloc[0]<=thr:\n",
    "            break\n",
    "            \n",
    "        tmp.drop(corr_cols[corr_cols['correlation']>thr]['col2'].values,axis=1, inplace=True)\n",
    "        print(tmp.shape[1], end=' ')\n",
    "        step+=1\n",
    "    \n",
    "    return tmp\n",
    "        \n",
    "df_outfield_nc=iteremove_corr(df_outfield,.75, limit=1)\n",
    "corr_cols=corr_pairs(df_outfield_nc)\n",
    "\n",
    "sns.distplot(corr_cols['correlation'])\"\"\"\n",
    "\n",
    "#tsvd on single, now skipping will be done at the end with everything\n",
    "\n",
    "\"\"\"ts=tsvd(n_components=int(df_outfield.shape[1])-1, random_state=32)\n",
    "ts.fit_transform(df_outall)\n",
    "tsvd_var_ratios = ts.explained_variance_ratio_\n",
    "\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "\n",
    "    total_variance = 0.0\n",
    "    n_components = 0\n",
    "\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance += explained_variance        \n",
    "        n_components += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "\n",
    "    return n_components\n",
    "\n",
    "# Run function\n",
    "num_comp=select_n_components(tsvd_var_ratios, 0.99)\n",
    "print(num_comp)\n",
    "ts=tsvd(n_components=num_comp, random_state=32)\n",
    "df_outtsvd=pd.DataFrame(ts.fit_transform(df_outall),index=df_outall.index)\"\"\"\n",
    "\n",
    "#mapping\n",
    "\n",
    "\"\"\"mapping=umap.UMAP(metric='cosine', n_components=2, min_dist=0.0, spread=1, n_neighbors=int(np.sqrt(df_outfield_nc.shape[0])), \\\n",
    "                                n_epochs=2500, learning_rate=0.05, \\\n",
    "                                verbose=False, random_state=32)\n",
    "mapping.fit(df_outfield_nc.astype(float).values)\n",
    "mh=pd.DataFrame(mapping.transform(df_outfield_nc.values), index=df_outfield_nc.index)\n",
    "\n",
    "for c in df_outfull.position_code.unique():\n",
    "    plt.scatter(mh[0][df_outfull.position_code==c],mh[1][df_outfull.position_code==c],label=pos_dict[c])\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "\n",
    "sel_cut=nearZeroVarDropAuto(df_outfield, .999)\n",
    "print(sel_cut.shape)\n",
    "\n",
    "mapping=umap.UMAP(metric='cosine', n_components=2, min_dist=0.0, spread=1, n_neighbors=int(np.sqrt(sel_cut.shape[0])), \\\n",
    "                                n_epochs=2500, learning_rate=0.05, \\\n",
    "                                verbose=False, random_state=32)\n",
    "mapping.fit(sel_cut.astype(float).values)\n",
    "mh=pd.DataFrame(mapping.transform(sel_cut.values), index=sel_cut.index)\n",
    "\n",
    "for c in df_outfull.position_code.unique():\n",
    "    plt.scatter(mh[0][df_outfull.position_code==c],mh[1][df_outfull.position_code==c],label=pos_dict[c])\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "sel_cut=df_outtsvd\n",
    "mapping=umap.UMAP(metric='cosine', n_components=2, min_dist=0.0, spread=1, n_neighbors=int(np.sqrt(sel_cut.shape[0])), \\\n",
    "                                n_epochs=2500, learning_rate=0.05, \\\n",
    "                                verbose=False, random_state=32)\n",
    "mapping.fit(sel_cut.astype(float).values)\n",
    "mh=pd.DataFrame(mapping.transform(sel_cut.values), index=sel_cut.index)\n",
    "\n",
    "for c in df_outfull.position_code.unique():\n",
    "    plt.scatter(mh[0][df_outfull.position_code==c],mh[1][df_outfull.position_code==c],label=pos_dict[c])\n",
    "    \n",
    "plt.legend()\"\"\"\n",
    "\n",
    "#df_outfield.to_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Outfield_clean.hdf',key='pl')\n",
    "#df_outall.to_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Outfield_allfeat.hdf',key='pl')\n",
    "#df_outtsvd.to_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Outfield_tsvd.hdf',key='pl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up Keeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_keeper(df_keeper, df_gk_extra):\n",
    "    df_keeper=df_keeper.fillna(0)\n",
    "\n",
    "    #df_keeper=df_keeper.drop(['birth_year'],axis=1)\n",
    "    #df_keeper['age']=df_keeper['age'].apply(lambda x: x.split('-')[0]).astype(int)\n",
    "    df_keeper=df_keeper.drop(['age'],axis=1)\n",
    "    df_keeper.columns=[x[:-3] if x.endswith('_gk') else x for x in df_keeper.columns]\n",
    "\n",
    "    df_keeper.nationality = pd.Categorical(df_keeper.nationality)\n",
    "    df_keeper.position = pd.Categorical(df_keeper.position)\n",
    "    df_keeper.squad = pd.Categorical(df_keeper.squad)\n",
    "\n",
    "    nat_dict=dict( enumerate(df_keeper.nationality.cat.categories ) )\n",
    "    pos_dict=dict( enumerate(df_keeper.position.cat.categories ) )\n",
    "    squ_dict=dict( enumerate(df_keeper.squad.cat.categories ) )\n",
    "\n",
    "    df_keeper.set_index('player', inplace=True, drop=True)\n",
    "    df_keeper=df_keeper[[x for x in df_keeper.columns if '90' not in x]]\n",
    "    df_keeper=df_keeper.loc[:, ~(df_keeper==0).all(axis=0)]\n",
    "\n",
    "\n",
    "\n",
    "    #position code category should be ordered from GK, DF to FW\n",
    "    df_keefull=df_keeper.copy(deep=True)\n",
    "    df_keefull['nationality_code']=df_keeper.nationality.cat.codes\n",
    "    df_keefull['position_code']=df_keeper.position.cat.codes\n",
    "    df_keefull['squad_code']=df_keeper.squad.cat.codes\n",
    "\n",
    "\n",
    "    df_keeper=df_keeper.drop('nationality',axis=1)\n",
    "    df_keeper=df_keeper.drop('position',axis=1)\n",
    "    df_keeper=df_keeper.drop('squad',axis=1)\n",
    "\n",
    "    #normalize game starts and minutes by the number of games played\n",
    "    df_keeper[['games_starts','minutes']]=df_keeper[['games_starts','minutes']].div(df_keeper['games'], axis=0)\n",
    "\n",
    "\n",
    "    #normalize by minutes played\n",
    "    df_keeper[df_keeper.columns.difference(['nationality_code','position_code','squad_code']+\\\n",
    "                                               ['birth_year', 'games', 'games_starts', 'minutes']+\\\n",
    "                                               [x for x in df_keeper.columns if 'x' in x]+\\\n",
    "                                               [x for x in df_keeper.columns if '_pct' in x])] = \\\n",
    "        df_keeper[df_keeper.columns.difference(['nationality_code','position_code','squad_code']+\\\n",
    "                                                   ['birth_year', 'games', 'games_starts', 'minutes']+\\\n",
    "                                                   [x for x in df_keeper.columns if 'x' in x]+\\\n",
    "                                                   [x for x in df_keeper.columns if '_pct' in x])]\\\n",
    "                                                   .div(df_keeper['minutes'],axis=0)\n",
    "\n",
    "    df_keeper=df_keeper.astype(float)\n",
    "    df_keeper['birth_year']=df_keeper['birth_year'].astype(int)\n",
    "    #print(df_keeper.shape)\n",
    "    df_keeall=df_keeper.copy(deep=True)\n",
    "\n",
    "    todrop=['games_starts','save_pct','clean_sheets_pct','passes_throws','passes_launched','wins','losses','draws']+[x for x in df_keeper.columns if 'pct' in x]\n",
    "    df_keeper.drop([x for x in todrop if x in df_keeper.columns],axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    age=df_keeper['birth_year'][~df_keeper.index.duplicated(keep='first')]\n",
    "    df_keeper=df_keeper.sum(level=0)\n",
    "    df_keeper['birth_year']=age\n",
    "    #print(df_keeper.shape)\n",
    "    \n",
    "    df_keeper=pd.concat([df_keeper,df_gk_extra],axis=1)\n",
    "    df_keeper = df_keeper.loc[:,~df_keeper.columns.duplicated()]\n",
    "    df_keeper=df_keeper.loc[:, ~(df_keeper==0).all(axis=0)]\n",
    "    \n",
    "    return df_keeper, df_keeall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_keeper.to_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Keeper_clean.hdf',key='pl')\n",
    "#df_keeall.to_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Keeper_allfeat.hdf',key='pl')\n",
    "#df_keetsvd.to_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Keeper_tsvd.hdf',key='pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_outfield=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Outfield_clean.hdf',key='pl')\n",
    "#df_keeper=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Keeper_clean.hdf',key='pl')\n",
    "\n",
    "def clean_players(df_outfield, df_keeper):\n",
    "    \n",
    "    df_outfield, df_outfield_all, df_gk_extra = clean_outfield(df_outfield)\n",
    "    df_keeper, df_keall = clean_keeper(df_keeper, df_gk_extra)\n",
    "    \n",
    "    df_outfield['keeper']=0\n",
    "    df_keeper['keeper']=1\n",
    "\n",
    "    df_players=pd.concat([df_outfield,df_keeper],axis=0).fillna(0)\n",
    "    \n",
    "    return df_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Team from Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_team_from_lineup(lineup, df_players):\n",
    "\n",
    "    df_players=df_players.loc[lineup.index.intersection(df_players.index)]\n",
    "\n",
    "    df_players=df_players.append(pd.DataFrame(np.nan, columns=df_players.columns, index=lineup.index.difference(df_players.index)))\n",
    "    df_players=df_players.loc[lineup.index].fillna(0)\n",
    "    \n",
    "    df_players['bench']=lineup['bench']\n",
    "    df_players['team']=lineup['team']\n",
    "    #missing=df_players[df_players.isna().any(axis=1)].index\n",
    "\n",
    "    df_players = df_players[~df_players.index.duplicated(keep='first')]\n",
    "    #df_players = df_players.fillna(0)\n",
    "    \n",
    "    return df_players, lineup.index.difference(df_players.index)\n",
    "\n",
    "def fillto50(lineup):\n",
    "    team1=lineup[lineup['team']==0]\n",
    "    if len(team1)<25:\n",
    "        team1=team1.append(pd.DataFrame([[0,1,lineup['formation'].iloc[0]]]*(25-team1.shape[0]), \n",
    "                                        columns=team1.columns, \n",
    "                                        index=['dummy1'+str(x) for x in range((25-team1.shape[0]))]))\n",
    "\n",
    "    team2=lineup[lineup['team']==1]\n",
    "    if len(team2)<25:\n",
    "        team2=team2.append(pd.DataFrame([[0,1,lineup['formation'].iloc[0]]]*(25-team2.shape[0]), \n",
    "                                        columns=team2.columns, \n",
    "                                        index=['dummy2'+str(x) for x in range((25-team2.shape[0]))]))\n",
    "\n",
    "    return pd.concat([team1,team2],axis=0)\n",
    "\n",
    "#df_players.drop(['wins','draws','losses'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_report(match, df_players):\n",
    "    \n",
    "        team1,team2,gk1,gk2,shots,lineup=get_report_data(path=match)\n",
    "        teams=pd.concat([team1,team2],axis=0).reset_index(drop=True)\n",
    "        gks=pd.concat([gk1,gk2],axis=0).reset_index(drop=True)\n",
    "\n",
    "        teams.set_index('player',drop=True,inplace=True)\n",
    "        gks.set_index('player',drop=True,inplace=True)\n",
    "        lineup.set_index('player',drop=True,inplace=True)\n",
    "\n",
    "        lineup['bench']=lineup['bench'].astype(int)\n",
    "        lineup.team=(lineup.team==lineup.team.unique()[1]).astype(int)\n",
    "        lineup=fillto50(lineup)\n",
    "                \n",
    "        teams=teams[['minutes','goals','assists','cards_yellow','cards_red','own_goals']]\n",
    "        gks.columns=[x[:-3] if x.endswith('_gk') else x for x in gks.columns]\n",
    "        gks=gks[['goals_against','saves']]\n",
    "        #results=pd.concat([teams,gks],axis=1).loc[lineup.index].fillna(0)\n",
    "        \n",
    "        results=pd.concat([teams,gks],axis=1)\n",
    "        results=results.append(pd.DataFrame(np.nan, columns=results.columns, index=lineup.index.difference(results.index)))\n",
    "        results=results.loc[lineup.index].fillna(0)\n",
    "        \n",
    "        inp, missing=build_team_from_lineup(lineup, df_players)\n",
    "\n",
    "        #possibly redundant\n",
    "        results.loc[missing]=0\n",
    "        \n",
    "        return inp, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tsvd all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players=[]\n",
    "df_fixs=[]\n",
    "for series in ['SA2021','SA1920','BL2021','BL1920','LU2021','LU1920','PL2021','PL1920','LL2021','LL1920']+\\\n",
    "              ['SA1819','SA1718','BL1819','BL1718','LU1819','LU1718','PL1819','PL1718','LL1819','LL1718']:\n",
    "\n",
    "    df_outfield = pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/'+series+'_Outfield.hdf')\n",
    "    df_keeper = pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/'+series+'_Keeper.hdf')\n",
    "    cp = clean_players(df_outfield, df_keeper)\n",
    "    if 'gca_og_for' in cp:\n",
    "        #this is available only for the last year\n",
    "        cp.drop(['gca_og_for'],axis=1,inplace=True) \n",
    "    if 'corner_kicks_straight' in cp:\n",
    "        #this is available only for the last year\n",
    "        cp.drop(['corner_kicks_straight'],axis=1,inplace=True) \n",
    "    df_players.append(cp.replace(np.inf,0))#.fillna(0).astype(float))\n",
    "    \n",
    "    df_fixs.append(pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/'+series+'_Fix.hdf'))\n",
    "   \n",
    "allpl = pd.concat(df_players, axis=0).fillna(0).astype(float)\n",
    "allpl.drop(['keeper'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "ts=tsvd(n_components=int(allpl.shape[1])-1, random_state=32)\n",
    "ts.fit(allpl)\n",
    "tsvd_var_ratios = ts.explained_variance_ratio_\n",
    "\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "\n",
    "    total_variance = 0.0\n",
    "    n_components = 0\n",
    "\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance += explained_variance        \n",
    "        n_components += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "\n",
    "    return n_components\n",
    "\n",
    "# Run function\n",
    "num_comp=select_n_components(tsvd_var_ratios, 0.9999)\n",
    "print(num_comp)\n",
    "ts=tsvd(n_components=num_comp, random_state=32)\n",
    "ts.fit(allpl)\n",
    "\n",
    "df_players_ts=[]\n",
    "for i,play in enumerate(df_players):\n",
    "    #print(ts.transform(play))\n",
    "    #print([x for x in allpl.columns if x not in play.columns])\n",
    "    kp = play['keeper']\n",
    "    play = play.drop(['keeper'],axis=1)\n",
    "    try:\n",
    "        ts.transform(play)\n",
    "    except:\n",
    "        print(i)\n",
    "    df_players_ts.append(pd.DataFrame(ts.transform(play), index=play.index))\n",
    "    df_players_ts[-1]['keeper'] = kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2021\n",
      "357\n",
      "SA1920\n",
      "737\n",
      "BL2021\n",
      "1024\n",
      "BL1920\n",
      "1330\n",
      "LU2021\n",
      "1689\n",
      "LU1920\n",
      "1968\n",
      "PL2021\n",
      "2315\n",
      "PL1920\n",
      "2693\n",
      "LL2021\n",
      "3043\n",
      "LL1920\n",
      "3414\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "\n",
    "for i,series in enumerate(['SA2021','SA1920','BL2021','BL1920',\n",
    "                           'LU2021','LU1920','PL2021','PL1920',\n",
    "                           'LL2021','LL1920']):\n",
    "    \n",
    "    print(series)\n",
    "    \n",
    "    for match in df_fixs[i]['match_report'].values:\n",
    "\n",
    "        try:\n",
    "\n",
    "            inp, results = clean_report(match, df_players_ts[i])\n",
    "\n",
    "            inputs.append(inp.astype(float).values.flatten())\n",
    "            outputs.append(results.astype(float).values.flatten())\n",
    "\n",
    "        except:\n",
    "\n",
    "            pass\n",
    "\n",
    "    print(len(inputs))\n",
    "    \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)\n",
    "\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_inp_2a.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_out_2a.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA1819\n",
      "/en/matches/f68d48b6/Internazionale-Benevento-January-30-2021-Serie-A\n",
      "357\n",
      "SA1718\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "\n",
    "for i,series in enumerate(['SA1819','SA1718','BL1819','BL1718',\n",
    "                           'LU1819','LU1718','PL1819','PL1718',\n",
    "                           'LL1819','LL1718']):\n",
    "    \n",
    "    print(series)\n",
    "    \n",
    "    for match in df_fixs[i]['match_report'].values:\n",
    "\n",
    "        try:\n",
    "            inp, results = clean_report(match, df_players_ts[i])\n",
    "\n",
    "            inputs.append(inp.astype(float).values.flatten())\n",
    "            outputs.append(results.astype(float).values.flatten())\n",
    "            \n",
    "        except:\n",
    "        \n",
    "            print(match)\n",
    "\n",
    "    print(len(inputs))\n",
    "    \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)\n",
    "\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_inp_2b.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_out_2b.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_output(output,lineup):\n",
    "\n",
    "    reframe=pd.DataFrame(output.reshape(50,8), index=lineup.index,\n",
    "                 columns=['minutes','goals','assists','cards_yellow','cards_red','own_goals','goals_against','saves'])\n",
    "    reframe.drop([x for x in reframe.index if x.startswith('dummy')], axis=0, inplace=True)\n",
    "    byteamframe=pd.concat([reframe.loc[[x for x in reframe.index if x in lineup[lineup['team']==0].index]].sum(axis=0),\n",
    "                        reframe.loc[[x for x in reframe.index if x in lineup[lineup['team']==1].index]].sum(axis=0)], axis=1).T\n",
    "    \n",
    "    return reframe, byteamframe[byteamframe.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old but gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build dataset of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "inputs=[]\n",
    "outputs=[]\n",
    "for match in df_fix['match_report'].values:\n",
    "    \n",
    "    try:\n",
    "\n",
    "        inp, results = clean_report(match, df_players)\n",
    "\n",
    "        inputs.append(inp.astype(float).values.flatten())\n",
    "        outputs.append(results.astype(float).values.flatten())\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        pass\n",
    "        \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)\n",
    "\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/SA2021_inp.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/SA2021_out.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tsvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_outfield=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Outfield_clean.hdf',key='pl')\n",
    "df_keeper=pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/SA2021_Keeper_clean.hdf',key='pl')\n",
    "\n",
    "df_players=pd.concat([df_outfield,df_keeper],axis=0).fillna(0)\n",
    "#df_players.drop(['wins','draws','losses'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "ts=tsvd(n_components=int(df_players.shape[1])-1, random_state=32)\n",
    "ts.fit_transform(df_players)\n",
    "tsvd_var_ratios = ts.explained_variance_ratio_\n",
    "\n",
    "\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "\n",
    "    total_variance = 0.0\n",
    "    n_components = 0\n",
    "\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance += explained_variance        \n",
    "        n_components += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "\n",
    "    return n_components\n",
    "\n",
    "# Run function\n",
    "num_comp=select_n_components(tsvd_var_ratios, 0.9999)\n",
    "print(num_comp)\n",
    "ts=tsvd(n_components=num_comp, random_state=32)\n",
    "df_players=pd.DataFrame(ts.fit_transform(df_players),index=df_players.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587, 19)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_players['keeper']=0\n",
    "df_players['keeper'].loc[df_keeper.index]=1\n",
    "df_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "//miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "inputs=[]\n",
    "outputs=[]\n",
    "lineups=[]\n",
    "for match in df_fix['match_report'].values:\n",
    "    \n",
    "    try:\n",
    "\n",
    "        team1,team2,gk1,gk2,shots,lineup=get_report_data(path=match)\n",
    "        teams=pd.concat([team1,team2],axis=0).reset_index(drop=True)\n",
    "        gks=pd.concat([gk1,gk2],axis=0).reset_index(drop=True)\n",
    "\n",
    "        teams.set_index('player',drop=True,inplace=True)\n",
    "        gks.set_index('player',drop=True,inplace=True)\n",
    "        lineup.set_index('player',drop=True,inplace=True)\n",
    "\n",
    "        lineup['bench']=lineup['bench'].astype(int)\n",
    "        lineup.team=(lineup.team==lineup.team.unique()[1]).astype(int)\n",
    "        lineup=fillto50(lineup)\n",
    "\n",
    "        lineups.append(lineup)\n",
    "        teams=teams[['minutes','goals','assists','cards_yellow','cards_red','own_goals']]\n",
    "        gks.columns=[x[:-3] if x.endswith('_gk') else x for x in gks.columns]\n",
    "        gks=gks[['goals_against','saves']]\n",
    "        results=pd.concat([teams,gks],axis=1).loc[lineup.index].fillna(0)\n",
    "\n",
    "        inp, missing=build_team_from_lineup(lineup, df_players=df_players)\n",
    "        \n",
    "        #possibly redundant\n",
    "        results.loc[missing]=0\n",
    "\n",
    "        inputs.append(inp.astype(float).values.flatten())\n",
    "        outputs.append(results.astype(float).values.flatten())\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        pass\n",
    "        \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/SA2021_inp_tsvd.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/SA2021_out_tsvd.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/SA2021_lineups.pkl', 'wb') as pk:\n",
    "    pickle.dump(lineups,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/SA2021_out.pkl', 'rb') as pk:\n",
    "    out=pickle.load(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframe, byteam= revert_output(out[0], lineups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goals</th>\n",
       "      <th>assists</th>\n",
       "      <th>cards_yellow</th>\n",
       "      <th>cards_red</th>\n",
       "      <th>own_goals</th>\n",
       "      <th>goals_against</th>\n",
       "      <th>saves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   goals  assists  cards_yellow  cards_red  own_goals  goals_against  saves\n",
       "0    1.0      1.0           3.0        0.0        0.0            0.0    3.0\n",
       "1    0.0      0.0           1.0        0.0        0.0            1.0    5.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byteam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allplayers by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718\n",
      "SA\n",
      "BL\n",
      "LU\n",
      "PL\n",
      "LL\n",
      "1819\n",
      "SA\n",
      "BL\n",
      "LU\n",
      "PL\n",
      "LL\n",
      "1920\n",
      "SA\n",
      "BL\n",
      "LU\n",
      "PL\n",
      "LL\n",
      "2021\n",
      "SA\n",
      "BL\n",
      "LU\n",
      "PL\n",
      "LL\n"
     ]
    }
   ],
   "source": [
    "df_players=[]\n",
    "allpl_year=[]\n",
    "    \n",
    "for year in ['1718','1819','1920','2021']:\n",
    "    print(year)\n",
    "    \n",
    "    for league in ['SA','BL','LU','PL','LL']:\n",
    "        \n",
    "        print(league)\n",
    "        series=league+year\n",
    "        df_outfield = pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/'+series+'_Outfield.hdf')\n",
    "        df_keeper = pd.read_hdf('/Users/federico comitani/GitHub/sodakick/data/'+series+'_Keeper.hdf')\n",
    "        cp = clean_players(df_outfield, df_keeper)\n",
    "        if 'gca_og_for' in cp:\n",
    "            #this is available only for the last year\n",
    "            cp.drop(['gca_og_for'],axis=1,inplace=True) \n",
    "        if 'corner_kicks_straight' in cp:\n",
    "            #this is available only for the last year\n",
    "            cp.drop(['corner_kicks_straight'],axis=1,inplace=True) \n",
    "\n",
    "        df_players.append(cp.replace(np.inf,0))#.fillna(0).astype(float))\n",
    "\n",
    "    \n",
    "    ay = pd.concat(df_players, axis=0).fillna(0).astype(float)\n",
    "    \n",
    "    age=ay['birth_year'][~ay.index.duplicated(keep='first')]\n",
    "    ay=ay.sum(level=0)\n",
    "    ay['birth_year']=age\n",
    "    \n",
    "    allpl_year.append(ay)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(allpl_year)):\n",
    "    for j in range(len(allpl_year)):\n",
    "        if i!=j:\n",
    "            missing=allpl_year[j].index.difference(allpl_year[i].index)\n",
    "            missingDf=pd.DataFrame(np.nan,columns=allpl_year[j].columns,index=missing)\n",
    "            missingDf['birth_year']=allpl_year[j]['birth_year'].loc[missing]\n",
    "            allpl_year[i]=allpl_year[i].append(missingDf)\n",
    "            \n",
    "for i in range(len(allpl_year)):\n",
    "    allpl_year[i]=allpl_year[i].sort_index()\n",
    "    \n",
    "#fillna if you want to keep them as separate channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge them with weights\n",
    "from functools import reduce\n",
    "import copy\n",
    "allpl_yr_nu=copy.deepcopy(allpl_year)\n",
    "\n",
    "allpl_weighted=[]\n",
    "while len(allpl_yr_nu)>0:\n",
    "    \n",
    "    current=allpl_yr_nu.pop()\n",
    "    columns=current.columns\n",
    "    weight=1.0\n",
    "    \n",
    "    by=current['birth_year']\n",
    "    current.drop(['birth_year'],axis=1,inplace=True)\n",
    "    \n",
    "    div=pd.Series([1]*current.shape[0], index=current.index)\n",
    "    \n",
    "    for i in range(len(allpl_yr_nu))[::-1]:\n",
    "    \n",
    "        weight=weight/2\n",
    "        \n",
    "        to_add=allpl_yr_nu[i]*weight\n",
    "        to_add.drop(['birth_year'],axis=1,inplace=True)\n",
    "\n",
    "        notmissing=np.where(~to_add.isnull().all(1))\n",
    "        div.iloc[notmissing]+=weight\n",
    "\n",
    "        to_add=to_add.fillna(0)\n",
    "        \n",
    "\n",
    "        current=current.add(to_add)\n",
    "        \n",
    "    current=current.divide(div,axis=0)\n",
    "    current.dropna(how='all',axis=0,inplace=True)\n",
    "\n",
    "    current['birth_year']=by.loc[current.index]\n",
    "    \n",
    "    allpl_weighted.append(current[columns])\n",
    "    \n",
    "allpl_weighted=allpl_weighted[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "allpl=pd.concat(allpl_weighted, axis=0)\n",
    "allpl.drop(['keeper'], axis=1, inplace=True)\n",
    "\n",
    "ts=tsvd(n_components=int(allpl.shape[1])-1, random_state=32)\n",
    "ts.fit(allpl)\n",
    "tsvd_var_ratios = ts.explained_variance_ratio_\n",
    "\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "\n",
    "    total_variance = 0.0\n",
    "    n_components = 0\n",
    "\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance += explained_variance        \n",
    "        n_components += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "\n",
    "    return n_components\n",
    "\n",
    "# Run function\n",
    "num_comp=select_n_components(tsvd_var_ratios, 0.9999)\n",
    "print(num_comp)\n",
    "ts=tsvd(n_components=num_comp, random_state=32)\n",
    "ts.fit(allpl)\n",
    "\n",
    "allpl_weighted_ts=[]\n",
    "for i,play in enumerate(allpl_weighted):\n",
    "    #print(ts.transform(play))\n",
    "    #print([x for x in allpl.columns if x not in play.columns])\n",
    "    kp = play['keeper']\n",
    "    play = play.drop(['keeper'],axis=1)\n",
    "    try:\n",
    "        ts.transform(play)\n",
    "    except:\n",
    "        print(i)\n",
    "    allpl_weighted_ts.append(pd.DataFrame(ts.transform(play), index=play.index))\n",
    "    allpl_weighted_ts[-1]['keeper'] = kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/allplayers_weighted.pkl', 'wb') as pk:\n",
    "    pickle.dump(allpl_weighted,pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/allplayers_weighted_tsvd.pkl', 'wb') as pk:\n",
    "    pickle.dump(allpl_weighted_ts,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_year_dict={'1718': allpl_weighted_ts[0],\n",
    "                   '1819': allpl_weighted_ts[1],\n",
    "                   '1920': allpl_weighted_ts[2],\n",
    "                   '2021': allpl_weighted_ts[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2021\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(45, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(46, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(46, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(45, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(36, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(38, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(45, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(45, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(45, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(45, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(41, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(45, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(39, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(40, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(42, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(44, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n",
      "(43, 16)\n",
      "(50, 16)\n",
      "(50, 16)\n",
      "(50, 18)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "\n",
    "for i,series in enumerate(['SA2021','SA1920','BL2021','BL1920','LU2021','LU1920','PL2021','PL1920','LL2021','LL1920']):\n",
    "    \n",
    "    print(series)\n",
    "    \n",
    "    for match in df_fixs[i]['match_report'].values:\n",
    "\n",
    "        try:\n",
    "\n",
    "            inp, results = clean_report(match, players_year_dict[series[2:]])\n",
    "\n",
    "            inputs.append(inp.astype(float).values.flatten())\n",
    "            outputs.append(results.astype(float).values.flatten())\n",
    "\n",
    "        except:\n",
    "\n",
    "            pass\n",
    "\n",
    "    print(len(inputs))\n",
    "    \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)\n",
    "\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp_a.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out_a.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA1819\n",
      "357\n",
      "SA1718\n",
      "737\n",
      "BL1819\n",
      "1024\n",
      "BL1718\n",
      "1330\n",
      "LU1819\n",
      "1689\n",
      "LU1718\n",
      "1968\n",
      "PL1819\n",
      "2315\n",
      "PL1718\n",
      "2693\n",
      "LL1819\n",
      "3045\n",
      "LL1718\n",
      "3422\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "\n",
    "for i,series in enumerate(['SA1819','SA1718','BL1819','BL1718','LU1819','LU1718','PL1819','PL1718','LL1819','LL1718']):\n",
    "    \n",
    "    print(series)\n",
    "    \n",
    "    for match in df_fixs[i]['match_report'].values:\n",
    "\n",
    "        try:\n",
    "\n",
    "            inp, results = clean_report(match, players_year_dict[series[2:]])\n",
    "\n",
    "            inputs.append(inp.astype(float).values.flatten())\n",
    "            outputs.append(results.astype(float).values.flatten())\n",
    "\n",
    "        except:\n",
    "\n",
    "            pass\n",
    "\n",
    "    print(len(inputs))\n",
    "    \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)\n",
    "\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp_b.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out_b.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp_a.pkl', 'rb') as pk:\n",
    "    inputs=pickle.load(pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out_a.pkl', 'rb') as pk:\n",
    "    outputs=pickle.load(pk)\n",
    "    \n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp.pkl', 'rb') as pk:\n",
    "    inputs2=pickle.load(pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out.pkl', 'rb') as pk:\n",
    "    outputs2=pickle.load(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=np.concatenate([inputs,inputs2])\n",
    "outputs=np.concatenate([outputs,outputs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_inp.pkl', 'wb') as pk:\n",
    "    pickle.dump(inputs,pk)\n",
    "\n",
    "with open(r'/Users/federico comitani/GitHub/sodakick/data/10leagues_weight_out.pkl', 'wb') as pk:\n",
    "    pickle.dump(outputs,pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
